{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61dfebb8-0f7f-46d6-bb81-e5f83ae92878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import wandb\n",
    "from ott.neural import datasets\n",
    "import sys\n",
    "from omegaconf import DictConfig\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from typing import Optional, Literal\n",
    "import jax\n",
    "import pathlib\n",
    "import optax\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from flax import linen as nn\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from flax.training import train_state\n",
    "\n",
    "from ott.neural.networks.layers import time_encoder\n",
    "from ott.neural.methods.flows import dynamics, otfm\n",
    "from ott.neural.networks import velocity_field\n",
    "from ott.solvers import utils as solver_utils\n",
    "import jax.tree_util as jtu\n",
    "from ott.neural.networks.layers import time_encoder\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5cef7c9-5bac-41a7-bff7-7b77e6a24fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ot_pert.metrics import compute_metrics, compute_mean_metrics\n",
    "from src.ot_pert.nets.nets import VelocityFieldWithAttention\n",
    "from src.ot_pert.utils import ConditionalLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8d9117e-686f-4a49-a1f5-dc2f2f4bd724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reconstruct_data(embedding: np.ndarray, projection_matrix: np.ndarray, mean_to_add: np.ndarray) -> np.ndarray:\n",
    "    return np.matmul(embedding, projection_matrix.T) + mean_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb042442-062d-4f8a-afdc-e585d7554e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_match_fn(\n",
    "        src_lin: Optional[jnp.ndarray], tgt_lin: Optional[jnp.ndarray],\n",
    "        src_quad: Optional[jnp.ndarray], tgt_quad: Optional[jnp.ndarray], *,\n",
    "        typ: Literal[\"lin\", \"quad\", \"fused\"], epsilon: float = 1e-2, tau_a: float = 1.0,\n",
    "        tau_b: float = 1.0,\n",
    "    ) -> jnp.ndarray:\n",
    "        if typ == \"lin\":\n",
    "            return solver_utils.match_linear(x=src_lin, y=tgt_lin, scale_cost=\"mean\", epsilon=epsilon, tau_a=tau_a, tau_b=tau_b)\n",
    "        if typ == \"quad\":\n",
    "            return solver_utils.match_quadratic(xx=src_quad, yy=tgt_quad)\n",
    "        if typ == \"fused\":\n",
    "            return solver_utils.match_quadratic(\n",
    "                xx=src_quad, yy=tgt_quad, x=src_lin, y=tgt_lin\n",
    "            )\n",
    "        raise NotImplementedError(f\"Unknown type: {typ}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a91b5cf0-1638-47a7-9e05-2dc3abe6160b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m target_dim \u001b[38;5;241m=\u001b[39m source_dim\n\u001b[1;32m     45\u001b[0m condition_dim \u001b[38;5;241m=\u001b[39m condition_1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     47\u001b[0m vf \u001b[38;5;241m=\u001b[39m VelocityFieldWithAttention(\n\u001b[0;32m---> 48\u001b[0m     num_heads\u001b[38;5;241m=\u001b[39m\u001b[43mcfg\u001b[49m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m     49\u001b[0m     qkv_feature_dim\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mqkv_feature_dim,\n\u001b[1;32m     50\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[1;32m     51\u001b[0m     hidden_dims\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhidden_dims,\n\u001b[1;32m     52\u001b[0m     time_dims\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtime_dims,\n\u001b[1;32m     53\u001b[0m     output_dims\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39moutput_dims\u001b[38;5;241m+\u001b[39m[target_dim],\n\u001b[1;32m     54\u001b[0m     condition_dims\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcondition_dims,\n\u001b[1;32m     55\u001b[0m     time_encoder \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(time_encoder\u001b[38;5;241m.\u001b[39mcyclical_time_encoder, n_freqs\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtime_n_freqs),\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(vf)\n\u001b[1;32m     60\u001b[0m model \u001b[38;5;241m=\u001b[39m otfm\u001b[38;5;241m.\u001b[39mOTFlowMatching(vf,\n\u001b[1;32m     61\u001b[0m     flow\u001b[38;5;241m=\u001b[39mdynamics\u001b[38;5;241m.\u001b[39mConstantNoiseFlow(cfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mflow_noise),\n\u001b[1;32m     62\u001b[0m     match_fn\u001b[38;5;241m=\u001b[39mjax\u001b[38;5;241m.\u001b[39mjit(functools\u001b[38;5;241m.\u001b[39mpartial(data_match_fn, typ\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlin\u001b[39m\u001b[38;5;124m\"\u001b[39m, src_quad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tgt_quad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, epsilon\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mepsilon, tau_a\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtau_a, tau_b\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtau_b)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptax\u001b[38;5;241m.\u001b[39mMultiSteps(optax\u001b[38;5;241m.\u001b[39madam(learning_rate\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlearning_rate), cfg\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmulti_steps)\n\u001b[1;32m     66\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "adata_train = sc.read('/lustre/groups/ml01/workspace/ot_perturbation/data/norman/adata_train_0_seen_genes.h5ad')\n",
    "adata_train.obs = adata_train.obs.rename(columns={\"perturbation_name\": \"condition\"})\n",
    "dls = []\n",
    "\n",
    "train_data_source = {}\n",
    "train_data_target = {}\n",
    "train_data_source_decoded = {}\n",
    "train_data_target_decoded = {}\n",
    "train_data_conditions = {}\n",
    "\n",
    "\n",
    "source = adata_train[adata_train.obs[\"condition\"]==\"ctrl\"].obsm['X_pca']\n",
    "source_decoded = adata_train[adata_train.obs[\"condition\"]==\"ctrl\"].X\n",
    "for cond in adata_train.obs[\"condition\"].cat.categories:\n",
    "    if cond == \"ctrl\":\n",
    "        continue\n",
    "    target = adata_train[adata_train.obs[\"condition\"]==cond].obsm['X_pca']\n",
    "    target_decoded = adata_train[adata_train.obs[\"condition\"]==cond].X.A\n",
    "    condition_1 = adata_train[adata_train.obs[\"condition\"]==cond].obsm['emb_1']\n",
    "    condition_2 = adata_train[adata_train.obs[\"condition\"]==cond].obsm['emb_2']\n",
    "    assert np.all(np.all(condition_1 == condition_1[0], axis=1))\n",
    "    assert np.all(np.all(condition_2 == condition_2[0], axis=1))\n",
    "    expanded_arr = np.expand_dims(np.concatenate((condition_1[0,:][None,:],condition_2[0,:][None,:]), axis=0), axis=0)\n",
    "    conds = np.tile(expanded_arr, (len(source), 1, 1))\n",
    "    dls.append(DataLoader(datasets.OTDataset(datasets.OTData(\n",
    "        lin=source,\n",
    "        condition=conds,\n",
    "    ), datasets.OTData(lin=target)), batch_size=128, shuffle=True))\n",
    "    train_data_source[cond] = source\n",
    "    train_data_target[cond] = target\n",
    "    train_data_conditions[cond] = conds\n",
    "    train_data_source_decoded[cond] = source_decoded\n",
    "    train_data_target_decoded[cond] = target_decoded\n",
    "\n",
    "# train_loader = ConditionalLoader(dls, seed=0)\n",
    "\n",
    "# reconstruct_data_fn = functools.partial(reconstruct_data, projection_matrix=adata_train.varm[\"PCs\"], mean_to_add=adata_train.varm[\"X_train_mean\"].T)\n",
    "\n",
    "# source_dim = source.shape[1]\n",
    "# target_dim = source_dim\n",
    "# condition_dim = condition_1.shape[1]\n",
    "\n",
    "# source_dim = source.shape[1]\n",
    "# target_dim = source_dim\n",
    "# condition_dim = condition_1.shape[1]\n",
    "\n",
    "# vf = VelocityFieldWithAttention(\n",
    "#     num_heads=cfg.model.num_heads,\n",
    "#     qkv_feature_dim=cfg.model.qkv_feature_dim,\n",
    "#     max_seq_length=cfg.model.max_seq_length,\n",
    "#     hidden_dims=cfg.model.hidden_dims,\n",
    "#     time_dims=cfg.model.time_dims,\n",
    "#     output_dims=cfg.model.output_dims+[target_dim],\n",
    "#     condition_dims=cfg.model.condition_dims,\n",
    "#     time_encoder = functools.partial(time_encoder.cyclical_time_encoder, n_freqs=cfg.model.time_n_freqs),\n",
    "#     )\n",
    "\n",
    "# print(vf)\n",
    "\n",
    "# model = otfm.OTFlowMatching(vf,\n",
    "#     flow=dynamics.ConstantNoiseFlow(cfg.model.flow_noise),\n",
    "#     match_fn=jax.jit(functools.partial(data_match_fn, typ=\"lin\", src_quad=None, tgt_quad=None, epsilon=cfg.model.epsilon, tau_a=cfg.model.tau_a, tau_b=cfg.model.tau_b)),\n",
    "#     condition_dim=condition_dim,\n",
    "#     rng=jax.random.PRNGKey(13),\n",
    "#     optimizer=optax.MultiSteps(optax.adam(learning_rate=cfg.model.learning_rate), cfg.model.multi_steps)\n",
    "# )\n",
    "\n",
    "# print(model)\n",
    "\n",
    "# training_logs = {\"loss\": []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6d9f3b-3fd1-4798-8e56-d75eb130ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70f4e61-bd1b-4d4b-b656-36460a1e6b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 12:38:20.299900: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.3 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "a = jnp.array([1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483f8be5-5d96-40f3-be8a-032cfc123198",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.rand(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37745b0a-5ee3-472c-9b6e-4980d53f4c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6844ce9-426c-44f0-bca8-c434e3d21bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8811, 0.5417, 0.8617],\n",
       "        [0.5732, 0.9433, 0.4122]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "597de95d-2ddc-436e-bc2e-6c9c31293f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.cat((b, torch.zeros_like(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b5c7ea7-23fa-4582-8dbb-b4c7b5347c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8811, 0.5417, 0.8617],\n",
       "        [0.5732, 0.9433, 0.4122],\n",
       "        [0.0000, 0.0000, 1.0000],\n",
       "        [0.0000, 0.0000, 1.0000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(b==torch.tensor([[0.0000, 0.0000, 0.0000]]), torch.tensor([[0.0000, 0.0000, 1.0000]]), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4911b5-fed5-404d-b395-12841e38dc21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
