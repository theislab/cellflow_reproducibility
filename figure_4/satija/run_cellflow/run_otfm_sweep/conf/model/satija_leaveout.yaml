condition_embedding_dim: 1024

time_encoder_dims: [2048, 2048, 2048]
time_encoder_dropout: 0.0

hidden_dims: [4096, 4096, 4096]
hidden_dropout: 0.0

decoder_dims: [4096, 4096, 4096]
decoder_dropout: 0.2

pooling: "attention_token"

layers_before_pool:
  gene:
    layer_type: "mlp"
    dims: [1024, 1024]
    dropout: 0.2
  pathway:
    layer_type: "mlp"
    dims: [1024, 1024]
    dropout: 0.2
  cell_type:
    layer_type: "mlp"
    dims: [512, 512]
    dropout: 0.2
    
layers_after_pool: 
    layer_type: "mlp"
    dims: [4096, 4096]

cond_output_dropout: 0.5
time_freqs: 1024

multi_steps: 20

epsilon: 1.0
tau_a: 1.0
tau_b: 1.0

flow_noise: 0.5
flow_type: "constant_noise"

linear_projection_before_concatenation: False
layer_norm_before_concatenation: False
