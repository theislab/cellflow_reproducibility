{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is adapted from https://github.com/bowang-lab/scGPT/blob/7301b51a72f5db321fccebb51bc4dd1380d99023/tutorials/Tutorial_Perturbation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///lustre/groups/ml01/code/leander.dony/scGPT\n",
      "  Installing build dependencies ... \u001b[?done\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.13.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scGPT==0.2.1) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.2.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scGPT==0.2.1) (4.12.2)\n",
      "Requirement already satisfied: scib<2.0.0,>=1.0.3 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scGPT==0.2.1) (1.1.7)\n",
      "Requirement already satisfied: torchtext in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scGPT==0.2.1) (0.18.0)\n",
      "Requirement already satisfied: umap-learn>=0.5.3 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scGPT==0.2.1) (0.5.7)\n",
      "Requirement already satisfied: orbax<0.1.8 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scGPT==0.2.1) (0.1.7)\n",
      "Requirement already satisfied: scikit-misc>=0.1.4 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scGPT==0.2.1) (0.5.1)\n",
      "Requirement already satisfied: leidenalg>=0.8.10 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scGPT==0.2.1) (0.10.2)\n",
      "Requirement already satisfied: cell-gears<0.0.3 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scGPT==0.2.1) (0.0.2)\n",
      "Requirement already satisfied: scanpy<2.0.0,>=1.9.1 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scGPT==0.2.1) (1.11.0)\n",
      "Requirement already satisfied: numba>=0.55.1 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scGPT==0.2.1) (0.61.0)\n",
      "Requirement already satisfied: datasets<3.0.0,>=2.3.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scGPT==0.2.1) (2.21.0)\n",
      "Requirement already satisfied: scvi-tools<1.0,>=0.16.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scGPT==0.2.1) (0.20.3)\n",
      "Requirement already satisfied: pandas>=1.3.5 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scGPT==0.2.1) (2.2.3)\n",
      "Requirement already satisfied: dcor in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from cell-gears<0.0.3->scGPT==0.2.1) (0.6)\n",
      "Requirement already satisfied: networkx in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from cell-gears<0.0.3->scGPT==0.2.1) (3.4.2)\n",
      "Requirement already satisfied: numpy in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from cell-gears<0.0.3->scGPT==0.2.1) (2.1.3)\n",
      "Requirement already satisfied: tqdm in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from cell-gears<0.0.3->scGPT==0.2.1) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from cell-gears<0.0.3->scGPT==0.2.1) (1.5.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (0.29.2)\n",
      "Requirement already satisfied: xxhash in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (3.5.0)\n",
      "Requirement already satisfied: aiohttp in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (3.11.13)\n",
      "Requirement already satisfied: filelock in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (3.17.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (2.32.3)\n",
      "Requirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (2024.6.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (19.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (6.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (0.3.8)\n",
      "Requirement already satisfied: packaging in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (24.2)\n",
      "Requirement already satisfied: multiprocess in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (0.70.16)\n",
      "Requirement already satisfied: igraph<0.12,>=0.10.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from leidenalg>=0.8.10->scGPT==0.2.1) (0.11.8)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from numba>=0.55.1->scGPT==0.2.1) (0.44.0)\n",
      "Requirement already satisfied: importlib_resources in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from orbax<0.1.8->scGPT==0.2.1) (6.5.2)\n",
      "Requirement already satisfied: jax>=0.4.6 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from orbax<0.1.8->scGPT==0.2.1) (0.5.2)\n",
      "Requirement already satisfied: msgpack in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from orbax<0.1.8->scGPT==0.2.1) (1.1.0)\n",
      "Requirement already satisfied: nest_asyncio in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from orbax<0.1.8->scGPT==0.2.1) (1.6.0)\n",
      "Requirement already satisfied: absl-py in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from orbax<0.1.8->scGPT==0.2.1) (2.1.0)\n",
      "Requirement already satisfied: etils in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from orbax<0.1.8->scGPT==0.2.1) (1.12.1)\n",
      "Requirement already satisfied: cached_property in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from orbax<0.1.8->scGPT==0.2.1) (2.0.1)\n",
      "Requirement already satisfied: jaxlib in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from orbax<0.1.8->scGPT==0.2.1) (0.5.1)\n",
      "Requirement already satisfied: tensorstore>=0.1.20 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from orbax<0.1.8->scGPT==0.2.1) (0.1.72)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from pandas>=1.3.5->scGPT==0.2.1) (2025.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from pandas>=1.3.5->scGPT==0.2.1) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from pandas>=1.3.5->scGPT==0.2.1) (2.9.0.post0)\n",
      "Requirement already satisfied: anndata>=0.8 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (0.11.3)\n",
      "Requirement already satisfied: patsy!=1.0.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (1.0.1)\n",
      "Requirement already satisfied: seaborn>=0.13 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (0.13.2)\n",
      "Requirement already satisfied: matplotlib>=3.6 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (3.10.1)\n",
      "Requirement already satisfied: h5py>=3.7 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (3.13.0)\n",
      "Requirement already satisfied: statsmodels>=0.13 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (0.14.4)\n",
      "Requirement already satisfied: joblib in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (1.4.2)\n",
      "Requirement already satisfied: natsort in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (8.4.0)\n",
      "Requirement already satisfied: legacy-api-wrap>=1.4 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (1.4.1)\n",
      "Requirement already satisfied: session-info2 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (0.1.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (0.5.13)\n",
      "Requirement already satisfied: scipy>=1.8 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (1.15.2)\n",
      "Requirement already satisfied: pydot in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scib<2.0.0,>=1.0.3->scGPT==0.2.1) (3.0.4)\n",
      "Requirement already satisfied: deprecated in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scib<2.0.0,>=1.0.3->scGPT==0.2.1) (1.2.18)\n",
      "Requirement already satisfied: flax in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (0.10.4)\n",
      "Requirement already satisfied: openpyxl>=3.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (3.1.5)\n",
      "Requirement already satisfied: ml-collections>=0.1.1 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (1.0.0)\n",
      "Requirement already satisfied: rich>=12.0.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (13.9.4)\n",
      "Requirement already satisfied: mudata>=0.1.2 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (0.3.1)\n",
      "Requirement already satisfied: chex in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (0.1.89)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (1.6.2)\n",
      "Requirement already satisfied: numpyro in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (0.17.0)\n",
      "Requirement already satisfied: docrep>=0.3.2 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (0.3.2)\n",
      "Requirement already satisfied: pyro-ppl>=1.6.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (1.9.1)\n",
      "Requirement already satisfied: pytorch-lightning<1.10.0,>=1.9.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (1.9.5)\n",
      "Requirement already satisfied: optax in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (0.2.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from torch>=1.13.0->scGPT==0.2.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from torch>=1.13.0->scGPT==0.2.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from torch>=1.13.0->scGPT==0.2.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from torch>=1.13.0->scGPT==0.2.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from torch>=1.13.0->scGPT==0.2.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from torch>=1.13.0->scGPT==0.2.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from torch>=1.13.0->scGPT==0.2.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from torch>=1.13.0->scGPT==0.2.1) (12.1.3.1)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from torch>=1.13.0->scGPT==0.2.1) (2.3.0)\n",
      "Requirement already satisfied: sympy in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from torch>=1.13.0->scGPT==0.2.1) (1.13.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from torch>=1.13.0->scGPT==0.2.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from torch>=1.13.0->scGPT==0.2.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from torch>=1.13.0->scGPT==0.2.1) (12.1.0.106)\n",
      "Requirement already satisfied: jinja2 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from torch>=1.13.0->scGPT==0.2.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->scGPT==0.2.1) (12.8.93)\n",
      "Requirement already satisfied: exceptiongroup in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from anndata>=0.8->scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (1.2.2)\n",
      "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from anndata>=0.8->scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (1.11.1)\n",
      "Requirement already satisfied: six in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from docrep>=0.3.2->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (1.17.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (0.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (2.5.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (5.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (1.18.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from aiohttp->datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (25.1.0)\n",
      "Requirement already satisfied: texttable>=1.6.2 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from igraph<0.12,>=0.10.0->leidenalg>=0.8.10->scGPT==0.2.1) (1.7.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from jax>=0.4.6->orbax<0.1.8->scGPT==0.2.1) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from jax>=0.4.6->orbax<0.1.8->scGPT==0.2.1) (3.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from matplotlib>=3.6->scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from matplotlib>=3.6->scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (11.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from matplotlib>=3.6->scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from matplotlib>=3.6->scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from matplotlib>=3.6->scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (3.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from matplotlib>=3.6->scanpy<2.0.0,>=1.9.1->scGPT==0.2.1) (4.56.0)\n",
      "Requirement already satisfied: et-xmlfile in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from openpyxl>=3.0->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (2.0.0)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from pyro-ppl>=1.6.0->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (0.1.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from pytorch-lightning<1.10.0,>=1.9.0->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from requests>=2.32.2->datasets<3.0.0,>=2.3.0->scGPT==0.2.1) (3.10)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from rich>=12.0.0->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from rich>=12.0.0->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (2.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from scikit-learn->cell-gears<0.0.3->scGPT==0.2.1) (3.5.0)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from chex->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (1.0.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from deprecated->scib<2.0.0,>=1.0.3->scGPT==0.2.1) (1.17.2)\n",
      "Requirement already satisfied: treescope>=0.1.7 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from flax->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (0.1.9)\n",
      "Requirement already satisfied: orbax-checkpoint in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from flax->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (0.11.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->scGPT==0.2.1) (3.0.2)\n",
      "Requirement already satisfied: multipledispatch in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from numpyro->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (1.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from sympy->torch>=1.13.0->scGPT==0.2.1) (1.3.0)\n",
      "Requirement already satisfied: setuptools in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from lightning-utilities>=0.6.0.post0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (65.5.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (0.1.2)\n",
      "Requirement already satisfied: simplejson>=3.16.0 in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (3.20.1)\n",
      "Requirement already satisfied: protobuf in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (6.30.0)\n",
      "Requirement already satisfied: humanize in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from orbax-checkpoint->flax->scvi-tools<1.0,>=0.16.0->scGPT==0.2.1) (4.12.1)\n",
      "Requirement already satisfied: zipp in /home/icb/leander.dony/.pyenv/versions/3.10.16/envs/scgpt-3.10/lib/python3.10/site-packages (from etils->orbax<0.1.8->scGPT==0.2.1) (3.21.0)\n",
      "Building wheels for collected packages: scGPT\n",
      "  Building editable for scGPT (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scGPT: filename=scgpt-0.2.1-py3-none-any.whl size=5592 sha256=87133b8721fd47f6a901e7769ace2cb1d3939ef71f4d8fb521d0e16cec5a0054\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ljr_5jo9/wheels/01/9d/a4/89479c356a44dbe89b518a7a40c1dda9424ab7122c150f4b80\n",
      "Successfully built scGPT\n",
      "Installing collected packages: scGPT\n",
      "Successfully installed scGPT-0.2.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!MAX_JOBS=26 pip install \"flash-attn<1.0.5\" --no-build-isolation\n",
    "!pip uninstall -y scgpt\n",
    "!pip install -e /lustre/groups/ml01/code/leander.dony/scGPT/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/leander.dony/.pyenv/versions/scgpt-3.10/lib/python3.10/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/icb/leander.dony/.pyenv/versions/scgpt-3.10/lib/python3.10/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "from torch_geometric.loader import DataLoader\n",
    "from gears import PertData, GEARS\n",
    "from gears.inference import compute_metrics, deeper_analysis, non_dropout_analysis\n",
    "from gears.utils import create_cell_graph_dataset_for_prediction\n",
    "\n",
    "import scgpt as scg\n",
    "from scgpt.model import TransformerGenerator\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    criterion_neg_log_bernoulli,\n",
    "    masked_relative_error,\n",
    ")\n",
    "from scgpt.tokenizer import tokenize_batch, pad_batch, tokenize_and_pad_batch\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.utils import set_seed, map_raw_id_to_vocab_id, compute_perturbation_metrics\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import pandas as pd\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, train_loader: torch.utils.data.DataLoader) -> None:\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss, total_mse = 0.0, 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    num_batches = len(train_loader)\n",
    "    for batch, batch_data in enumerate(train_loader):\n",
    "        batch_size = len(batch_data.y)\n",
    "        batch_data.to(device)\n",
    "        x: torch.Tensor = batch_data.x  # (batch_size * n_genes, 2)\n",
    "        ori_gene_values = x[:, 0].view(batch_size, n_genes)\n",
    "        #pert_flags = x[:, 1].long().view(batch_size, n_genes)\n",
    "        pert_flags = torch.zeros((batch_size, n_genes), dtype = torch.long, device = device)\n",
    "        for idx in range(batch_size):\n",
    "            for pi in batch_data.pert_idx[idx]:\n",
    "                if pi != -1:\n",
    "                    pert_name = pert_names[pi]\n",
    "                    gene_idx = np.where(pert_data.gene_names == pert_name)[0][0]\n",
    "                    pert_flags[idx, gene_idx] = 1\n",
    "        target_gene_values = batch_data.y  # (batch_size, n_genes)\n",
    "\n",
    "        if include_zero_gene in [\"all\", \"batch-wise\"]:\n",
    "            if include_zero_gene == \"all\":\n",
    "                input_gene_ids = torch.arange(n_genes, device=device, dtype=torch.long)\n",
    "            else:\n",
    "                input_gene_ids = (\n",
    "                    ori_gene_values.nonzero()[:, 1].flatten().unique().sort()[0]\n",
    "                )\n",
    "            # sample input_gene_id\n",
    "            if len(input_gene_ids) > max_seq_len:\n",
    "                input_gene_ids = torch.randperm(len(input_gene_ids), device=device)[\n",
    "                    :max_seq_len\n",
    "                ]\n",
    "            input_values = ori_gene_values[:, input_gene_ids]\n",
    "            input_pert_flags = pert_flags[:, input_gene_ids]\n",
    "            target_values = target_gene_values[:, input_gene_ids]\n",
    "\n",
    "            mapped_input_gene_ids = map_raw_id_to_vocab_id(input_gene_ids, gene_ids)\n",
    "            mapped_input_gene_ids = mapped_input_gene_ids.repeat(batch_size, 1)\n",
    "\n",
    "            # src_key_padding_mask = mapped_input_gene_ids.eq(vocab[pad_token])\n",
    "            src_key_padding_mask = torch.zeros_like(\n",
    "                input_values, dtype=torch.bool, device=device\n",
    "            )\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=amp):\n",
    "            output_dict = model(\n",
    "                mapped_input_gene_ids,\n",
    "                input_values,\n",
    "                input_pert_flags,\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                CLS=CLS,\n",
    "                CCE=CCE,\n",
    "                MVC=MVC,\n",
    "                ECS=ECS,\n",
    "            )\n",
    "            output_values = output_dict[\"mlm_output\"]\n",
    "\n",
    "            masked_positions = torch.ones_like(\n",
    "                input_values, dtype=torch.bool\n",
    "            )  # Use all\n",
    "            loss = loss_mse = criterion(output_values, target_values, masked_positions)\n",
    "\n",
    "        model.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.filterwarnings(\"always\")\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(),\n",
    "                1.0,\n",
    "                error_if_nonfinite=False if scaler.is_enabled() else True,\n",
    "            )\n",
    "            if len(w) > 0:\n",
    "                logger.warning(\n",
    "                    f\"Found infinite gradient. This may be caused by the gradient \"\n",
    "                    f\"scaler. The current scale is {scaler.get_scale()}. This warning \"\n",
    "                    \"can be ignored if no longer occurs after autoscaling of the scaler.\"\n",
    "                )\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # torch.cuda.empty_cache()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_mse += loss_mse.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            cur_mse = total_mse / log_interval\n",
    "            # ppl = math.exp(cur_loss)\n",
    "            logger.info(\n",
    "                f\"| epoch {epoch:3d} | {batch:3d}/{num_batches:3d} batches | \"\n",
    "                f\"lr {lr:05.4f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | mse {cur_mse:5.2f} |\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            total_mse = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_perturb(\n",
    "    loader: DataLoader, model: TransformerGenerator, device: torch.device\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Run model in inference mode using a given data loader\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    pert_cat = []\n",
    "    pred = []\n",
    "    truth = []\n",
    "    pred_de = []\n",
    "    truth_de = []\n",
    "    results = {}\n",
    "    logvar = []\n",
    "\n",
    "    for itr, batch in enumerate(loader):\n",
    "        batch.to(device)\n",
    "        pert_cat.extend(batch.pert)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            p = model.pred_perturb(\n",
    "                batch,\n",
    "                pert_names,\n",
    "                pert_data.gene_names,\n",
    "                include_zero_gene=include_zero_gene,\n",
    "                gene_ids=gene_ids,\n",
    "            )\n",
    "            t = batch.y\n",
    "            pred.extend(p.cpu())\n",
    "            truth.extend(t.cpu())\n",
    "\n",
    "            # Differentially expressed genes\n",
    "            for itr, de_idx in enumerate(batch.de_idx):\n",
    "                pred_de.append(p[itr, de_idx])\n",
    "                truth_de.append(t[itr, de_idx])\n",
    "\n",
    "    # all genes\n",
    "    results[\"pert_cat\"] = np.array(pert_cat)\n",
    "    pred = torch.stack(pred)\n",
    "    truth = torch.stack(truth)\n",
    "    results[\"pred\"] = pred.detach().cpu().numpy().astype(float)\n",
    "    results[\"truth\"] = truth.detach().cpu().numpy().astype(float)\n",
    "\n",
    "    pred_de = torch.stack(pred_de)\n",
    "    truth_de = torch.stack(truth_de)\n",
    "    results[\"pred_de\"] = pred_de.detach().cpu().numpy().astype(float)\n",
    "    results[\"truth_de\"] = truth_de.detach().cpu().numpy().astype(float)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_genes_groups_by_cov(\n",
    "    adata,\n",
    "    groupby,\n",
    "    control_group,\n",
    "    covariate,\n",
    "    n_genes=50,\n",
    "    rankby_abs=True,\n",
    "    key_added=\"rank_genes_groups_cov\",\n",
    "    return_dict=False,\n",
    "):\n",
    "    gene_dict = {}\n",
    "    cov_categories = adata.obs[covariate].unique()\n",
    "    for cov_cat in cov_categories:\n",
    "        # name of the control group in the groupby obs column\n",
    "        control_group_cov = control_group  # \"_\".join([cov_cat, control_group])\n",
    "        # subset adata to cells belonging to a covariate category\n",
    "        adata_cov = adata[adata.obs[covariate] == cov_cat]\n",
    "        # compute DEGs\n",
    "        sc.tl.rank_genes_groups(\n",
    "            adata_cov,\n",
    "            groupby=groupby,\n",
    "            reference=control_group_cov,\n",
    "            rankby_abs=rankby_abs,\n",
    "            n_genes=n_genes,\n",
    "            use_raw=False,\n",
    "        )\n",
    "        # add entries to dictionary of gene sets\n",
    "        de_genes = pd.DataFrame(adata_cov.uns[\"rank_genes_groups\"][\"names\"])\n",
    "        for group in de_genes:\n",
    "            gene_dict[group] = de_genes[group].tolist()\n",
    "    adata.uns[key_added] = gene_dict\n",
    "    if return_dict:\n",
    "        return gene_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for data prcocessing\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "pad_value = 0  # for padding values\n",
    "pert_pad_id = 0\n",
    "include_zero_gene = \"all\"\n",
    "max_seq_len = 1536\n",
    "\n",
    "# settings for training\n",
    "MLM = True  # whether to use masked language modeling, currently it is always on.\n",
    "CLS = False  # celltype classification objective\n",
    "CCE = False  # Contrastive cell embedding objective\n",
    "MVC = False  # Masked value prediction for cell embedding\n",
    "ECS = False  # Elastic cell similarity objective\n",
    "amp = True\n",
    "load_model = \"/lustre/groups/ml01/workspace/leander.dony/projects/cellflow/250302_scGPT/scgpt_model/scGPT_human\"\n",
    "load_param_prefixs = [\n",
    "    \"encoder\",\n",
    "    \"value_encoder\",\n",
    "    \"transformer_encoder\",\n",
    "]\n",
    "\n",
    "# settings for optimizer\n",
    "lr = 1e-4  # or 1e-4\n",
    "batch_size = 64\n",
    "eval_batch_size = 64\n",
    "epochs = 15\n",
    "schedule_interval = 1\n",
    "early_stop = 10\n",
    "\n",
    "# settings for the model\n",
    "embsize = 512  # embedding dimension\n",
    "d_hid = 512  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 12  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 8  # number of heads in nn.MultiheadAttention\n",
    "n_layers_cls = 3\n",
    "dropout = 0  # dropout probability\n",
    "use_fast_transformer = True  # whether to use fast transformer\n",
    "\n",
    "# logging\n",
    "log_interval = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DATA_DIR = \"/lustre/groups/ml01/workspace/leander.dony/projects/cellflow/241106_gears/reproduce_biolord_repro/data/perturbations/norman/\"\n",
    "WRITE_DIR = \"/lustre/groups/ml01/workspace/leander.dony/projects/cellflow/250302_scGPT/adatas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DE analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local copy of pyg dataset is detected. Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "pert_data = PertData(DATA_DIR[:-1])\n",
    "pert_data.load(data_path = DATA_DIR + \"norman2019\")\n",
    "de_dict = rank_genes_groups_by_cov(\n",
    "    pert_data.adata,\n",
    "    groupby=\"condition\",\n",
    "    covariate=\"cell_type\",\n",
    "    control_group=\"ctrl\",\n",
    "    n_genes=50,\n",
    "    key_added=\"rank_genes_groups_cov_all\",\n",
    "    return_dict=True\n",
    ")\n",
    "pert_data.adata.write(f\"{WRITE_DIR}/adata_all.h5ad\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to /lustre/groups/ml01/workspace/leander.dony/projects/cellflow/250302_scGPT/logs/dev_perturb_norman-Mar26-07-59\n",
      "scGPT - INFO - Running on 2025-03-26 07:59:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local copy of pyg dataset is detected. Loading...\n",
      "Done!\n",
      "Local copy of split is detected. Loading...\n",
      "Simulation split test composition:\n",
      "combo_seen0:4\n",
      "combo_seen1:52\n",
      "combo_seen2:18\n",
      "unseen_single:37\n",
      "Done!\n",
      "Creating dataloaders....\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - match 4547/5045 genes in vocabulary of size 60697.\n",
      "scGPT - INFO - Resume model from /lustre/groups/ml01/workspace/leander.dony/projects/cellflow/250302_scGPT/scgpt_model/scGPT_human/best_model.pt, the model args will override the config /lustre/groups/ml01/workspace/leander.dony/projects/cellflow/250302_scGPT/scgpt_model/scGPT_human/args.json.\n",
      "scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])\n",
      "scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])\n",
      "scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - | epoch   1 | 100/815 batches | lr 0.0001 | ms/batch 694.85 | loss  0.05 | mse  0.05 |\n",
      "scGPT - INFO - | epoch   1 | 200/815 batches | lr 0.0001 | ms/batch 691.45 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - | epoch   1 | 300/815 batches | lr 0.0001 | ms/batch 690.57 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - | epoch   1 | 400/815 batches | lr 0.0001 | ms/batch 690.76 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - | epoch   1 | 500/815 batches | lr 0.0001 | ms/batch 689.94 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - | epoch   1 | 600/815 batches | lr 0.0001 | ms/batch 691.47 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - | epoch   1 | 700/815 batches | lr 0.0001 | ms/batch 686.11 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - | epoch   1 | 800/815 batches | lr 0.0001 | ms/batch 686.50 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - val_metrics at epoch 1: \n",
      "scGPT - INFO - {'pearson': np.float64(0.9883829455565742), 'pearson_de': np.float64(0.9010024186443871), 'pearson_delta': np.float64(0.4434529886462197), 'pearson_de_delta': np.float64(0.7282964257066177)}\n",
      "scGPT - INFO - | end of epoch   1 | time: 730.16s | \n",
      "scGPT - INFO - Best model with score 0.9884\n",
      "scGPT - INFO - | epoch   2 | 100/815 batches | lr 0.0001 | ms/batch 700.06 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - | epoch   2 | 200/815 batches | lr 0.0001 | ms/batch 691.62 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - | epoch   2 | 300/815 batches | lr 0.0001 | ms/batch 692.48 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - | epoch   2 | 400/815 batches | lr 0.0001 | ms/batch 688.02 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - | epoch   2 | 500/815 batches | lr 0.0001 | ms/batch 687.94 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - | epoch   2 | 600/815 batches | lr 0.0001 | ms/batch 689.20 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - | epoch   2 | 700/815 batches | lr 0.0001 | ms/batch 691.97 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - | epoch   2 | 800/815 batches | lr 0.0001 | ms/batch 691.15 | loss  0.04 | mse  0.04 |\n",
      "scGPT - INFO - val_metrics at epoch 2: \n",
      "scGPT - INFO - {'pearson': np.float64(0.9887785468503689), 'pearson_de': np.float64(0.92830028670399), 'pearson_delta': np.float64(0.41090361563812267), 'pearson_de_delta': np.float64(0.5502144527251134)}\n",
      "scGPT - INFO - | end of epoch   2 | time: 731.63s | \n",
      "scGPT - INFO - Best model with score 0.9888\n",
      "scGPT - INFO - | epoch   3 | 100/815 batches | lr 0.0001 | ms/batch 695.89 | loss  0.04 | mse  0.04 |\n"
     ]
    }
   ],
   "source": [
    "for seed in range(1,6):\n",
    "    save_dir = Path(f\"/lustre/groups/ml01/workspace/leander.dony/projects/cellflow/250302_scGPT/logs/dev_perturb_norman-{time.strftime('%b%d-%H-%M')}/\")\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"saving to {save_dir}\")\n",
    "    logger = scg.logger\n",
    "    scg.utils.add_file_handler(logger, save_dir / \"run.log\")\n",
    "    # log running date\n",
    "    logger.info(f\"Running on {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    pert_data = PertData(DATA_DIR[:-1])\n",
    "    pert_data.load(data_path = DATA_DIR + \"norman2019\")\n",
    "    pert_data.prepare_split(split=\"simulation\", seed=seed)\n",
    "    pert_data.get_dataloader(batch_size=batch_size, test_batch_size=eval_batch_size)\n",
    "    \n",
    "    \n",
    "    model_dir = Path(load_model)\n",
    "    model_config_file = model_dir / \"args.json\"\n",
    "    model_file = model_dir / \"best_model.pt\"\n",
    "    vocab_file = model_dir / \"vocab.json\"\n",
    "    \n",
    "    vocab = GeneVocab.from_file(vocab_file)\n",
    "    for s in special_tokens:\n",
    "        if s not in vocab:\n",
    "            vocab.append_token(s)\n",
    "    \n",
    "    pert_data.adata.var[\"id_in_vocab\"] = [\n",
    "        1 if gene in vocab else -1 for gene in pert_data.adata.var[\"gene_name\"]\n",
    "    ]\n",
    "    gene_ids_in_vocab = np.array(pert_data.adata.var[\"id_in_vocab\"])\n",
    "    logger.info(\n",
    "        f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n",
    "        f\"in vocabulary of size {len(vocab)}.\"\n",
    "    )\n",
    "    genes = pert_data.adata.var[\"gene_name\"].tolist()\n",
    "    \n",
    "    # model\n",
    "    with open(model_config_file, \"r\") as f:\n",
    "        model_configs = json.load(f)\n",
    "    logger.info(\n",
    "        f\"Resume model from {model_file}, the model args will override the \"\n",
    "        f\"config {model_config_file}.\"\n",
    "    )\n",
    "    embsize = model_configs[\"embsize\"]\n",
    "    nhead = model_configs[\"nheads\"]\n",
    "    d_hid = model_configs[\"d_hid\"]\n",
    "    nlayers = model_configs[\"nlayers\"]\n",
    "    n_layers_cls = model_configs[\"n_layers_cls\"]\n",
    "    \n",
    "    vocab.set_default_index(vocab[\"<pad>\"])\n",
    "    gene_ids = np.array(\n",
    "        [vocab[gene] if gene in vocab else vocab[\"<pad>\"] for gene in genes], dtype=int\n",
    "    )\n",
    "    n_genes = len(genes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ntokens = len(vocab)  # size of vocabulary\n",
    "    model = TransformerGenerator(\n",
    "        ntokens,\n",
    "        embsize,\n",
    "        nhead,\n",
    "        d_hid,\n",
    "        nlayers,\n",
    "        nlayers_cls=n_layers_cls,\n",
    "        n_cls=1,\n",
    "        vocab=vocab,\n",
    "        dropout=dropout,\n",
    "        pad_token=pad_token,\n",
    "        pad_value=pad_value,\n",
    "        pert_pad_id=pert_pad_id,\n",
    "        use_fast_transformer=use_fast_transformer,\n",
    "    )\n",
    "    \n",
    "    # only load params that start with the prefix\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = torch.load(model_file)\n",
    "    pretrained_dict = {\n",
    "        k: v\n",
    "        for k, v in pretrained_dict.items()\n",
    "        if any([k.startswith(prefix) for prefix in load_param_prefixs])\n",
    "    }\n",
    "    for k, v in pretrained_dict.items():\n",
    "        logger.info(f\"Loading params {k} with shape {v.shape}\")\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    criterion = masked_mse_loss\n",
    "    criterion_cls = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, schedule_interval, gamma=0.9)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    \n",
    "    \n",
    "    with open(os.path.join(pert_data.data_path, 'essential_norman.pkl'), 'rb') as f:\n",
    "      essential_genes = pickle.load(f)\n",
    "    with open(os.path.join(pert_data.data_path, 'gene2go_all.pkl'), 'rb') as f:\n",
    "        lookup_gene2go = pickle.load(f)\n",
    "    pert_names = np.unique(list({i: lookup_gene2go[i] for i in essential_genes if i in lookup_gene2go}.keys()))\n",
    "    \n",
    "    \n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_val_corr = 0\n",
    "    best_model = None\n",
    "    patience = 0\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train_loader = pert_data.dataloader[\"train_loader\"]\n",
    "        valid_loader = pert_data.dataloader[\"val_loader\"]\n",
    "    \n",
    "        train(\n",
    "            model,\n",
    "            train_loader,\n",
    "        )\n",
    "    \n",
    "        val_res = eval_perturb(valid_loader, model, device)\n",
    "        val_metrics = compute_perturbation_metrics(\n",
    "            val_res, pert_data.adata[pert_data.adata.obs[\"condition\"] == \"ctrl\"]\n",
    "        )\n",
    "        logger.info(f\"val_metrics at epoch {epoch}: \")\n",
    "        logger.info(val_metrics)\n",
    "    \n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        logger.info(f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \")\n",
    "    \n",
    "        val_score = val_metrics[\"pearson\"]\n",
    "        if val_score > best_val_corr:\n",
    "            best_val_corr = val_score\n",
    "            best_model = copy.deepcopy(model)\n",
    "            logger.info(f\"Best model with score {val_score:5.4f}\")\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= early_stop:\n",
    "                logger.info(f\"Early stop at epoch {epoch}\")\n",
    "                break\n",
    "    \n",
    "        scheduler.step()\n",
    "    torch.save(best_model.state_dict(), save_dir / \"best_model.pt\")\n",
    "    \n",
    "    \n",
    "    results = eval_perturb(pert_data.dataloader[\"test_loader\"],\n",
    "                           best_model,\n",
    "                           device)\n",
    "    for kind in [\"truth\", \"pred\"]:\n",
    "        adata = anndata.AnnData(\n",
    "            X=results[kind],\n",
    "            var=pert_data.adata.var,\n",
    "            obs=pd.DataFrame({\n",
    "                \"condition\": results[\"pert_cat\"], \n",
    "                \"subgroup\": pd.Series(results[\"pert_cat\"]).map({v: k for k, vs in pert_data.subgroup[\"test_subgroup\"].items() for v in vs})\n",
    "            }),\n",
    "            uns={\"rank_genes_groups_cov_all\": de_dict},\n",
    "        )\n",
    "        for subgroup in adata.obs[\"subgroup\"].unique():\n",
    "            adata[adata.obs[\"subgroup\"] == subgroup].write(os.path.join(WRITE_DIR, f'norman_scgpt_seed{seed}_test_{subgroup.replace(\"_\", \"\")}_{kind}.h5ad'), compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scgpt-3.10",
   "language": "python",
   "name": "scgpt-3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
