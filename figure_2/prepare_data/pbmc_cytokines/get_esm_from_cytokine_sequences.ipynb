{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f29e00e9-d04d-4ce4-88b8-2e1f941eb0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/dominik.klein/mambaforge/envs/esm_cfp/lib/python3.12/site-packages/anndata/utils.py:429: FutureWarning: Importing read_csv from `anndata` is deprecated. Import anndata.io.read_csv instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/dominik.klein/mambaforge/envs/esm_cfp/lib/python3.12/site-packages/anndata/utils.py:429: FutureWarning: Importing read_excel from `anndata` is deprecated. Import anndata.io.read_excel instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/dominik.klein/mambaforge/envs/esm_cfp/lib/python3.12/site-packages/anndata/utils.py:429: FutureWarning: Importing read_hdf from `anndata` is deprecated. Import anndata.io.read_hdf instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/dominik.klein/mambaforge/envs/esm_cfp/lib/python3.12/site-packages/anndata/utils.py:429: FutureWarning: Importing read_loom from `anndata` is deprecated. Import anndata.io.read_loom instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/dominik.klein/mambaforge/envs/esm_cfp/lib/python3.12/site-packages/anndata/utils.py:429: FutureWarning: Importing read_mtx from `anndata` is deprecated. Import anndata.io.read_mtx instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/dominik.klein/mambaforge/envs/esm_cfp/lib/python3.12/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/dominik.klein/mambaforge/envs/esm_cfp/lib/python3.12/site-packages/anndata/utils.py:429: FutureWarning: Importing read_umi_tools from `anndata` is deprecated. Import anndata.io.read_umi_tools instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/icb/dominik.klein/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from functools import cached_property\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "from collections.abc import Callable, Iterable\n",
    "from esm import FastaBatchedDataset, pretrained\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "    from transformers import AutoTokenizer, EsmModel\n",
    "except ImportError as e:\n",
    "    torch = None\n",
    "    DataLoader = None\n",
    "    AutoTokenizer = None\n",
    "    EsmModel = None\n",
    "    raise ImportError(\n",
    "        \"To use gene embedding, please install `transformers` and `torch` \\\n",
    "            e.g. via `pip install cfp['embedding']`.\"\n",
    "    ) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1769ae8f-e8da-46b3-a1ef-b6472ff0a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "out_dir = \"/lustre/groups/ml01/workspace/ot_perturbation/data/pbmc\"\n",
    "fasta_file = os.path.join(out_dir, \"cytokines.fasta\")\n",
    "\n",
    "records = list(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "\n",
    "data = {\n",
    "    \"gene_id\": [record.description for record in records],\n",
    "    \"protein_sequence\": [str(record.seq) for record in records]\n",
    "}\n",
    "df_sequences = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4542450-3d2b-4485-9a85-ea3e6e682832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4-1BBL</td>\n",
       "      <td>MEYASDASLDPEAPWPPAPRARACRVLPWALVAGLLLLLLLAAACA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADSF</td>\n",
       "      <td>MKALCLLLLPVLGLLVSSKTLCSMEEAINERIQEVAGSLIFRAISS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APRIL</td>\n",
       "      <td>MPASSPFLLAPKGPPGNMGGPVREPALSVALWLSWGAALGAVACAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAFF</td>\n",
       "      <td>MRRGPRSLRGRDAPAPTPCVPAECFDLLVRHCVACGLLRTPRPKPA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C3a</td>\n",
       "      <td>MASFSAETNSTDLLSQPWNEPPVILSMVILSLTFLLGLPGNGLVLW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>LT-alpha</td>\n",
       "      <td>MTPPERLFLPRVCGTTLHLLLLGLLLVLLPGAQGLPGVGLTPSAAQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>LT-beta</td>\n",
       "      <td>MGALGLEGRGGRLQGRGSLLLAVAGATSLVTLLLAVPITVLAVLAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>EBI3</td>\n",
       "      <td>MTPQLLLALVLWASCPPCSGRKGPPAALTLPRVQCRASRYPIAVDC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>LT-alpha1-beta2</td>\n",
       "      <td>MTPPERLFLPRVCGTTLHLLLLGLLLVLLPGAQGLPGVGLTPSAAQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>LT-alpha2-beta1</td>\n",
       "      <td>MTPPERLFLPRVCGTTLHLLLLGLLLVLLPGAQGLPGVGLTPSAAQ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gene_id                                   protein_sequence\n",
       "0            4-1BBL  MEYASDASLDPEAPWPPAPRARACRVLPWALVAGLLLLLLLAAACA...\n",
       "1              ADSF  MKALCLLLLPVLGLLVSSKTLCSMEEAINERIQEVAGSLIFRAISS...\n",
       "2             APRIL  MPASSPFLLAPKGPPGNMGGPVREPALSVALWLSWGAALGAVACAM...\n",
       "3              BAFF  MRRGPRSLRGRDAPAPTPCVPAECFDLLVRHCVACGLLRTPRPKPA...\n",
       "4               C3a  MASFSAETNSTDLLSQPWNEPPVILSMVILSLTFLLGLPGNGLVLW...\n",
       "..              ...                                                ...\n",
       "88         LT-alpha  MTPPERLFLPRVCGTTLHLLLLGLLLVLLPGAQGLPGVGLTPSAAQ...\n",
       "89          LT-beta  MGALGLEGRGGRLQGRGSLLLAVAGATSLVTLLLAVPITVLAVLAL...\n",
       "90             EBI3  MTPQLLLALVLWASCPPCSGRKGPPAALTLPRVQCRASRYPIAVDC...\n",
       "91  LT-alpha1-beta2  MTPPERLFLPRVCGTTLHLLLLGLLLVLLPGAQGLPGVGLTPSAAQ...\n",
       "92  LT-alpha2-beta1  MTPPERLFLPRVCGTTLHLLLLGLLLVLLPGAQGLPGVGLTPSAAQ...\n",
       "\n",
       "[93 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "078f1def-1156-47b9-8a0c-5043d87de055",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EmbeddingConfig:\n",
    "    fasta_path: str\n",
    "    model_name: str = \"esm2_t36_3B_UR50D\"\n",
    "    output_dir: str = \"gene_embeddings\"\n",
    "    include: str = \"mean\"\n",
    "    use_gpu: bool = True\n",
    "    toks_per_batch: int = 4096\n",
    "    truncation_seq_length: int = 1022\n",
    "    repr_layers: list[int] | None = None\n",
    "    save_to_disk: bool = True\n",
    "    _valid_includes = [\"per_tok\", \"mean\", \"bos\"]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.repr_layers is None:\n",
    "            self.repr_layers = [-1]\n",
    "        assert (\n",
    "            self.include in self._valid_includes\n",
    "        ), f\"Must be one of {self._valid_includes}\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4a35c8a-bbfc-4daa-8981-d5b326414dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_from_seq(\n",
    "    config: EmbeddingConfig,\n",
    "):\n",
    "    model, alphabet = pretrained.load_model_and_alphabet(config.model_name)\n",
    "    model.eval()\n",
    "    if torch.cuda.is_available() and config.use_gpu:\n",
    "        model = model.cuda()\n",
    "    dataset = FastaBatchedDataset.from_file(config.fasta_path)\n",
    "    batches = dataset.get_batch_indices(config.toks_per_batch, extra_toks_per_seq=1)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        collate_fn=alphabet.get_batch_converter(config.truncation_seq_length),\n",
    "        batch_sampler=batches,\n",
    "    )\n",
    "    print(f\"Read {len(dataset)} sequences from {config.fasta_path}\")\n",
    "    results: dict[str, dict[str, torch.Tensor]] = {}\n",
    "    # Don't overwrite existing embeddings\n",
    "    for file in os.listdir(config.output_dir):\n",
    "        if file.endswith(\".pth\"):\n",
    "            print(\n",
    "                f\"Found existing .pth file in {config.output_dir}. Skipping embedding generation.\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        assert all(\n",
    "            -(model.num_layers + 1) <= i <= model.num_layers for i in config.repr_layers\n",
    "        )\n",
    "    repr_layers = [\n",
    "        (i + model.num_layers + 1) % (model.num_layers + 1) for i in config.repr_layers\n",
    "    ]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (labels, strs, toks) in enumerate(data_loader):\n",
    "            print(\n",
    "                f\"Processing {batch_idx + 1} of {len(batches)} batches ({toks.size(0)} sequences)\"\n",
    "            )\n",
    "            if torch.cuda.is_available() and config.use_gpu:\n",
    "                toks = toks.to(device=\"cuda\", non_blocking=True)\n",
    "\n",
    "            out = model(toks, repr_layers=repr_layers, return_contacts=False)\n",
    "            representations = {\n",
    "                layer: t.to(device=\"cpu\") for layer, t in out[\"representations\"].items()\n",
    "            }\n",
    "\n",
    "            for i, label in enumerate(labels):\n",
    "                output_file = os.path.join(config.output_dir, f\"{label}.pth\")\n",
    "                result = {\"label\": label}\n",
    "                truncate_len = min(config.truncation_seq_length, len(strs[i]))\n",
    "                # Call clone on tensors to ensure tensors are not views into a larger representation\n",
    "                # See https://github.com/pytorch/pytorch/issues/1995\n",
    "                emb = None\n",
    "                if \"per_tok\" in config.include:\n",
    "                    emb = {\n",
    "                        layer: t[i, 1 : truncate_len + 1].clone()\n",
    "                        for layer, t in representations.items()\n",
    "                    }\n",
    "                elif \"mean\" in config.include:\n",
    "                    emb = {\n",
    "                        layer: t[i, 1 : truncate_len + 1].mean(0).clone()\n",
    "                        for layer, t in representations.items()\n",
    "                    }\n",
    "                elif \"bos\" in config.include:\n",
    "                    emb = {\n",
    "                        layer: t[i, 0].clone() for layer, t in representations.items()\n",
    "                    }\n",
    "\n",
    "                result[config.include] = emb\n",
    "                average_layers = torch.stack(list(emb.values())).mean(0)\n",
    "                result[\"average_layers\"] = average_layers\n",
    "                if config.save_to_disk:\n",
    "                    torch.save(\n",
    "                        result,\n",
    "                        output_file,\n",
    "                    )\n",
    "                    results[label] = output_file\n",
    "                else:\n",
    "                    results[label] = average_layers\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2af50135-489b-4976-adb9-232c5072e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchedDataset:\n",
    "    \"\"\"Modified batched dataset from fair-esm `c9c7d4f0fec964ce10c3e11dccec6c16edaa5144`\"\"\"\n",
    "\n",
    "    def __init__(self, sequence_labels, sequence_strs):\n",
    "        self.sequence_labels = list(sequence_labels)\n",
    "        self.sequence_strs = list(sequence_strs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequence_labels[idx], self.sequence_strs[idx]\n",
    "\n",
    "    def get_batch_indices(\n",
    "        self, toks_per_batch, extra_toks_per_seq=0\n",
    "    ) -> list[list[int]]:\n",
    "        sizes = [(len(s), i) for i, s in enumerate(self.sequence_strs)]\n",
    "        sizes.sort()\n",
    "        batches = []\n",
    "        buf: list[int] = []\n",
    "        max_len = 0\n",
    "\n",
    "        def _flush_current_buf():\n",
    "            nonlocal max_len, buf\n",
    "            if len(buf) == 0:\n",
    "                return\n",
    "            batches.append(buf)\n",
    "            buf = []\n",
    "            max_len = 0\n",
    "\n",
    "        for sz, i in sizes:\n",
    "            sz += extra_toks_per_seq\n",
    "            if max(sz, max_len) * (len(buf) + 1) > toks_per_batch:\n",
    "                _flush_current_buf()\n",
    "            max_len = max(max_len, sz)\n",
    "            buf.append(i)\n",
    "\n",
    "        _flush_current_buf()\n",
    "        return batches\n",
    "        \n",
    "def create_dataloader(\n",
    "    prot_names: list[str],\n",
    "    sequences: list[str],\n",
    "    toks_per_batch: int,\n",
    "    collate_fn: Callable,  # type: ignore[type-arg]\n",
    ") -> DataLoader:\n",
    "    dataset = BatchedDataset(prot_names, sequences)\n",
    "    batches = dataset.get_batch_indices(toks_per_batch, extra_toks_per_seq=1)\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_sampler=batches,\n",
    "    )\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "def _get_esm_collate_fn(\n",
    "    tokenizer: Callable, max_length: int | None, truncation: bool, return_tensors: str  # type: ignore[type-arg]\n",
    ") -> Callable:  # type: ignore[type-arg]\n",
    "    def collate_fn(batch):\n",
    "        # batch of tuples (gene_id, sequence)\n",
    "        gene_id, seq = zip(*batch, strict=False)\n",
    "        metadata = {\"gene_id\": gene_id, \"protein_sequence\": seq}\n",
    "        token = tokenizer(\n",
    "            seq,\n",
    "            padding=True,\n",
    "            max_length=max_length,\n",
    "            truncation=truncation,\n",
    "            return_tensors=return_tensors,\n",
    "        )\n",
    "        return metadata, token\n",
    "\n",
    "    return collate_fn\n",
    "    \n",
    "def get_model_and_tokenizer(\n",
    "    model_name: str, use_cuda: bool, cache_dir: None | str\n",
    ") -> tuple[EsmModel, AutoTokenizer]:\n",
    "    model_path = os.path.join(\"facebook\", model_name)\n",
    "    model = EsmModel.from_pretrained(model_path, cache_dir=cache_dir)\n",
    "    model.eval()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, cache_dir=cache_dir)\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    model.requires_grad_(False)\n",
    "    return model, tokenizer\n",
    "    \n",
    "def protein_features_from_genes(\n",
    "    metadata: pd.DataFrame,\n",
    "    esm_model_name: str = \"esm2_t36_3B_UR50D\",\n",
    "    toks_per_batch: int = 4096,\n",
    "    trunc_len: int | None = 1022,\n",
    "    truncation: bool = True,\n",
    "    use_cuda: bool = True,\n",
    "    cache_dir: None | str = None,\n",
    ") -> tuple[dict[str, torch.Tensor], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Compute gene embeddings using ESM2 :cite:`lin:2023`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    genes : list[str]\n",
    "        List of gene names.\n",
    "    esm_model_name : str\n",
    "        Name of the ESM model to use.\n",
    "    toks_per_batch : int\n",
    "        Number of tokens per batch.\n",
    "    trunc_len : int | None\n",
    "        Maximum length of the sequence.\n",
    "    truncation : bool\n",
    "        Whether to truncate the sequence.\n",
    "    use_cuda : bool\n",
    "        Use GPU if available.\n",
    "    cache_dir : str | None\n",
    "        Directory to cache the model.\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, torch.Tensor]\n",
    "        Dictionary with gene names as keys and embeddings as values.\n",
    "    \"\"\"\n",
    "    if os.getenv(\"HF_HOME\") is None and cache_dir is None:\n",
    "        print(\n",
    "            \"HF_HOME environment variable is not set and `cache_dir` is None. \\\n",
    "                Cache will be stored in the current directory.\"\n",
    "        )\n",
    "    to_emb = metadata[metadata.protein_sequence.notnull()]\n",
    "    use_cuda = use_cuda and torch.cuda.is_available()\n",
    "    esm, tokenizer = get_model_and_tokenizer(esm_model_name, use_cuda, cache_dir)\n",
    "    data_loader = create_dataloader(\n",
    "        prot_names=to_emb[\"gene_id\"].to_list(),\n",
    "        sequences=to_emb[\"protein_sequence\"].to_list(),\n",
    "        toks_per_batch=toks_per_batch,\n",
    "        collate_fn=_get_esm_collate_fn(\n",
    "            tokenizer, max_length=trunc_len, truncation=truncation, return_tensors=\"pt\"\n",
    "        ),\n",
    "    )\n",
    "    results = {}\n",
    "    for batch_metadata, batch in data_loader:\n",
    "        if use_cuda:\n",
    "            batch = {k: v.cuda() for k, v in batch.items()}\n",
    "        batch_results = esm(**batch).last_hidden_state\n",
    "        for i, name in enumerate(batch_metadata[\"gene_id\"]):\n",
    "            trunc_len = min(trunc_len, len(batch_metadata[\"protein_sequence\"][i]))  # type: ignore[type-var]\n",
    "            emb = batch_results[i, 1 : trunc_len + 1].mean(0).clone()  # type: ignore[operator]\n",
    "            results[name] = emb\n",
    "    return results, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44521ea2-b0d1-4176-8416-92fa01fbb6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HOME environment variable is not set and `cache_dir` is None.                 Cache will be stored in the current directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.91s/it]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t36_3B_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "res = protein_features_from_genes(df_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01be9175-180e-49bb-8540-088ae25a8321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39c7872b-ee2d-4247-8302-fdef0f518add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34e60881-cf66-4c64-8f42-b9fa1242e094",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1,seq1 in res[0].items():\n",
    "    for k2,seq2 in res[0].items():\n",
    "        if (seq1==seq2).all() and k1!=k2:\n",
    "            print(k1,k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "194a53b8-4bd2-40c0-ad0e-b62f5c9ce2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4-1BBL</td>\n",
       "      <td>MEYASDASLDPEAPWPPAPRARACRVLPWALVAGLLLLLLLAAACA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADSF</td>\n",
       "      <td>MKALCLLLLPVLGLLVSSKTLCSMEEAINERIQEVAGSLIFRAISS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APRIL</td>\n",
       "      <td>MPASSPFLLAPKGPPGNMGGPVREPALSVALWLSWGAALGAVACAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAFF</td>\n",
       "      <td>MRRGPRSLRGRDAPAPTPCVPAECFDLLVRHCVACGLLRTPRPKPA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C3a</td>\n",
       "      <td>MASFSAETNSTDLLSQPWNEPPVILSMVILSLTFLLGLPGNGLVLW...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gene_id                                   protein_sequence\n",
       "0  4-1BBL  MEYASDASLDPEAPWPPAPRARACRVLPWALVAGLLLLLLLAAACA...\n",
       "1    ADSF  MKALCLLLLPVLGLLVSSKTLCSMEEAINERIQEVAGSLIFRAISS...\n",
       "2   APRIL  MPASSPFLLAPKGPPGNMGGPVREPALSVALWLSWGAALGAVACAM...\n",
       "3    BAFF  MRRGPRSLRGRDAPAPTPCVPAECFDLLVRHCVACGLLRTPRPKPA...\n",
       "4     C3a  MASFSAETNSTDLLSQPWNEPPVILSMVILSLTFLLGLPGNGLVLW..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sequences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9816c293-bda9-423f-8474-0be3f4683654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IFN-lambda1': tensor([ 0.0112, -0.0815,  0.0285,  ...,  0.0089, -0.0819, -0.0276],\n",
       "        device='cuda:0'),\n",
       " 'IL-8': tensor([-0.0143, -0.0439, -0.0228,  ..., -0.0219, -0.1844, -0.1153],\n",
       "        device='cuda:0'),\n",
       " 'ADSF': tensor([ 0.0192, -0.0595, -0.0010,  ...,  0.0255, -0.0967,  0.0006],\n",
       "        device='cuda:0'),\n",
       " 'TWEAK': tensor([ 0.0480, -0.0882, -0.0545,  ...,  0.0856, -0.0350, -0.1216],\n",
       "        device='cuda:0'),\n",
       " 'IL-5': tensor([ 0.0349, -0.0719,  0.0069,  ...,  0.0076, -0.0923, -0.0406],\n",
       "        device='cuda:0'),\n",
       " 'GM-CSF': tensor([ 0.0212, -0.0584, -0.0158,  ...,  0.0066, -0.0830, -0.0619],\n",
       "        device='cuda:0'),\n",
       " 'IL-13': tensor([ 0.0542, -0.0739,  0.0117,  ..., -0.0002, -0.1194, -0.0866],\n",
       "        device='cuda:0'),\n",
       " 'LIGHT': tensor([-0.0672,  0.0025,  0.0571,  ...,  0.0814, -0.1939, -0.1834],\n",
       "        device='cuda:0'),\n",
       " 'IL-3': tensor([ 0.0705, -0.0476, -0.0049,  ..., -0.0105, -0.1240, -0.0033],\n",
       "        device='cuda:0'),\n",
       " 'IL-2': tensor([ 0.0839, -0.0132, -0.0095,  ..., -0.0224, -0.0811, -0.0169],\n",
       "        device='cuda:0'),\n",
       " 'IL-4': tensor([ 0.0569, -0.0612, -0.0066,  ...,  0.0117, -0.0773, -0.0503],\n",
       "        device='cuda:0'),\n",
       " 'IL-17A': tensor([-0.0219, -0.0395, -0.0081,  ...,  0.0895, -0.2513, -0.0502],\n",
       "        device='cuda:0'),\n",
       " 'IL-36Ra': tensor([ 0.0741,  0.0405, -0.0255,  ...,  0.0941, -0.1304, -0.0983],\n",
       "        device='cuda:0'),\n",
       " 'PSPN': tensor([ 0.0317, -0.0847, -0.0438,  ...,  0.0696, -0.2174, -0.1157],\n",
       "        device='cuda:0'),\n",
       " 'TSLP': tensor([ 0.0574, -0.0229,  0.0041,  ..., -0.0380, -0.0903,  0.0048],\n",
       "        device='cuda:0'),\n",
       " 'IL-36-alpha': tensor([ 0.0827,  0.0495, -0.0141,  ...,  0.0764, -0.0986, -0.0015],\n",
       "        device='cuda:0'),\n",
       " 'IL-15': tensor([ 0.0558, -0.0393,  0.0391,  ..., -0.0528, -0.1778,  0.0053],\n",
       "        device='cuda:0'),\n",
       " 'IL-21': tensor([ 0.0399, -0.0222,  0.0031,  ..., -0.0121, -0.1206, -0.0168],\n",
       "        device='cuda:0'),\n",
       " 'IL-17F': tensor([ 0.0257, -0.0414,  0.0345,  ...,  0.0622, -0.2426, -0.0579],\n",
       "        device='cuda:0'),\n",
       " 'Leptin': tensor([ 0.0735, -0.0221,  0.0047,  ..., -0.0077, -0.1332, -0.0645],\n",
       "        device='cuda:0'),\n",
       " 'IL-26': tensor([ 0.0437, -0.0121,  0.0424,  ..., -0.0091, -0.1273, -0.0218],\n",
       "        device='cuda:0'),\n",
       " 'IL-20': tensor([ 0.0345, -0.0467,  0.0285,  ...,  0.0496, -0.1058, -0.1336],\n",
       "        device='cuda:0'),\n",
       " 'GITRL': tensor([ 0.0445, -0.0245,  0.0515,  ...,  0.0448, -0.1653,  0.0458],\n",
       "        device='cuda:0'),\n",
       " 'IL-17E': tensor([-0.0194, -0.0830,  0.0262,  ...,  0.0506, -0.2208, -0.0594],\n",
       "        device='cuda:0'),\n",
       " 'IL-19': tensor([ 0.0403, -0.0542,  0.0281,  ...,  0.0307, -0.1270, -0.1317],\n",
       "        device='cuda:0'),\n",
       " 'IL-1Ra': tensor([ 0.0614,  0.0098,  0.0033,  ...,  0.0467, -0.1841,  0.0007],\n",
       "        device='cuda:0'),\n",
       " 'IL-7': tensor([ 0.0701, -0.0593,  0.0004,  ...,  0.0181, -0.1332, -0.0190],\n",
       "        device='cuda:0'),\n",
       " 'IL-10': tensor([ 0.0019, -0.0520, -0.0040,  ...,  0.0156, -0.0686, -0.1257],\n",
       "        device='cuda:0'),\n",
       " 'IL-22': tensor([ 0.0224, -0.0056,  0.0050,  ...,  0.0332, -0.1330, -0.0864],\n",
       "        device='cuda:0'),\n",
       " 'IL-17B': tensor([-0.0116, -0.1062,  0.0211,  ...,  0.0413, -0.1592, -0.0674],\n",
       "        device='cuda:0'),\n",
       " 'OX40L': tensor([-0.0169, -0.0776,  0.0081,  ...,  0.0741, -0.1587, -0.1271],\n",
       "        device='cuda:0'),\n",
       " 'BAFF': tensor([ 0.0304, -0.0960, -0.0451,  ...,  0.0665, -0.0773, -0.0937],\n",
       "        device='cuda:0'),\n",
       " 'IFN-beta': tensor([ 0.0694, -0.0010, -0.0395,  ...,  0.0257, -0.1401, -0.0627],\n",
       "        device='cuda:0'),\n",
       " 'IFN-alpha1': tensor([ 0.0525, -0.0690, -0.0453,  ...,  0.0073, -0.1639, -0.2374],\n",
       "        device='cuda:0'),\n",
       " 'CD27L': tensor([ 0.0735, -0.0921,  0.0545,  ...,  0.0286, -0.1147, -0.0207],\n",
       "        device='cuda:0'),\n",
       " 'EPO': tensor([ 0.0311, -0.0769, -0.0174,  ...,  0.0461, -0.0822, -0.0954],\n",
       "        device='cuda:0'),\n",
       " 'IL-18': tensor([ 0.0202,  0.0246, -0.0399,  ...,  0.0461, -0.0667, -0.0517],\n",
       "        device='cuda:0'),\n",
       " 'IFN-omega': tensor([ 0.1131, -0.0528, -0.0213,  ...,  0.0234, -0.1863, -0.1706],\n",
       "        device='cuda:0'),\n",
       " 'IGF-1': tensor([-0.0940, -0.0550,  0.0329,  ...,  0.0398, -0.1471, -0.1976],\n",
       "        device='cuda:0'),\n",
       " 'IFN-lambda3': tensor([ 0.0531, -0.1055, -0.0542,  ...,  0.0706, -0.1226, -0.1468],\n",
       "        device='cuda:0'),\n",
       " 'IL-17C': tensor([ 0.0057, -0.0944,  0.0220,  ...,  0.0240, -0.1571, -0.0573],\n",
       "        device='cuda:0'),\n",
       " 'IL-11': tensor([-0.0360, -0.1113, -0.0717,  ...,  0.0852, -0.0836, -0.1839],\n",
       "        device='cuda:0'),\n",
       " 'IFN-lambda2': tensor([ 0.0534, -0.1009, -0.0227,  ...,  0.0588, -0.1294, -0.1261],\n",
       "        device='cuda:0'),\n",
       " 'CT-1': tensor([ 0.0574, -0.0302, -0.0542,  ...,  0.0747, -0.0579, -0.1218],\n",
       "        device='cuda:0'),\n",
       " 'IL-17D': tensor([-0.0434, -0.1771, -0.0720,  ...,  0.1374, -0.1350, -0.1787],\n",
       "        device='cuda:0'),\n",
       " 'LIF': tensor([ 0.0441, -0.0467, -0.0212,  ...,  0.0463, -0.1073, -0.1094],\n",
       "        device='cuda:0'),\n",
       " 'LT-alpha': tensor([ 0.0745, -0.0705,  0.0080,  ...,  0.0224, -0.1317,  0.0010],\n",
       "        device='cuda:0'),\n",
       " 'IL-24': tensor([ 0.0548, -0.0183,  0.0724,  ...,  0.0116, -0.1519, -0.0730],\n",
       "        device='cuda:0'),\n",
       " 'IFN-epsilon': tensor([ 0.0904,  0.0024, -0.0159,  ...,  0.0167, -0.1739, -0.1014],\n",
       "        device='cuda:0'),\n",
       " 'GDNF': tensor([-0.0723, -0.1063,  0.0423,  ...,  0.0847, -0.1423, -0.1150],\n",
       "        device='cuda:0'),\n",
       " 'IL-6': tensor([ 0.0623, -0.0049, -0.0090,  ...,  0.0326, -0.1039, -0.0553],\n",
       "        device='cuda:0'),\n",
       " 'IL-12': tensor([ 0.0053, -0.0519,  0.0066,  ...,  0.0881, -0.0632, -0.0949],\n",
       "        device='cuda:0'),\n",
       " 'PRL': tensor([ 0.0555, -0.0232, -0.0052,  ...,  0.0155, -0.1245, -0.0620],\n",
       "        device='cuda:0'),\n",
       " 'EBI3': tensor([ 0.0234,  0.0882, -0.0236,  ...,  0.0354, -0.1308, -0.0185],\n",
       "        device='cuda:0'),\n",
       " 'Noggin': tensor([-0.0556, -0.0715,  0.0615,  ..., -0.0109, -0.0580, -0.0160],\n",
       "        device='cuda:0'),\n",
       " 'CD30L': tensor([-0.0126, -0.0642,  0.0829,  ...,  0.0320, -0.1353,  0.0282],\n",
       "        device='cuda:0'),\n",
       " 'IL-32-beta': tensor([ 0.0666, -0.1021,  0.0536,  ...,  0.0222, -0.1643, -0.0741],\n",
       "        device='cuda:0'),\n",
       " 'FLT3L': tensor([-0.0051, -0.1007, -0.0852,  ...,  0.0283, -0.1254, -0.2884],\n",
       "        device='cuda:0'),\n",
       " 'IL-34': tensor([ 0.0490, -0.0774, -0.0015,  ...,  0.0659, -0.1635, -0.0954],\n",
       "        device='cuda:0'),\n",
       " 'IL-27': tensor([ 0.0138, -0.0765, -0.0373,  ...,  0.0562, -0.1553, -0.1360],\n",
       "        device='cuda:0'),\n",
       " 'LT-beta': tensor([-0.0253, -0.1592,  0.0106,  ...,  0.0321, -0.0497, -0.1051],\n",
       "        device='cuda:0'),\n",
       " 'APRIL': tensor([-0.0052, -0.1099,  0.0185,  ...,  0.0395, -0.1636, -0.0574],\n",
       "        device='cuda:0'),\n",
       " 'TL1A': tensor([ 0.0498, -0.0710,  0.0730,  ..., -0.0380, -0.1494,  0.0269],\n",
       "        device='cuda:0'),\n",
       " 'OSM': tensor([ 0.0694, -0.0409, -0.0029,  ...,  0.0785, -0.1422, -0.1100],\n",
       "        device='cuda:0'),\n",
       " '4-1BBL': tensor([ 0.0664, -0.0894,  0.0326,  ...,  0.0099, -0.0871,  0.0154],\n",
       "        device='cuda:0'),\n",
       " 'CD40L': tensor([ 0.0318, -0.0625,  0.0326,  ...,  0.0866, -0.0841, -0.1083],\n",
       "        device='cuda:0'),\n",
       " 'IL-1-beta': tensor([-0.0483, -0.0287,  0.0512,  ..., -0.0166, -0.1667,  0.0411],\n",
       "        device='cuda:0'),\n",
       " 'IL-33': tensor([ 0.0137,  0.0530,  0.0747,  ..., -0.0367, -0.2489,  0.0397],\n",
       "        device='cuda:0'),\n",
       " 'IL-1-alpha': tensor([-0.0431,  0.0344,  0.0314,  ..., -0.0209, -0.1504,  0.0356],\n",
       "        device='cuda:0'),\n",
       " 'SCF': tensor([ 0.1042, -0.0228, -0.0180,  ...,  0.0447, -0.0966, -0.1099],\n",
       "        device='cuda:0'),\n",
       " 'FasL': tensor([-0.0130, -0.0312,  0.0451,  ...,  0.0699, -0.1303,  0.0298],\n",
       "        device='cuda:0'),\n",
       " 'TRAIL': tensor([ 0.0090, -0.0698,  0.0580,  ...,  0.0334, -0.0903, -0.0262],\n",
       "        device='cuda:0'),\n",
       " 'FGF-beta': tensor([-0.0164, -0.0973, -0.0221,  ..., -0.0779, -0.2601,  0.0812],\n",
       "        device='cuda:0'),\n",
       " 'RANKL': tensor([ 0.0138, -0.0198,  0.0556,  ...,  0.0179, -0.0590,  0.0024],\n",
       "        device='cuda:0'),\n",
       " 'C5a': tensor([ 0.0662, -0.0467,  0.0546,  ...,  0.0073, -0.1051,  0.0773],\n",
       "        device='cuda:0'),\n",
       " 'Decorin': tensor([-0.0546, -0.0197,  0.0693,  ..., -0.0201, -0.0875, -0.0093],\n",
       "        device='cuda:0'),\n",
       " 'VEGF': tensor([ 0.0185, -0.0823,  0.0220,  ..., -0.0181, -0.1723,  0.0285],\n",
       "        device='cuda:0'),\n",
       " 'IL-35': tensor([ 0.0056, -0.0473,  0.0008,  ...,  0.0680, -0.0487, -0.1020],\n",
       "        device='cuda:0'),\n",
       " 'C3a': tensor([ 0.0951, -0.0453,  0.0731,  ..., -0.0048, -0.0492,  0.0555],\n",
       "        device='cuda:0'),\n",
       " 'IFN-gamma': tensor([ 0.0032,  0.1170,  0.0290,  ...,  0.0352, -0.1302, -0.0181],\n",
       "        device='cuda:0'),\n",
       " 'IL-9': tensor([ 0.0405, -0.0105,  0.0349,  ...,  0.0168, -0.2516, -0.0316],\n",
       "        device='cuda:0'),\n",
       " 'M-CSF': tensor([-0.0157, -0.0748, -0.0703,  ...,  0.0715, -0.0889, -0.2366],\n",
       "        device='cuda:0'),\n",
       " 'IL-23': tensor([ 0.0509, -0.0093,  0.0362,  ..., -0.0398, -0.1601, -0.0679],\n",
       "        device='cuda:0'),\n",
       " 'LT-alpha2-beta1': tensor([-0.0589,  0.0464, -0.1065,  ..., -0.0729, -0.0724, -0.1957],\n",
       "        device='cuda:0'),\n",
       " 'LT-alpha1-beta2': tensor([ 0.0578, -0.0784,  0.0190,  ...,  0.0086, -0.1227,  0.0343],\n",
       "        device='cuda:0'),\n",
       " 'HGF': tensor([ 0.0039, -0.0511, -0.0334,  ...,  0.0537, -0.1092, -0.0305],\n",
       "        device='cuda:0'),\n",
       " 'IL-31': tensor([-0.0082,  0.1287,  0.0249,  ...,  0.0470, -0.2481, -0.0275],\n",
       "        device='cuda:0'),\n",
       " 'TNF-alpha': tensor([-0.0139,  0.0717,  0.1651,  ..., -0.0075, -0.0839, -0.0097],\n",
       "        device='cuda:0'),\n",
       " 'G-CSF': tensor([ 0.0465, -0.0395,  0.0049,  ...,  0.0284, -0.1351, -0.1185],\n",
       "        device='cuda:0'),\n",
       " 'TPO': tensor([ 0.0053, -0.0722,  0.0933,  ...,  0.0265, -0.0943, -0.0075],\n",
       "        device='cuda:0'),\n",
       " 'EGF': tensor([ 0.0360,  0.0168,  0.0863,  ...,  0.0182, -0.1783,  0.0246],\n",
       "        device='cuda:0'),\n",
       " 'IL-16': tensor([-0.0050, -0.0319,  0.0206,  ...,  0.0019, -0.1390,  0.0773],\n",
       "        device='cuda:0'),\n",
       " 'TGF-beta1': tensor([-0.0140,  0.0013,  0.0354,  ..., -0.0257, -0.1051, -0.0129],\n",
       "        device='cuda:0')}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86ef99a6-698b-4d33-94d6-536ea6a2b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embs = {}\n",
    "for cytokine, v in res[0].items():\n",
    "    embs[cytokine] = np.array(v.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c1cf28b-a37c-4097-9ecd-bc44a8dac2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_dict = {k: v.astype(\"float64\") for k,v in embs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e93d32df-873b-439c-9ed8-1fbeb807d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(out_dir, \"esm2_embeddings.pkl\"), \"wb\") as file:\n",
    "    pickle.dump(embs_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73100471-db3f-4e87-82fe-f10bb1a23933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm_cfp",
   "language": "python",
   "name": "esm_cfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
