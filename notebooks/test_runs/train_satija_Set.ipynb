{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c28ffc-5e0a-49a9-a10a-3f27b6f5a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gears import PertData, GEARS\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pickle\n",
    "import jax\n",
    "import jax.tree_util as jtu\n",
    "from scipy.sparse import csr_matrix\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import wandb\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "from ott.geometry import costs, pointcloud\n",
    "from ott.tools.sinkhorn_divergence import sinkhorn_divergence\n",
    "from sklearn.metrics import pairwise_distances, r2_score\n",
    "from sklearn.metrics.pairwise import rbf_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887f89c8-3a8a-443c-bb79-a4a2a3e23f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(cfg):\n",
    "    \"\"\"Initialize and return a Weights & Biases logger.\"\"\"\n",
    "    wandb.login()\n",
    "    return wandb.init(\n",
    "        project=cfg['dataset']['wandb_project'],\n",
    "        # config=OmegaConf.to_container(cfg, resolve=True), #TODO: uncomment omegaconf\n",
    "        dir=\"/home/icb/lea.zimmermann/projects/pertot/ot_pert_reproducibility/runs_gears/bash_scripts\",\n",
    "        settings=wandb.Settings(start_method=\"thread\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84042c4e-7310-48ed-b928-c1981181d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(x, y, var_names):\n",
    "    return x[:, [gene in y for gene in var_names]]\n",
    "\n",
    "\n",
    "def compute_r_squared(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    return r2_score(np.mean(x, axis=0), np.mean(y, axis=0))\n",
    "\n",
    "\n",
    "def compute_sinkhorn_div(x: np.ndarray, y: np.ndarray, epsilon: float) -> float:\n",
    "    return float(\n",
    "        sinkhorn_divergence(\n",
    "            pointcloud.PointCloud,\n",
    "            x=x,\n",
    "            y=y,\n",
    "            cost_fn=costs.SqEuclidean(),\n",
    "            epsilon=epsilon,\n",
    "            scale_cost=1.0,\n",
    "        ).divergence\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_e_distance(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    sigma_X = pairwise_distances(x, x, metric=\"sqeuclidean\").mean()\n",
    "    sigma_Y = pairwise_distances(y, y, metric=\"sqeuclidean\").mean()\n",
    "    delta = pairwise_distances(x, y, metric=\"sqeuclidean\").mean()\n",
    "    return 2 * delta - sigma_X - sigma_Y\n",
    "\n",
    "\n",
    "def compute_metrics(x: np.ndarray, y: np.ndarray) -> Dict[str, float]:\n",
    "    metrics = {}\n",
    "    metrics[\"r_squared\"] = compute_r_squared(x, y)\n",
    "    metrics[\"sinkhorn_div_1\"] = compute_sinkhorn_div(x, y, epsilon=1.0)\n",
    "    metrics[\"sinkhorn_div_10\"] = compute_sinkhorn_div(x, y, epsilon=10.0)\n",
    "    metrics[\"sinkhorn_div_100\"] = compute_sinkhorn_div(x, y, epsilon=100.0)\n",
    "    metrics[\"e_distance\"] = compute_e_distance(x, y)\n",
    "    metrics[\"mmd\"] = compute_scalar_mmd(x, y)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_mean_metrics(metrics: Dict[str, Dict[str, float]], prefix: str = \"\"):\n",
    "    metric_names = list(list(metrics.values())[0].keys())\n",
    "    metric_dict = {prefix + met_name: [] for met_name in metric_names}\n",
    "    for met in metric_names:\n",
    "        stat = 0.0\n",
    "        for vals in metrics.values():\n",
    "            stat += vals[met]\n",
    "        metric_dict[prefix + met] = stat / len(metrics)\n",
    "    return metric_dict\n",
    "\n",
    "\n",
    "def mmd_distance(x, y, gamma):\n",
    "    xx = rbf_kernel(x, x, gamma)\n",
    "    xy = rbf_kernel(x, y, gamma)\n",
    "    yy = rbf_kernel(y, y, gamma)\n",
    "\n",
    "    return xx.mean() + yy.mean() - 2 * xy.mean()\n",
    "\n",
    "\n",
    "def compute_scalar_mmd(target, transport, gammas=None):  # from CellOT repo\n",
    "    if gammas is None:\n",
    "        gammas = [2, 1, 0.5, 0.1, 0.01, 0.005]\n",
    "\n",
    "    def safe_mmd(*args):\n",
    "        try:\n",
    "            mmd = mmd_distance(*args)\n",
    "        except ValueError:\n",
    "            mmd = np.nan\n",
    "        return mmd\n",
    "\n",
    "    return np.mean(list(map(lambda x: safe_mmd(target, transport, x), gammas)))\n",
    "\n",
    "\n",
    "def compute_metrics_fast(x: np.ndarray, y: np.ndarray) -> Dict[str, float]:\n",
    "    metrics = {}\n",
    "    metrics[\"r_squared\"] = compute_r_squared(x, y)\n",
    "    metrics[\"e_distance\"] = compute_e_distance(x, y)\n",
    "    metrics[\"mmd_distance\"] = compute_scalar_mmd(x, y)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ef5e35-a220-4410-af77-ee3e2c1b6539",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'dataset': {\n",
    "        'dataset_path': '/lustre/groups/ml01/workspace/ot_perturbation/data/satija/datasets/r2',\n",
    "        'base_path': '/home/icb/lea.zimmermann/projects/pertot/gears/data/satija',\n",
    "        'train_data': '/home/icb/lea.zimmermann/projects/pertot/gears/data/satija/satija_ifng_bxpc3',\n",
    "        'split_data': '/home/icb/lea.zimmermann/projects/pertot/gears/data/satija/satija_ifng_bxpc3/custom_split.pkl',\n",
    "        'test_data': '/lustre/groups/ml01/workspace/ot_perturbation/data/satija/datasets/r2',\n",
    "        'pathway': 'IFNG',\n",
    "        'cell_type': 'BXPC3',\n",
    "        'obsm_key_data': 'X_pca',\n",
    "        'obsm_key_cond': 'cond_emb',\n",
    "        'wandb_project': 'gears_satija_test'\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 1024,\n",
    "        'valid_freq': 10,\n",
    "        'num_iterations': 10000,\n",
    "        'out_dir': '/lustre/groups/ml01/workspace/ot_perturbation/data/satija/datasets',\n",
    "        'n_train_samples': 0,\n",
    "        'n_test_samples': 10,\n",
    "        'n_ood_samples': -1,\n",
    "        'fast_metrics': True,\n",
    "        'learning_rate': 0.0001,\n",
    "        'weight_decay': 0.5\n",
    "    },\n",
    "    'model': {\n",
    "        'hidden_dims': [1024, 1024, 1024],\n",
    "        'time_dims': [512, 512],\n",
    "        'output_dims': [1024, 1024, 1024],\n",
    "        'condition_dims': [1024, 1024, 512],\n",
    "        'time_n_freqs': 1024,\n",
    "        'flow_noise': 0.1,\n",
    "        'multi_steps': 20,\n",
    "        'epsilon': 0.01,\n",
    "        'tau_a': 1.0,\n",
    "        'tau_b': 1.0,\n",
    "        'dropout_rate': 0.0\n",
    "    },\n",
    "    'conf': {\n",
    "        'run': {\n",
    "            'dir': 'checkpoint_dir'\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b3f38e-0736-4c64-ab77-0e8e9b0bf7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(adata, cfg, *, skip_cond, deg, return_dl: bool):\n",
    "    \"\"\"Loads data and preprocesses it based on configuration.\"\"\"\n",
    "    dls = []\n",
    "    data_source = {}\n",
    "    data_target = {}\n",
    "    data_source_decoded = {}\n",
    "    data_target_decoded = {}\n",
    "    data_conditions = {}\n",
    "    genes = []\n",
    "    for cond in adata.obs[\"condition\"].cat.categories:\n",
    "        if cond!= 'NT+ctrl' and cond not in skip_cond:\n",
    "            src_str_unique = list(adata[adata.obs[\"condition\"] == cond].obs[\"cell_type\"].unique())\n",
    "            assert len(src_str_unique) == 1\n",
    "            src_str = 'ctrl'\n",
    "            source = adata[adata.obs[\"condition\"] == src_str].obsm[cfg['dataset']['obsm_key_data']]\n",
    "            source_decoded = adata[adata.obs[\"condition\"] == src_str].X.A\n",
    "            target = adata[adata.obs[\"condition\"] == cond].obsm[cfg['dataset']['obsm_key_data']]\n",
    "            target_decoded = adata[adata.obs[\"condition\"] == cond].X.A\n",
    "            data_source[cond] = source\n",
    "            data_target[cond] = target\n",
    "            data_source_decoded[cond] = source_decoded\n",
    "            data_target_decoded[cond] = target_decoded\n",
    "            data_conditions[cond] = cond\n",
    "\n",
    "    deg_dict = {k: v for k, v in deg.items() if k in data_conditions.keys()}\n",
    "\n",
    "    return {\n",
    "        \"source\": data_source,\n",
    "        \"target\": data_target,\n",
    "        \"source_decoded\": data_source_decoded,\n",
    "        \"target_decoded\": data_target_decoded,\n",
    "        \"conditions\": data_conditions,\n",
    "        \"deg_dict\": deg_dict,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4c08ad7-197b-4372-8c1f-279e643e0cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_split_path = './data/satija/satija_ifng_bxpc3/custom_split.pkl'\n",
    "with open(custom_split_path, 'rb') as file:\n",
    "    custom_split_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79452fa1-18df-4c90-b6a4-cc3d06ea3cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Found local copy...\n",
      "These perturbations are not in the GO graph and their perturbation can thus not be predicted\n",
      "['RARRES3+ctrl' 'HLA-DQB1+ctrl' 'FMNL2+ctrl' 'PLEK+ctrl' 'SRC+ctrl'\n",
      " 'IFI16+ctrl']\n",
      "Local copy of pyg dataset is detected. Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "pert_data = PertData('./data/satija')\n",
    "pert_data.load(data_path = '/home/icb/lea.zimmermann/projects/pertot/gears/data/satija/satija_ifng_bxpc3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc7d4c29-c19a-4ce4-9b20-342806883286",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_not_in_GO_graph = ['RARRES3+ctrl','HLA-DQB1+ctrl','FMNL2+ctrl','PLEK+ctrl','SRC+ctrl', 'IFI16+ctrl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46a9de40-7e9b-4477-8163-1b64c6b81d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_split_dict['train'] = [gene for gene in custom_split_dict['train'] if gene not in genes_not_in_GO_graph]\n",
    "# custom_split_dict['test'] = [gene for gene in custom_split_dict['test'] if gene not in genes_not_in_GO_graph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "783a879d-de70-4f71-84a5-d001f64f3a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dataloaders....\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "pert_data.prepare_split(split = 'custom', split_dict_path=custom_split_path, seed = 1) # get data split with seed\n",
    "pert_data.get_dataloader(batch_size = 512, test_batch_size = 512) # prepare data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7bef0d6-e3c9-42bd-8188-e982c674d1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlea-zimmermann\u001b[0m (\u001b[33mmodality_translation\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/icb/lea.zimmermann/projects/pertot/ot_pert_reproducibility/runs_gears/bash_scripts/wandb/run-20240508_213211-1z50pg7z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/modality_translation/gears_satija_test/runs/1z50pg7z' target=\"_blank\">dainty-morning-2</a></strong> to <a href='https://wandb.ai/modality_translation/gears_satija_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/modality_translation/gears_satija_test' target=\"_blank\">https://wandb.ai/modality_translation/gears_satija_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/modality_translation/gears_satija_test/runs/1z50pg7z' target=\"_blank\">https://wandb.ai/modality_translation/gears_satija_test/runs/1z50pg7z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger = setup_logger(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bdfda2e-34b1-4237-af28-f6282fadc5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gears_model = GEARS(pert_data, device='cuda', \n",
    "                    weight_bias_track = True,\n",
    "                    wandb_logger=logger,\n",
    "                    proj_name = 'gears_test_satija', \n",
    "                    exp_name = 'gears_test_satija')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa4181a4-2b71-4770-ae06-ab9271a20834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    }
   ],
   "source": [
    "gears_model.model_initialize(hidden_size = 64)\n",
    "#gears_model.load_pretrained('test_model_final_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8449ffd-eb3b-490a-8cbf-2e93722c1987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_size': 'hidden dimension, default 64',\n",
       " 'num_go_gnn_layers': 'number of GNN layers for GO graph, default 1',\n",
       " 'num_gene_gnn_layers': 'number of GNN layers for co-expression gene graph, default 1',\n",
       " 'decoder_hidden_size': 'hidden dimension for gene-specific decoder, default 16',\n",
       " 'num_similar_genes_go_graph': 'number of maximum similar K genes in the GO graph, default 20',\n",
       " 'num_similar_genes_co_express_graph': 'number of maximum similar K genes in the co expression graph, default 20',\n",
       " 'coexpress_threshold': 'pearson correlation threshold when constructing coexpression graph, default 0.4',\n",
       " 'uncertainty': 'whether or not to turn on uncertainty mode, default False',\n",
       " 'uncertainty_reg': 'regularization term to balance uncertainty loss and prediction loss, default 1',\n",
       " 'direction_lambda': 'regularization term to balance direction loss and prediction loss, default 1'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gears_model.tunable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baf55f86-a8b4-468c-98d0-33293921c0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "Epoch 1 Step 1 Train Loss: 2.8046\n",
      "Epoch 1 Step 51 Train Loss: 2.7799\n",
      "Epoch 1: Train Overall MSE: 0.0030 Validation Overall MSE: 0.0018. \n",
      "Train Top 20 DE MSE: 0.1014 Validation Top 20 DE MSE: 0.0427. \n",
      "Done!\n",
      "Start Testing...\n",
      "Best performing model: Test Top 20 DE MSE: 0.1927\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    optimizer = optim.Adam(gears_model.model.parameters(), lr=cfg['training']['learning_rate'], weight_decay = cfg['training']['weight_decay'])\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "    gears_model.train(epochs = 1, lr = 1e-4, optimizer=optimizer, scheduler=scheduler)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70a56087-f13d-4ed3-a89a-e50a80a124e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gears_model.save_model('test_model_final_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c50a955-7e47-49de-bb64-eb04f922958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(cfg, model, data, log_metrics, comp_metrics_fn, mask_fn, PCs, train_mean):\n",
    "    for split, dat in data.items():\n",
    "        if split == \"test\":\n",
    "            n_samples = cfg['training']['n_test_samples']\n",
    "        if split == \"ood\":\n",
    "            n_samples = cfg['training']['n_ood_samples']\n",
    "\n",
    "        if n_samples != 0:\n",
    "            if n_samples > 0:\n",
    "                idcs = np.random.choice(list(list(dat.values())[0]), n_samples)\n",
    "                dat_conditions = {k: v for k, v in dat[\"conditions\"].items() if k in idcs}\n",
    "                dat_deg_dict = {k: v for k, v in dat[\"deg_dict\"].items() if k in idcs}\n",
    "                dat_target = {k: v for k, v in dat[\"target\"].items() if k in idcs}\n",
    "                dat_target_decoded = {k: v for k, v in dat[\"target_decoded\"].items() if k in idcs}\n",
    "            else:\n",
    "                dat_conditions = dat[\"conditions\"]\n",
    "                dat_deg_dict = dat[\"deg_dict\"]\n",
    "                dat_target = dat[\"target\"]\n",
    "                dat_target_decoded = dat[\"target_decoded\"]\n",
    "            \n",
    "            predictions = {}\n",
    "            predictions_pca = {}\n",
    "            for k, v in dat_target_decoded.items():\n",
    "                cond = dat_conditions[k]\n",
    "                gene = cond.split('+')[0]\n",
    "                samples = np.zeros((v.shape[0], v.shape[1]))\n",
    "                for i in range(samples.shape[0]):\n",
    "                    samples[i] = model.predict([[gene]])[gene]\n",
    "                predictions[k] = samples\n",
    "                samples_centered = csr_matrix(samples - train_mean)\n",
    "                predictions_pca[k] = np.matmul(samples_centered.A, PCs)\n",
    "\n",
    "            metrics = jtu.tree_map(comp_metrics_fn, dat_target, predictions_pca)\n",
    "            mean_metrics = compute_mean_metrics(metrics, prefix=f\"{split}_\")\n",
    "            log_metrics.update(mean_metrics)\n",
    "\n",
    "            metrics_decoded = jtu.tree_map(comp_metrics_fn, dat_target_decoded, predictions) # TODO: besser verstehen\n",
    "            mean_metrics_decoded = compute_mean_metrics(metrics_decoded, prefix=f\"decoded_{split}_\")\n",
    "            log_metrics.update(mean_metrics_decoded)\n",
    "\n",
    "            prediction_decoded_deg = jtu.tree_map(mask_fn, predictions, dat_deg_dict)\n",
    "            target_decoded_deg = jax.tree_util.tree_map(mask_fn, dat_target_decoded, dat_deg_dict)\n",
    "            metrics_deg = jtu.tree_map(comp_metrics_fn, target_decoded_deg, prediction_decoded_deg)\n",
    "            mean_metrics_deg = compute_mean_metrics(metrics_deg, prefix=f\"deg_{split}_\")\n",
    "            log_metrics.update(mean_metrics_deg)\n",
    "            wandb.log(log_metrics)\n",
    "    return log_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7fe25fc-d68e-4918-828f-7d535214af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway = 'IFNG'\n",
    "cell_type = 'BXPC3'\n",
    "data_path = cfg['dataset']['test_data']\n",
    "adata_train = sc.read_h5ad(os.path.join(data_path, \"adata_train_\" + pathway + \"_\" + cell_type + \".h5ad\"))\n",
    "train_mean = adata_train.varm[\"X_train_mean\"].T\n",
    "PCs = adata_train.varm[\"PCs\"]\n",
    "mask_fn = partial(get_mask, var_names=adata_train.var_names)\n",
    "adata_test = sc.read_h5ad(os.path.join(data_path, \"adata_test_\" + pathway + \"_\" + cell_type + \".h5ad\"))\n",
    "adata_test.obs['condition'] = adata_test.obs['condition'].apply(lambda x: x.split('_')[-1] + '+ctrl')\n",
    "adata_ood = sc.read_h5ad(os.path.join(data_path, \"adata_ood_\" + pathway + \"_\" + cell_type + \".h5ad\"))\n",
    "adata_ood.obs['condition'] = adata_ood.obs['condition'].apply(lambda x: x.split('_')[-1] + '+ctrl')\n",
    "\n",
    "deg = {k.split('_')[1]+'+ctrl': v  for k, v in adata_train.uns[\"rank_genes_groups_cov_all\"].items()}\n",
    "testset = load_data(adata_test, cfg, skip_cond=genes_not_in_GO_graph, deg=deg, return_dl=False)\n",
    "oodset = load_data(adata_ood, cfg, skip_cond=genes_not_in_GO_graph, deg=deg, return_dl=False)\n",
    "test_data = {\n",
    "    'test': testset,\n",
    "    'ood': oodset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f2199d8-25ac-40fd-900c-20bc15675622",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_conditions = oodset[\"conditions\"]\n",
    "dat_deg_dict = oodset[\"deg_dict\"]\n",
    "dat_target = oodset[\"target\"]\n",
    "dat_target_decoded = oodset[\"target_decoded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6fc297b-e0b1-4367-a2d7-c64ff62f5c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1762/1762 [01:57<00:00, 14.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3002/3002 [03:21<00:00, 14.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1055/1055 [01:10<00:00, 14.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1012/1012 [01:08<00:00, 14.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 396/396 [00:26<00:00, 15.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 418/418 [00:27<00:00, 15.12it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "predictions_pca = {}\n",
    "for k, v in dat_target_decoded.items():\n",
    "    cond = dat_conditions[k]\n",
    "    gene = cond.split('+')[0]\n",
    "    samples = np.zeros((v.shape[0], v.shape[1]))\n",
    "    for i in tqdm(range(samples.shape[0])):\n",
    "        samples[i] = gears_model.predict([[gene]])[gene]\n",
    "        gears_model.saved_pred = {}\n",
    "    predictions[k] = samples\n",
    "    samples_centered = csr_matrix(samples - train_mean)\n",
    "    predictions_pca[k] = np.matmul(samples_centered.A, PCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b6dd614-309a-4dcf-b32b-a811213702dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ATF5+ctrl': array([[ 1.02094603,  0.03732041,  0.24941753, ..., -0.01482642,\n",
       "          0.00944634, -0.00974088],\n",
       "        [ 0.99692935,  0.09204905,  0.29063824, ..., -0.01482642,\n",
       "          0.00944634, -0.00974088],\n",
       "        [ 0.93782216,  0.05852691,  0.2642433 , ..., -0.01482642,\n",
       "          0.00944634, -0.00974088],\n",
       "        ...,\n",
       "        [ 0.99005729,  0.05048174,  0.2993288 , ..., -0.01482642,\n",
       "          0.00944634, -0.00974088],\n",
       "        [ 1.01992083,  0.05399077,  0.31296879, ..., -0.01482642,\n",
       "          0.00944634, -0.00974088],\n",
       "        [ 1.04258752,  0.04126821,  0.26125166, ..., -0.01482642,\n",
       "          0.00944634, -0.00974088]]),\n",
       " 'EHF+ctrl': array([[ 1.06576431,  0.03177255,  0.21048012, ..., -0.01465773,\n",
       "          0.01149083, -0.0070027 ],\n",
       "        [ 1.02943575,  0.04352525,  0.24986631, ..., -0.01465773,\n",
       "          0.01149083, -0.0070027 ],\n",
       "        [ 1.04573739,  0.05694483,  0.26531848, ..., -0.01465773,\n",
       "          0.01149083, -0.0070027 ],\n",
       "        ...,\n",
       "        [ 1.12565029,  0.04671755,  0.28909826, ..., -0.01465773,\n",
       "          0.01149083, -0.0070027 ],\n",
       "        [ 1.04436636,  0.07124182,  0.31570068, ..., -0.01465773,\n",
       "          0.01149083, -0.0070027 ],\n",
       "        [ 0.99564272,  0.05784941,  0.32231385, ..., -0.01465773,\n",
       "          0.01149083, -0.0070027 ]]),\n",
       " 'IRF7+ctrl': array([[ 1.04474568,  0.08306471,  0.24859482, ..., -0.01469756,\n",
       "          0.01086734, -0.01006898],\n",
       "        [ 1.05299938,  0.05703056,  0.33368865, ..., -0.01469756,\n",
       "          0.01086734, -0.01006898],\n",
       "        [ 1.03817165,  0.06018695,  0.26600933, ..., -0.01469757,\n",
       "          0.01086734, -0.01006898],\n",
       "        ...,\n",
       "        [ 0.97245848,  0.06838032,  0.2922146 , ..., -0.01469756,\n",
       "          0.01086734, -0.01006898],\n",
       "        [ 1.08287239,  0.09602375,  0.23282303, ..., -0.01469756,\n",
       "          0.01086734, -0.01006898],\n",
       "        [ 1.09693384,  0.07547832,  0.23834859, ..., -0.01469756,\n",
       "          0.01086734, -0.01006898]]),\n",
       " 'MAFB+ctrl': array([[ 1.10514188,  0.05406768,  0.26937303, ..., -0.0173724 ,\n",
       "          0.01306726, -0.01203771],\n",
       "        [ 0.99856037,  0.04231181,  0.19940017, ..., -0.0173724 ,\n",
       "          0.01306726, -0.01203768],\n",
       "        [ 1.05202472,  0.04319406,  0.2079265 , ..., -0.0173724 ,\n",
       "          0.01306726, -0.01203768],\n",
       "        ...,\n",
       "        [ 0.98574066,  0.02554596,  0.31610516, ..., -0.0173724 ,\n",
       "          0.01306726, -0.01203768],\n",
       "        [ 1.06502438,  0.05102757,  0.26658866, ..., -0.0173724 ,\n",
       "          0.01306726, -0.01203771],\n",
       "        [ 0.9595924 ,  0.06057548,  0.24159963, ..., -0.0173724 ,\n",
       "          0.01306726, -0.01203771]]),\n",
       " 'STAT1+ctrl': array([[ 0.99279886,  0.09589256,  0.24339762, ..., -0.01825696,\n",
       "          0.01322671, -0.01510843],\n",
       "        [ 0.95571381,  0.03382102,  0.30597255, ..., -0.01825696,\n",
       "          0.01322671, -0.01510843],\n",
       "        [ 1.09319341,  0.04957181,  0.24381994, ..., -0.01825696,\n",
       "          0.01322671, -0.01510843],\n",
       "        ...,\n",
       "        [ 1.13638532,  0.02793457,  0.2937662 , ..., -0.01825696,\n",
       "          0.01322671, -0.01510843],\n",
       "        [ 1.23282647,  0.07726763,  0.29015586, ..., -0.01825696,\n",
       "          0.01322671, -0.01510844],\n",
       "        [ 1.08670306,  0.0690258 ,  0.26506811, ..., -0.01825696,\n",
       "          0.01322671, -0.01510843]]),\n",
       " 'TRAFD1+ctrl': array([[ 1.07290697,  0.04041601,  0.24462909, ..., -0.02529779,\n",
       "          0.01073192, -0.01449494],\n",
       "        [ 0.93808764,  0.07818519,  0.30693135, ..., -0.02529779,\n",
       "          0.01073192, -0.01449494],\n",
       "        [ 0.94795442,  0.05046519,  0.319271  , ..., -0.02529779,\n",
       "          0.01073192, -0.01449494],\n",
       "        ...,\n",
       "        [ 0.97154981,  0.05917688,  0.21653226, ..., -0.02529779,\n",
       "          0.01073192, -0.01449495],\n",
       "        [ 1.16011095,  0.05063763,  0.24727167, ..., -0.02529779,\n",
       "          0.01073192, -0.01449494],\n",
       "        [ 0.97255993,  0.06309941,  0.21672015, ..., -0.02529779,\n",
       "          0.01073192, -0.01449494]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87faf08b-ad2e-4e06-b424-3987fbb48630",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_metrics_fn = compute_metrics_fast if cfg['training']['fast_metrics'] == True else compute_metrics\n",
    "logger = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d81d968f-752d-45e8-a136-c5a1dfc2993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction keys:  dict_keys(['ATF3+ctrl', 'CEBPE+ctrl', 'ETV7+ctrl', 'IFNGR1+ctrl', 'IFNGR2+ctrl', 'IRF9+ctrl', 'JUN+ctrl', 'PRDM1+ctrl', 'STAT3+ctrl'])\n",
      "dict_keys(['ATF3+ctrl', 'CEBPE+ctrl', 'ETV7+ctrl', 'IFNGR1+ctrl', 'IFNGR2+ctrl', 'IRF9+ctrl', 'JUN+ctrl', 'PRDM1+ctrl', 'STAT3+ctrl'])\n",
      "prediction keys:  dict_keys(['ATF5+ctrl', 'EHF+ctrl', 'IRF7+ctrl', 'MAFB+ctrl', 'STAT1+ctrl', 'TRAFD1+ctrl'])\n",
      "dict_keys(['ATF5+ctrl', 'EHF+ctrl', 'IRF7+ctrl', 'MAFB+ctrl', 'STAT1+ctrl', 'TRAFD1+ctrl'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_r_squared': -0.13263206607339656,\n",
       " 'test_e_distance': 9.333805714100865,\n",
       " 'test_mmd_distance': 0.7411452757046997,\n",
       " 'decoded_test_r_squared': 0.9564043227957176,\n",
       " 'decoded_test_e_distance': 20.553277096523377,\n",
       " 'decoded_test_mmd_distance': 0.9352270529716594,\n",
       " 'deg_test_r_squared': 0.711557366690024,\n",
       " 'deg_test_e_distance': 7.38784069975603,\n",
       " 'deg_test_mmd_distance': 0.6890335084127872,\n",
       " 'ood_r_squared': -1.3054404151460541,\n",
       " 'ood_e_distance': 11.966043398017737,\n",
       " 'ood_mmd_distance': 0.7372170868247233,\n",
       " 'decoded_ood_r_squared': 0.9585772880291242,\n",
       " 'decoded_ood_e_distance': 19.234332002478236,\n",
       " 'decoded_ood_mmd_distance': 0.926436611801701,\n",
       " 'deg_ood_r_squared': 0.5104898641044103,\n",
       " 'deg_ood_e_distance': 10.102668101192448,\n",
       " 'deg_ood_mmd_distance': 0.6970982322128306}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_step(cfg, gears_model, test_data, logger, compute_metrics_fast, mask_fn, PCs, train_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b2f42-1dde-4035-99b5-67969d9e5819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gears",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
