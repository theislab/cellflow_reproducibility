{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e761b2ce-9f52-4aff-ba9e-93048c063928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import wandb\n",
    "from ott.neural import datasets\n",
    "import sys\n",
    "from omegaconf import DictConfig\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from typing import Optional, Literal\n",
    "import jax\n",
    "import pathlib\n",
    "import optax\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from flax import linen as nn\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from flax.training import train_state\n",
    "\n",
    "from ott.neural.networks.layers import time_encoder\n",
    "from ott.neural.methods.flows import dynamics, otfm\n",
    "from ott.neural.networks import velocity_field\n",
    "from ott.solvers import utils as solver_utils\n",
    "import jax.tree_util as jtu\n",
    "from ott.neural.networks.layers import time_encoder\n",
    "from ott.neural.networks.velocity_field import VelocityField\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "import scanpy as sc\n",
    "from ot_pert.metrics import compute_metrics_fast, compute_mean_metrics\n",
    "from ot_pert.nets.nets import VelocityFieldWithAttention\n",
    "from ot_pert.utils import ConditionalLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74575f53-0f9e-4c99-b2a8-967ec3143352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_data(embedding: np.ndarray, projection_matrix: np.ndarray, mean_to_add: np.ndarray) -> np.ndarray:\n",
    "    return np.matmul(embedding, projection_matrix.T) + mean_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e7d7477-ca40-49dd-b84c-6f6b67f71706",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsm_key_cond = \"ecfp_dose_cell_line\"\n",
    "obsm_key_data = \"X_pca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80093da-403e-4a3e-8a39-afc0b8d66467",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train_path = \"/lustre/groups/ml01/workspace/ot_perturbation/data/sciplex/adata_train_30.h5ad\"\n",
    "adata_test_path = \"/lustre/groups/ml01/workspace/ot_perturbation/data/sciplex/adata_test_30.h5ad\"\n",
    "adata_ood_path = \"/lustre/groups/ml01/workspace/ot_perturbation/data/sciplex/adata_ood_30.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab46905-01b3-42e4-a2a1-ed7baa0b8344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/dominik.klein/mambaforge/envs/ot_pert_genot/lib/python3.12/site-packages/anndata/__init__.py:51: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n",
      "/home/icb/dominik.klein/mambaforge/envs/ot_pert_genot/lib/python3.12/site-packages/anndata/__init__.py:51: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n",
      "/home/icb/dominik.klein/mambaforge/envs/ot_pert_genot/lib/python3.12/site-packages/anndata/__init__.py:51: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "adata_train = sc.read(adata_train_path)\n",
    "adata_test = sc.read(adata_test_path)\n",
    "adata_ood = sc.read(adata_ood_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9fda51-88db-44f2-b359-eb538622de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.subsample(adata_train, fraction=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b701de-8c48-4880-b85d-cc667475d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train.obsm[\"ecfp_dose\"] = np.concatenate(\n",
    "    (adata_train.obsm[\"ecfp\"], np.asarray(adata_train.obs[\"dose\"])[:, None]), axis=1\n",
    ")\n",
    "adata_test.obsm[\"ecfp_dose\"] = np.concatenate(\n",
    "    (adata_test.obsm[\"ecfp\"], np.asarray(adata_test.obs[\"dose\"])[:, None]), axis=1\n",
    ")\n",
    "adata_ood.obsm[\"ecfp_dose\"] = np.concatenate(\n",
    "    (adata_ood.obsm[\"ecfp\"], np.asarray(adata_ood.obs[\"dose\"])[:, None]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2342c0bc-9552-4c62-9fda-87af01ce07cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train.obsm[\"ecfp_dose_cell_line\"] = np.concatenate(\n",
    "    (adata_train.obsm[\"ecfp_dose\"], adata_train.obsm[\"cell_line_emb\"]), axis=1\n",
    ")\n",
    "adata_test.obsm[\"ecfp_dose_cell_line\"] = np.concatenate(\n",
    "    (adata_test.obsm[\"ecfp_dose\"], adata_test.obsm[\"cell_line_emb\"]), axis=1\n",
    ")\n",
    "adata_ood.obsm[\"ecfp_dose_cell_line\"] = np.concatenate(\n",
    "    (adata_ood.obsm[\"ecfp_dose\"], adata_ood.obsm[\"cell_line_emb\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e81c5a24-8ae5-495c-bf39-588a5600bbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 09:23:45.391035: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.3 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "def data_match_fn(\n",
    "    src_lin: Optional[jnp.ndarray], tgt_lin: Optional[jnp.ndarray],\n",
    "    src_quad: Optional[jnp.ndarray], tgt_quad: Optional[jnp.ndarray], *,\n",
    "    typ: Literal[\"lin\", \"quad\", \"fused\"], epsilon: float = 1e-2, tau_a: float = 1.0,\n",
    "    tau_b: float = 1.0,\n",
    ") -> jnp.ndarray:\n",
    "    if typ == \"lin\":\n",
    "        return solver_utils.match_linear(x=src_lin, y=tgt_lin, scale_cost=\"mean\", epsilon=epsilon, tau_a=tau_a, tau_b=tau_b)\n",
    "    if typ == \"quad\":\n",
    "        return solver_utils.match_quadratic(xx=src_quad, yy=tgt_quad)\n",
    "    if typ == \"fused\":\n",
    "        return solver_utils.match_quadratic(\n",
    "            xx=src_quad, yy=tgt_quad, x=src_lin, y=tgt_lin\n",
    "        )\n",
    "    raise NotImplementedError(f\"Unknown type: {typ}.\")\n",
    "\n",
    "# Load data\n",
    "\n",
    "dls = []\n",
    "\n",
    "train_data_source = {}\n",
    "train_data_target = {}\n",
    "train_data_source_decoded = {}\n",
    "train_data_target_decoded = {}\n",
    "train_data_conditions = {}\n",
    "\n",
    "\n",
    "for cond in adata_train.obs[\"condition\"].cat.categories:\n",
    "    if \"Vehicle\" in cond:\n",
    "        continue\n",
    "    src_str = list(adata_train[adata_train.obs[\"condition\"]==cond].obs[\"cell_type\"].unique())\n",
    "    assert len(src_str) == 1\n",
    "    source = adata_train[adata_train.obs[\"condition\"]==src_str[0]+\"_Vehicle_0.0\"].obsm[obsm_key_data]\n",
    "    source_decoded = adata_train[adata_train.obs[\"condition\"]==src_str[0]+\"_Vehicle_0.0\"].X.A\n",
    "    target = adata_train[adata_train.obs[\"condition\"]==cond].obsm[obsm_key_data]\n",
    "    target_decoded = adata_train[adata_train.obs[\"condition\"]==cond].X.A\n",
    "    conds = adata_train[adata_train.obs[\"condition\"]==cond].obsm[obsm_key_cond]\n",
    "    assert np.all(np.all(conds == conds[0], axis=1))\n",
    "    conds = np.tile(conds[0], (len(source), 1))\n",
    "    dls.append(DataLoader(datasets.OTDataset(datasets.OTData(\n",
    "        lin=source,\n",
    "        condition=conds,\n",
    "    ), datasets.OTData(lin=target)), batch_size=10, shuffle=True))\n",
    "    train_data_source[cond] = source\n",
    "    train_data_target[cond] = target\n",
    "    train_data_conditions[cond] = conds\n",
    "    train_data_source_decoded[cond] = source_decoded\n",
    "    train_data_target_decoded[cond] = target_decoded\n",
    "\n",
    "train_loader = ConditionalLoader(dls, seed=0)\n",
    "\n",
    "test_data_source = {}\n",
    "test_data_target = {}\n",
    "test_data_source_decoded = {}\n",
    "test_data_target_decoded = {}\n",
    "test_data_conditions = {}\n",
    "\n",
    "for cond in adata_test.obs[\"condition\"].cat.categories:\n",
    "    if \"Vehicle\" in cond:\n",
    "        continue\n",
    "    src_str = list(adata_test[adata_test.obs[\"condition\"]==cond].obs[\"cell_type\"].unique())\n",
    "    assert len(src_str) == 1\n",
    "    source = adata_test[adata_test.obs[\"condition\"]==src_str[0]+\"_Vehicle_0.0\"].obsm[obsm_key_data]\n",
    "    source_decoded = adata_test[adata_test.obs[\"condition\"]==src_str[0]+\"_Vehicle_0.0\"].X.A\n",
    "    \n",
    "    target = adata_test[adata_test.obs[\"condition\"]==cond].obsm[obsm_key_data]\n",
    "    target_decoded = adata_test[adata_test.obs[\"condition\"]==cond].X.A\n",
    "    \n",
    "        \n",
    "    conds = adata_test[adata_test.obs[\"condition\"]==cond].obsm[obsm_key_cond]\n",
    "    assert np.all(np.all(conds == conds[0], axis=1))\n",
    "    conds = np.tile(conds[0], (len(source), 1))\n",
    "    test_data_source[cond] = source\n",
    "    test_data_target[cond] = target\n",
    "    test_data_source_decoded[cond] = source_decoded\n",
    "    test_data_target_decoded[cond] = target_decoded\n",
    "    test_data_conditions[cond] = conds\n",
    "\n",
    "ood_data_source = {}\n",
    "ood_data_target = {}\n",
    "ood_data_source_decoded = {}\n",
    "ood_data_target_decoded = {}\n",
    "ood_data_conditions = {}\n",
    "\n",
    "for cond in adata_ood.obs[\"condition\"].cat.categories:\n",
    "    if \"Vehicle\" in cond:\n",
    "        continue\n",
    "    src_str = list(adata_ood[adata_ood.obs[\"condition\"]==cond].obs[\"cell_type\"].unique())\n",
    "    assert len(src_str) == 1\n",
    "    source = adata_ood[adata_ood.obs[\"condition\"]==src_str[0]+\"_Vehicle_0.0\"].obsm[obsm_key_data]\n",
    "    source_decoded = adata_ood[adata_ood.obs[\"condition\"]==src_str[0]+\"_Vehicle_0.0\"].X.A\n",
    "    target = adata_ood[adata_ood.obs[\"condition\"]==cond].obsm[obsm_key_data]\n",
    "    target_decoded = adata_ood[adata_ood.obs[\"condition\"]==cond].X.A\n",
    "    conds = adata_ood[adata_ood.obs[\"condition\"]==cond].obsm[obsm_key_cond]\n",
    "    assert np.all(np.all(conds == conds[0], axis=1))\n",
    "    conds = np.tile(conds[0], (len(source), 1))\n",
    "    ood_data_source[cond] = source\n",
    "    ood_data_target[cond] = target\n",
    "    ood_data_source_decoded[cond] = source_decoded\n",
    "    ood_data_target_decoded[cond] = target_decoded\n",
    "    ood_data_conditions[cond] = conds\n",
    "\n",
    "reconstruct_data_fn = functools.partial(reconstruct_data, projection_matrix=adata_train.varm[\"PCs\"], mean_to_add=adata_train.varm[\"X_train_mean\"].T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4e3ec12-c0cd-4b18-8a05-c06d531dde9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_data_fn = functools.partial(reconstruct_data, projection_matrix=adata_train.varm[\"PCs\"], mean_to_add=adata_train.varm[\"X_train_mean\"].T)\n",
    "\n",
    "train_deg_dict = {k: v for k,v in adata_train.uns['rank_genes_groups_cov_all'].items() if k in train_data_conditions.keys()}\n",
    "test_deg_dict = {k: v for k,v in adata_train.uns['rank_genes_groups_cov_all'].items() if k in test_data_conditions.keys()}\n",
    "ood_deg_dict = {k: v for k,v in adata_train.uns['rank_genes_groups_cov_all'].items() if k in ood_data_conditions.keys()}\n",
    "\n",
    "def get_mask(x, y):\n",
    "    return x[:, [gene in y for gene in adata_train.var_names]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86e0193b-e615-47ba-a26e-8115ea641ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dim = source.shape[1]\n",
    "target_dim = source_dim\n",
    "condition_dim = conds.shape[1]\n",
    "\n",
    "source_dim = source.shape[1]\n",
    "target_dim = source_dim\n",
    "condition_dim = conds.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad838285-5aaa-45b4-abdc-56301ac404e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Sequence\n",
    "\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from flax import linen as nn\n",
    "\n",
    "from ott.neural.networks.layers import time_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f164dda3-7388-4045-af38-c361721a5e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VelocityFieldNew(nn.Module):\n",
    "  hidden_dims: Sequence[int]\n",
    "  output_dims: Sequence[int]\n",
    "  condition_dims: Optional[Sequence[int]] = None\n",
    "  time_dims: Optional[Sequence[int]] = None\n",
    "  time_encoder: Callable[[jnp.ndarray],\n",
    "                         jnp.ndarray] = time_encoder.cyclical_time_encoder\n",
    "  act_fn: Callable[[jnp.ndarray], jnp.ndarray] = nn.silu\n",
    "  dropout_rate: float = 0.0\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(\n",
    "      self,\n",
    "      t: jnp.ndarray,\n",
    "      x: jnp.ndarray,\n",
    "      condition: Optional[jnp.ndarray] = None,\n",
    "      deterministic: bool = False\n",
    "  ) -> jnp.ndarray:\n",
    "    \"\"\"Forward pass through the neural vector field.\n",
    "\n",
    "        Args:\n",
    "          t: Time of shape ``[batch, 1]``.\n",
    "          x: Data of shape ``[batch, ...]``.\n",
    "          condition: Conditioning vector of shape ``[batch, ...]``.\n",
    "          deterministic: If `True`, disables dropout for inference.\n",
    "\n",
    "        Returns:\n",
    "          Output of the neural vector field of shape ``[batch, output_dim]``.\n",
    "        \"\"\"\n",
    "    time_dims = self.hidden_dims if self.time_dims is None else self.time_dims\n",
    "\n",
    "    t = self.time_encoder(t)\n",
    "    for time_dim in time_dims:\n",
    "      t = self.act_fn(nn.Dense(time_dim)(t))\n",
    "      t = nn.Dropout(rate=self.dropout_rate, deterministic=deterministic)(t)\n",
    "\n",
    "    for hidden_dim in self.hidden_dims:\n",
    "      x = self.act_fn(nn.Dense(hidden_dim)(x))\n",
    "      x = nn.Dropout(rate=self.dropout_rate, deterministic=deterministic)(x)\n",
    "\n",
    "    if self.condition_dims is not None:\n",
    "      assert condition is not None, \"No condition was passed.\"\n",
    "      for cond_dim in self.condition_dims:\n",
    "        condition = self.act_fn(nn.Dense(cond_dim)(condition))\n",
    "        condition = nn.Dropout(\n",
    "            rate=self.dropout_rate, deterministic=deterministic\n",
    "        )(\n",
    "            condition\n",
    "        )\n",
    "      feats = jnp.concatenate([t, x, condition], axis=-1)\n",
    "    else:\n",
    "      feats = jnp.concatenate([t, x], axis=-1)\n",
    "\n",
    "    for output_dim in self.output_dims[:-1]:\n",
    "      feats = self.act_fn(nn.Dense(output_dim)(feats))\n",
    "      feats = nn.Dropout(\n",
    "          rate=self.dropout_rate, deterministic=deterministic\n",
    "      )(\n",
    "          feats\n",
    "      )\n",
    "\n",
    "    # No activation function for the final layer\n",
    "    return nn.Dense(self.output_dims[-1])(feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "318c0f30-741f-4c43-b91d-9faee6132676",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\"VelocityFieldNew\" object has no attribute \"create_train_state\". If \"create_train_state\" is defined in '.setup()', remember these fields are only accessible from inside 'init' or 'apply'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m vf \u001b[38;5;241m=\u001b[39m VelocityFieldNew(\n\u001b[1;32m      2\u001b[0m     hidden_dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m1024\u001b[39m],\n\u001b[1;32m      3\u001b[0m     time_dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m512\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m otfm\u001b[38;5;241m.\u001b[39mOTFlowMatching(vf,\n\u001b[1;32m     11\u001b[0m     flow\u001b[38;5;241m=\u001b[39mdynamics\u001b[38;5;241m.\u001b[39mConstantNoiseFlow(\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     12\u001b[0m     match_fn\u001b[38;5;241m=\u001b[39mjax\u001b[38;5;241m.\u001b[39mjit(functools\u001b[38;5;241m.\u001b[39mpartial(data_match_fn, typ\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlin\u001b[39m\u001b[38;5;124m\"\u001b[39m, src_quad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tgt_quad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, tau_a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, tau_b\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)),\n\u001b[1;32m     13\u001b[0m     condition_dim\u001b[38;5;241m=\u001b[39mcondition_dim,\n\u001b[1;32m     14\u001b[0m     rng\u001b[38;5;241m=\u001b[39mjax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m13\u001b[39m),\n\u001b[1;32m     15\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptax\u001b[38;5;241m.\u001b[39mMultiSteps(optax\u001b[38;5;241m.\u001b[39madam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m), \u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n",
      "File \u001b[0;32m~/mambaforge/envs/ot_pert_genot/lib/python3.12/site-packages/ott/neural/methods/flows/otfm.py:62\u001b[0m, in \u001b[0;36mOTFlowMatching.__init__\u001b[0;34m(self, vf, flow, match_fn, time_sampler, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_sampler \u001b[38;5;241m=\u001b[39m time_sampler\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch_fn \u001b[38;5;241m=\u001b[39m match_fn\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf\u001b[38;5;241m.\u001b[39mcreate_train_state(\n\u001b[1;32m     63\u001b[0m     input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf\u001b[38;5;241m.\u001b[39moutput_dims[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_step_fn()\n",
      "File \u001b[0;32m~/mambaforge/envs/ot_pert_genot/lib/python3.12/site-packages/flax/linen/module.py:1317\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m   msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m If \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is defined in \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m.setup()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m, remember these fields \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare only accessible from inside \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1316\u001b[0m   )\n\u001b[0;32m-> 1317\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[0;31mAttributeError\u001b[0m: \"VelocityFieldNew\" object has no attribute \"create_train_state\". If \"create_train_state\" is defined in '.setup()', remember these fields are only accessible from inside 'init' or 'apply'."
     ]
    }
   ],
   "source": [
    "vf = VelocityFieldNew(\n",
    "    hidden_dims=[1024, 1024, 1024],\n",
    "    time_dims=[512,512],\n",
    "    output_dims=[1024, 1024, 1024]+[target_dim],\n",
    "    condition_dims=[2048, 2048],\n",
    "    time_encoder = functools.partial(time_encoder.cyclical_time_encoder, n_freqs=1024),\n",
    "    dropout_rate=0.2\n",
    "    )\n",
    "\n",
    "model = otfm.OTFlowMatching(vf,\n",
    "    flow=dynamics.ConstantNoiseFlow(0),\n",
    "    match_fn=jax.jit(functools.partial(data_match_fn, typ=\"lin\", src_quad=None, tgt_quad=None, epsilon=0.1, tau_a=1.0, tau_b=1.0)),\n",
    "    condition_dim=condition_dim,\n",
    "    rng=jax.random.PRNGKey(13),\n",
    "    optimizer=optax.MultiSteps(optax.adam(learning_rate=1e-4), 20)\n",
    ")\n",
    "\n",
    "training_logs = {\"loss\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df472524-4a2a-496b-9169-6d1f5eafb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "for it in tqdm(range(1000)):\n",
    "    rng, rng_resample, rng_step_fn = jax.random.split(rng, 3)\n",
    "    batch = next(train_loader)\n",
    "    batch = jtu.tree_map(jnp.asarray, batch)\n",
    "\n",
    "    src, tgt = batch[\"src_lin\"], batch[\"tgt_lin\"]\n",
    "    src_cond = batch.get(\"src_condition\")\n",
    "\n",
    "    if model.match_fn is not None:\n",
    "        tmat = model.match_fn(src, tgt)\n",
    "        src_ixs, tgt_ixs = solver_utils.sample_joint(rng_resample, tmat)\n",
    "        src, tgt = src[src_ixs], tgt[tgt_ixs]\n",
    "        src_cond = None if src_cond is None else src_cond[src_ixs]\n",
    "\n",
    "    model.vf_state, loss = model.step_fn(\n",
    "        rng_step_fn,\n",
    "        model.vf_state,\n",
    "        src,\n",
    "        tgt,\n",
    "        src_cond,\n",
    "    )\n",
    "\n",
    "    training_logs[\"loss\"].append(float(loss))\n",
    "    if (it % 100000 == 0) and (it > 0):\n",
    "        idcs = np.random.choice(list(test_data_source.keys()), 20)\n",
    "        test_data_source_tmp = {k:v for k,v in test_data_source.items() if k in idcs}\n",
    "        test_data_target_tmp = {k:v for k,v in test_data_target.items() if k in idcs}\n",
    "        test_data_conditions_tmp = {k:v for k,v in test_data_conditions.items() if k in idcs}\n",
    "        test_data_target_decoded_tmp = {k:v for k,v in test_data_target_decoded.items() if k in idcs}\n",
    "        test_deg_dict_tmp = {k:v for k,v in test_deg_dict.items() if k in idcs}\n",
    "        valid_losses = []\n",
    "        #for cond in test_data_source_tmp.keys():\n",
    "        #    src = test_data_source_tmp[cond]\n",
    "        #    tgt = test_data_target_tmp[cond]\n",
    "        #    src_cond = test_data_conditions_tmp[cond]\n",
    "        #    if model.match_fn is not None:\n",
    "        #        tmat = model.match_fn(src, tgt)\n",
    "        #        src_ixs, tgt_ixs = solver_utils.sample_joint(rng_resample, tmat)\n",
    "        #        src, tgt = src[src_ixs], tgt[tgt_ixs]\n",
    "        #        src_cond = None if src_cond is None else src_cond[src_ixs]\n",
    "        #    _, valid_loss = model.step_fn(\n",
    "        #        rng,\n",
    "        #        model.vf_state,\n",
    "        #        src,\n",
    "        #        tgt,\n",
    "        #        src_cond,\n",
    "        #    )\n",
    "        #    valid_losses.append(valid_loss)\n",
    "\n",
    "        # predicted_target_train = jax.tree_util.tree_map(model.transport, train_data_source, train_data_conditions)\n",
    "        # train_metrics = jax.tree_util.tree_map(compute_metrics_fast, train_data_target, predicted_target_train)\n",
    "        # mean_train_metrics = compute_mean_metrics(train_metrics, prefix=\"train_\")\n",
    "\n",
    "        # predicted_target_train_decoded = jax.tree_util.tree_map(reconstruct_data_fn, predicted_target_train)\n",
    "        # train_metrics_decoded = jax.tree_util.tree_map(compute_metrics_fast, train_data_target_decoded, predicted_target_train_decoded)\n",
    "        # mean_train_metrics_decoded = compute_mean_metrics(train_metrics_decoded, prefix=\"decoded_train_\")\n",
    "\n",
    "        # train_deg_target_decoded_predicted = jax.tree_util.tree_map(get_mask, predicted_target_train_decoded, train_deg_dict)\n",
    "        # train_deg_target_decoded = jax.tree_util.tree_map(get_mask, train_data_target_decoded, test_deg_dict)\n",
    "\n",
    "        predicted_target_test = jax.tree_util.tree_map(model.transport, test_data_source_tmp, test_data_conditions_tmp)\n",
    "        #test_metrics = jax.tree_util.tree_map(compute_metrics_fast, test_data_target_tmp, predicted_target_test)\n",
    "        #mean_test_metrics = compute_mean_metrics(test_metrics, prefix=\"test_\")\n",
    "\n",
    "        predicted_target_test_decoded = jax.tree_util.tree_map(reconstruct_data_fn, predicted_target_test)\n",
    "        test_metrics_decoded = jax.tree_util.tree_map(\n",
    "            compute_metrics_fast, test_data_target_decoded_tmp, predicted_target_test_decoded\n",
    "        )\n",
    "        mean_test_metrics_decoded = compute_mean_metrics(test_metrics_decoded, prefix=\"decoded_test_\")\n",
    "\n",
    "        \n",
    "        #test_deg_target_decoded_predicted = jax.tree_util.tree_map(\n",
    "        #    get_mask, predicted_target_test_decoded, test_deg_dict_tmp\n",
    "        #)\n",
    "        #test_deg_target_decoded = jax.tree_util.tree_map(get_mask, test_data_target_decoded_tmp, test_deg_dict_tmp)\n",
    "        #deg_test_metrics_encoded = jax.tree_util.tree_map(\n",
    "        #    compute_metrics_fast, test_deg_target_decoded, test_deg_target_decoded_predicted\n",
    "        #)\n",
    "        #deg_mean_test_metrics_encoded = compute_mean_metrics(deg_test_metrics_encoded, prefix=\"deg_test_\")\n",
    "\n",
    "        predicted_target_ood = jax.tree_util.tree_map(model.transport, ood_data_source, ood_data_conditions)\n",
    "        ood_metrics = jax.tree_util.tree_map(compute_metrics_fast, ood_data_target, predicted_target_ood)\n",
    "        mean_ood_metrics = compute_mean_metrics(ood_metrics, prefix=\"ood_\")\n",
    "\n",
    "        predicted_target_ood_decoded = jax.tree_util.tree_map(reconstruct_data_fn, predicted_target_ood)\n",
    "        ood_metrics_decoded = jax.tree_util.tree_map(\n",
    "            compute_metrics_fast, ood_data_target_decoded, predicted_target_ood_decoded\n",
    "        )\n",
    "        mean_ood_metrics_decoded = compute_mean_metrics(ood_metrics_decoded, prefix=\"decoded_ood_\")\n",
    "\n",
    "        #ood_deg_target_decoded_predicted = jax.tree_util.tree_map(\n",
    "        #    get_mask, predicted_target_ood_decoded, ood_deg_dict\n",
    "        #)\n",
    "        #ood_deg_target_decoded = jax.tree_util.tree_map(get_mask, ood_data_target_decoded, ood_deg_dict)\n",
    "        #deg_ood_metrics_encoded = jax.tree_util.tree_map(\n",
    "        #    compute_metrics_fast, ood_deg_target_decoded, ood_deg_target_decoded_predicted\n",
    "        #)\n",
    "        #deg_mean_ood_metrics_encoded = compute_mean_metrics(deg_ood_metrics_encoded, prefix=\"deg_ood_\")\n",
    "        print(mean_test_metrics_decoded, mean_ood_metrics_decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29c3437-af1a-46f7-8f94-dee977fdf04e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa5aa1d-a803-4f14-9f21-57bbe91646f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633784c9-8ca1-4ac9-aca1-00e6112699db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b79180-6428-4c99-a4cf-2ea57f936d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb36bf29-fb41-4990-a0cb-d42612786af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_target_ood = jax.tree_util.tree_map(model.transport, ood_data_source, ood_data_conditions)\n",
    "ood_metrics = jax.tree_util.tree_map(compute_metrics_fast, ood_data_target, predicted_target_ood)\n",
    "mean_ood_metrics = compute_mean_metrics(ood_metrics, prefix=\"ood_\")\n",
    "\n",
    "predicted_target_ood_decoded = jax.tree_util.tree_map(reconstruct_data_fn, predicted_target_ood)\n",
    "ood_metrics_decoded = jax.tree_util.tree_map(\n",
    "    compute_metrics_fast, ood_data_target_decoded, predicted_target_ood_decoded\n",
    ")\n",
    "mean_ood_metrics_decoded = compute_mean_metrics(ood_metrics_decoded, prefix=\"decoded_ood_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22507b33-b218-41db-9ac2-2e63a5b4d886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decoded_ood_r_squared': -0.7164179366485877,\n",
       " 'decoded_ood_e_distance': 52.26967538874433,\n",
       " 'decoded_ood_mmd_distance': 0.13167360613726622}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_ood_metrics_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f58d6b2-83f6-42b1-bfa9-ba184e28627e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75f9cd3-9fcb-4713-ab95-68f4ddd2ebc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ood_metrics_decoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ood_metrics_decoded\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ood_metrics_decoded' is not defined"
     ]
    }
   ],
   "source": [
    "ood_metrics_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b605b457-2c5d-4d3d-9f20-a8cf290661b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([el for el in test_data_source.keys() if el.startswith(\"K562\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a44719a-7d29-43e7-8721-e4a5d7d9d052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([el for el in test_data_source.keys() if el.startswith(\"MCF7\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "939ed433-5d4e-477a-81a4-984c5d87eb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([el for el in test_data_source.keys() if el.startswith(\"A549\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c09eaf-91ea-46f9-a527-5f92c1baa834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ot_pert_genot",
   "language": "python",
   "name": "ot_pert_genot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
