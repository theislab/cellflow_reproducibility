{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e761b2ce-9f52-4aff-ba9e-93048c063928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import wandb\n",
    "from ott.neural import datasets\n",
    "import sys\n",
    "from omegaconf import DictConfig\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from typing import Optional, Literal\n",
    "import jax\n",
    "import pathlib\n",
    "import optax\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from flax import linen as nn\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from flax.training import train_state\n",
    "\n",
    "from ott.neural.networks.layers import time_encoder\n",
    "from ott.neural.methods.flows import dynamics, otfm, genot\n",
    "from ott.neural.networks import velocity_field\n",
    "from ott.solvers import utils as solver_utils\n",
    "import jax.tree_util as jtu\n",
    "from ott.neural.networks.layers import time_encoder\n",
    "from ott.neural.networks.velocity_field import VelocityField\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "import scanpy as sc\n",
    "from ot_pert.metrics import compute_metrics_fast, compute_mean_metrics\n",
    "from ot_pert.nets.nets import VelocityFieldWithAttention\n",
    "from ot_pert.utils import ConditionalLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74575f53-0f9e-4c99-b2a8-967ec3143352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_data(embedding: np.ndarray, projection_matrix: np.ndarray, mean_to_add: np.ndarray) -> np.ndarray:\n",
    "    return np.matmul(embedding, projection_matrix.T) + mean_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e7d7477-ca40-49dd-b84c-6f6b67f71706",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsm_key_cond = \"ecfp_dose_cell_line\"\n",
    "obsm_key_data = \"X_pca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80093da-403e-4a3e-8a39-afc0b8d66467",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train_path = \"/lustre/groups/ml01/workspace/ot_perturbation/data/sciplex/adata_train_30.h5ad\"\n",
    "adata_test_path = \"/lustre/groups/ml01/workspace/ot_perturbation/data/sciplex/adata_test_30.h5ad\"\n",
    "adata_ood_path = \"/lustre/groups/ml01/workspace/ot_perturbation/data/sciplex/adata_ood_30.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab46905-01b3-42e4-a2a1-ed7baa0b8344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/dominik.klein/mambaforge/envs/ot_pert_genot/lib/python3.12/site-packages/anndata/__init__.py:51: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n",
      "/home/icb/dominik.klein/mambaforge/envs/ot_pert_genot/lib/python3.12/site-packages/anndata/__init__.py:51: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n",
      "/home/icb/dominik.klein/mambaforge/envs/ot_pert_genot/lib/python3.12/site-packages/anndata/__init__.py:51: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "adata_train = sc.read(adata_train_path)\n",
    "adata_test = sc.read(adata_test_path)\n",
    "adata_ood = sc.read(adata_ood_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9fda51-88db-44f2-b359-eb538622de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.subsample(adata_train, fraction=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b701de-8c48-4880-b85d-cc667475d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train.obsm[\"ecfp_dose\"] = np.concatenate(\n",
    "    (adata_train.obsm[\"ecfp\"], np.asarray(adata_train.obs[\"dose\"])[:, None]), axis=1\n",
    ")\n",
    "adata_test.obsm[\"ecfp_dose\"] = np.concatenate(\n",
    "    (adata_test.obsm[\"ecfp\"], np.asarray(adata_test.obs[\"dose\"])[:, None]), axis=1\n",
    ")\n",
    "adata_ood.obsm[\"ecfp_dose\"] = np.concatenate(\n",
    "    (adata_ood.obsm[\"ecfp\"], np.asarray(adata_ood.obs[\"dose\"])[:, None]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2342c0bc-9552-4c62-9fda-87af01ce07cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train.obsm[\"ecfp_dose_cell_line\"] = np.concatenate(\n",
    "    (adata_train.obsm[\"ecfp_dose\"], adata_train.obsm[\"cell_line_emb\"]), axis=1\n",
    ")\n",
    "adata_test.obsm[\"ecfp_dose_cell_line\"] = np.concatenate(\n",
    "    (adata_test.obsm[\"ecfp_dose\"], adata_test.obsm[\"cell_line_emb\"]), axis=1\n",
    ")\n",
    "adata_ood.obsm[\"ecfp_dose_cell_line\"] = np.concatenate(\n",
    "    (adata_ood.obsm[\"ecfp_dose\"], adata_ood.obsm[\"cell_line_emb\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e81c5a24-8ae5-495c-bf39-588a5600bbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 13:08:08.452735: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.3 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "def data_match_fn(\n",
    "    src_lin: Optional[jnp.ndarray], tgt_lin: Optional[jnp.ndarray],\n",
    "    src_quad: Optional[jnp.ndarray], tgt_quad: Optional[jnp.ndarray], *,\n",
    "    typ: Literal[\"lin\", \"quad\", \"fused\"], epsilon: float = 1e-2, tau_a: float = 1.0,\n",
    "    tau_b: float = 1.0,\n",
    ") -> jnp.ndarray:\n",
    "    if typ == \"lin\":\n",
    "        return solver_utils.match_linear(x=src_lin, y=tgt_lin, scale_cost=\"mean\", epsilon=epsilon, tau_a=tau_a, tau_b=tau_b)\n",
    "    if typ == \"quad\":\n",
    "        return solver_utils.match_quadratic(xx=src_quad, yy=tgt_quad)\n",
    "    if typ == \"fused\":\n",
    "        return solver_utils.match_quadratic(\n",
    "            xx=src_quad, yy=tgt_quad, x=src_lin, y=tgt_lin\n",
    "        )\n",
    "    raise NotImplementedError(f\"Unknown type: {typ}.\")\n",
    "\n",
    "# Load data\n",
    "\n",
    "dls = []\n",
    "\n",
    "train_data_source = {}\n",
    "train_data_target = {}\n",
    "train_data_source_decoded = {}\n",
    "train_data_target_decoded = {}\n",
    "train_data_conditions = {}\n",
    "\n",
    "\n",
    "for cond in adata_train.obs[\"condition\"].cat.categories:\n",
    "    if \"Vehicle\" in cond:\n",
    "        continue\n",
    "    src_str = list(adata_train[adata_train.obs[\"condition\"]==cond].obs[\"cell_type\"].unique())\n",
    "    assert len(src_str) == 1\n",
    "    source = adata_train[adata_train.obs[\"condition\"]==src_str[0]+\"_Vehicle_0.0\"].obsm[obsm_key_data]\n",
    "    source_decoded = adata_train[adata_train.obs[\"condition\"]==src_str[0]+\"_Vehicle_0.0\"].X.A\n",
    "    target = adata_train[adata_train.obs[\"condition\"]==cond].obsm[obsm_key_data]\n",
    "    target_decoded = adata_train[adata_train.obs[\"condition\"]==cond].X.A\n",
    "    conds = adata_train[adata_train.obs[\"condition\"]==cond].obsm[obsm_key_cond]\n",
    "    assert np.all(np.all(conds == conds[0], axis=1))\n",
    "    conds = np.tile(conds[0], (len(source), 1))\n",
    "    dls.append(DataLoader(datasets.OTDataset(datasets.OTData(\n",
    "        lin=source,\n",
    "        condition=conds,\n",
    "    ), datasets.OTData(lin=target)), batch_size=1024, shuffle=True))\n",
    "    train_data_source[cond] = source\n",
    "    train_data_target[cond] = target\n",
    "    train_data_conditions[cond] = conds\n",
    "    train_data_source_decoded[cond] = source_decoded\n",
    "    train_data_target_decoded[cond] = target_decoded\n",
    "\n",
    "train_loader = ConditionalLoader(dls, seed=0)\n",
    "\n",
    "test_data_source = {}\n",
    "test_data_target = {}\n",
    "test_data_source_decoded = {}\n",
    "test_data_target_decoded = {}\n",
    "test_data_conditions = {}\n",
    "\n",
    "for cond in adata_test.obs[\"condition\"].cat.categories:\n",
    "    if \"Vehicle\" in cond:\n",
    "        continue\n",
    "    src_str = list(adata_test[adata_test.obs[\"condition\"]==cond].obs[\"cell_type\"].unique())\n",
    "    assert len(src_str) == 1\n",
    "    source = adata_test[adata_test.obs[\"condition\"]==src_str[0]+\"_Vehicle_0.0\"].obsm[obsm_key_data]\n",
    "    source_decoded = adata_test[adata_test.obs[\"condition\"]==src_str[0]+\"_Vehicle_0.0\"].X.A\n",
    "\n",
    "    target = adata_test[adata_test.obs[\"condition\"]==cond].obsm[obsm_key_data]\n",
    "    target_decoded = adata_test[adata_test.obs[\"condition\"]==cond].X.A\n",
    "\n",
    "\n",
    "    conds = adata_test[adata_test.obs[\"condition\"]==cond].obsm[obsm_key_cond]\n",
    "    assert np.all(np.all(conds == conds[0], axis=1))\n",
    "    conds = np.tile(conds[0], (len(source), 1))\n",
    "    test_data_source[cond] = source\n",
    "    test_data_target[cond] = target\n",
    "    test_data_source_decoded[cond] = source_decoded\n",
    "    test_data_target_decoded[cond] = target_decoded\n",
    "    test_data_conditions[cond] = conds\n",
    "\n",
    "ood_data_source = {}\n",
    "ood_data_target = {}\n",
    "ood_data_source_decoded = {}\n",
    "ood_data_target_decoded = {}\n",
    "ood_data_conditions = {}\n",
    "\n",
    "for cond in adata_ood.obs[\"condition\"].cat.categories:\n",
    "    if \"Vehicle\" in cond:\n",
    "        continue\n",
    "    src_str = list(adata_ood[adata_ood.obs[\"condition\"]==cond].obs[\"cell_type\"].unique())\n",
    "    assert len(src_str) == 1\n",
    "    source = adata_ood[adata_ood.obs[\"condition\"]==src_str[0]+\"_Vehicle_0.0\"].obsm[obsm_key_data]\n",
    "    source_decoded = adata_ood[adata_ood.obs[\"condition\"]==src_str[0]+\"_Vehicle_0.0\"].X.A\n",
    "    target = adata_ood[adata_ood.obs[\"condition\"]==cond].obsm[obsm_key_data]\n",
    "    target_decoded = adata_ood[adata_ood.obs[\"condition\"]==cond].X.A\n",
    "    conds = adata_ood[adata_ood.obs[\"condition\"]==cond].obsm[obsm_key_cond]\n",
    "    assert np.all(np.all(conds == conds[0], axis=1))\n",
    "    conds = np.tile(conds[0], (len(source), 1))\n",
    "    ood_data_source[cond] = source\n",
    "    ood_data_target[cond] = target\n",
    "    ood_data_source_decoded[cond] = source_decoded\n",
    "    ood_data_target_decoded[cond] = target_decoded\n",
    "    ood_data_conditions[cond] = conds\n",
    "\n",
    "reconstruct_data_fn = functools.partial(reconstruct_data, projection_matrix=adata_train.varm[\"PCs\"], mean_to_add=adata_train.varm[\"X_train_mean\"].T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4e3ec12-c0cd-4b18-8a05-c06d531dde9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_data_fn = functools.partial(reconstruct_data, projection_matrix=adata_train.varm[\"PCs\"], mean_to_add=adata_train.varm[\"X_train_mean\"].T)\n",
    "\n",
    "train_deg_dict = {k: v for k,v in adata_train.uns['rank_genes_groups_cov_all'].items() if k in train_data_conditions.keys()}\n",
    "test_deg_dict = {k: v for k,v in adata_train.uns['rank_genes_groups_cov_all'].items() if k in test_data_conditions.keys()}\n",
    "ood_deg_dict = {k: v for k,v in adata_train.uns['rank_genes_groups_cov_all'].items() if k in ood_data_conditions.keys()}\n",
    "\n",
    "def get_mask(x, y):\n",
    "    return x[:, [gene in y for gene in adata_train.var_names]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86e0193b-e615-47ba-a26e-8115ea641ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dim = source.shape[1]\n",
    "target_dim = source_dim\n",
    "condition_dim = conds.shape[1]\n",
    "\n",
    "source_dim = source.shape[1]\n",
    "target_dim = source_dim\n",
    "condition_dim = conds.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad838285-5aaa-45b4-abdc-56301ac404e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Sequence\n",
    "\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from flax import linen as nn\n",
    "\n",
    "from ott.neural.networks.layers import time_encoder\n",
    "from ot_pert.nets.nets import CondVelocityField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "318c0f30-741f-4c43-b91d-9faee6132676",
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = CondVelocityField(\n",
    "    hidden_dims=[1024, 1024, 1024],\n",
    "    time_dims=[512,512],\n",
    "    output_dims=[1024, 1024, 1024]+[target_dim],\n",
    "    condition_dims=[2048, 2048],\n",
    "    time_encoder = functools.partial(time_encoder.cyclical_time_encoder, n_freqs=1024),\n",
    "    dropout_rate=0.2\n",
    "    )\n",
    "\n",
    "model = genot.GENOT(\n",
    "    vf,\n",
    "    flow=dynamics.ConstantNoiseFlow(0.0),\n",
    "    data_match_fn=jax.jit(functools.partial(data_match_fn, typ=\"lin\", src_quad=None, tgt_quad=None)),\n",
    "    source_dim=source_dim,\n",
    "    target_dim=target_dim,\n",
    "    condition_dim=condition_dim,\n",
    "    rng=jax.random.PRNGKey(13),\n",
    "    optimizer=optax.MultiSteps(optax.adam(learning_rate=1e-4), 20),)\n",
    "training_logs = {\"loss\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06b39388-2df6-4ccd-8c65-4a6a2412b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import sys\n",
    "import traceback\n",
    "from typing import Optional, Literal, Tuple, Dict\n",
    "import hydra\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import numpy as np\n",
    "import optax\n",
    "import scanpy as sc\n",
    "import wandb\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from ott.neural import datasets\n",
    "from ott.neural.methods.flows import dynamics, genot\n",
    "from ott.neural.networks.layers import time_encoder\n",
    "from ott.neural.networks.velocity_field import VelocityField\n",
    "from ott.solvers import utils as solver_utils\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import orbax\n",
    "import os\n",
    "\n",
    "def prepare_data(\n",
    "    batch: Dict[str, jnp.ndarray]\n",
    "    ) -> Tuple[Tuple[jnp.ndarray, Optional[jnp.ndarray], jnp.ndarray],\n",
    "            Tuple[jnp.ndarray, jnp.ndarray, Optional[jnp.ndarray],\n",
    "                    Optional[jnp.ndarray]]]:\n",
    "    src_lin, src_quad = batch.get(\"src_lin\"), batch.get(\"src_quad\")\n",
    "    tgt_lin, tgt_quad = batch.get(\"tgt_lin\"), batch.get(\"tgt_quad\")\n",
    "\n",
    "    if src_quad is None and tgt_quad is None:  # lin\n",
    "        src, tgt = src_lin, tgt_lin\n",
    "        arrs = src_lin, tgt_lin\n",
    "    elif src_lin is None and tgt_lin is None:  # quad\n",
    "        src, tgt = src_quad, tgt_quad\n",
    "        arrs = src_quad, tgt_quad\n",
    "    elif all(\n",
    "        arr is not None for arr in (src_lin, tgt_lin, src_quad, tgt_quad)\n",
    "    ):  # fused quad\n",
    "        src = jnp.concatenate([src_lin, src_quad], axis=1)\n",
    "        tgt = jnp.concatenate([tgt_lin, tgt_quad], axis=1)\n",
    "        arrs = src_quad, tgt_quad, src_lin, tgt_lin\n",
    "    else:\n",
    "        raise RuntimeError(\"Cannot infer OT problem type from data.\")\n",
    "\n",
    "    return (src, batch.get(\"src_condition\"), tgt), arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df472524-4a2a-496b-9169-6d1f5eafb87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 18334/50000 [41:07<1:06:15,  7.97it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "for it in tqdm(range(50000)):\n",
    "    batch = next(iter(train_loader))\n",
    "    batch = jtu.tree_map(jnp.asarray, batch)\n",
    "    rng = jax.random.split(rng, 5)\n",
    "    rng, rng_resample, rng_noise, rng_time, rng_step_fn = rng\n",
    "    \n",
    "    batch = jtu.tree_map(jnp.asarray, batch)\n",
    "    (src, src_cond, tgt), matching_data = prepare_data(batch)\n",
    "    \n",
    "    n = src.shape[0]\n",
    "    time = model.time_sampler(rng_time, n * model.n_samples_per_src)\n",
    "    latent = model.latent_noise_fn(rng_noise, (n, model.n_samples_per_src))\n",
    "    \n",
    "    tmat = model.data_match_fn(*matching_data)  # (n, m)\n",
    "    src_ixs, tgt_ixs = solver_utils.sample_conditional(  # (n, k), (m, k)\n",
    "    rng_resample,\n",
    "    tmat,\n",
    "    k=model.n_samples_per_src,\n",
    "    )\n",
    "    \n",
    "    src, tgt = src[src_ixs], tgt[tgt_ixs]  # (n, k, ...),  # (m, k, ...)\n",
    "    if src_cond is not None:\n",
    "        src_cond = src_cond[src_ixs]\n",
    "    \n",
    "    if model.latent_match_fn is not None:\n",
    "        src, src_cond, tgt = model._match_latent(rng, src, src_cond, latent, tgt)\n",
    "    \n",
    "    src = src.reshape(-1, *src.shape[2:])  # (n * k, ...)\n",
    "    tgt = tgt.reshape(-1, *tgt.shape[2:])  # (m * k, ...)\n",
    "    latent = latent.reshape(-1, *latent.shape[2:])\n",
    "    if src_cond is not None:\n",
    "        src_cond = src_cond.reshape(-1, *src_cond.shape[2:])\n",
    "\n",
    "    \n",
    "    \n",
    "    loss, model.vf_state = model.step_fn(\n",
    "    rng_step_fn, model.vf_state, time, src, tgt, latent, src_cond\n",
    "    )\n",
    "\n",
    "    training_logs[\"loss\"].append(float(loss))\n",
    "    if (it % 100000 == 0) and (it > 0):\n",
    "        idcs = np.random.choice(list(test_data_source.keys()), 20)\n",
    "        test_data_source_tmp = {k:v for k,v in test_data_source.items() if k in idcs}\n",
    "        test_data_target_tmp = {k:v for k,v in test_data_target.items() if k in idcs}\n",
    "        test_data_conditions_tmp = {k:v for k,v in test_data_conditions.items() if k in idcs}\n",
    "        test_data_target_decoded_tmp = {k:v for k,v in test_data_target_decoded.items() if k in idcs}\n",
    "        test_deg_dict_tmp = {k:v for k,v in test_deg_dict.items() if k in idcs}\n",
    "        valid_losses = []\n",
    "        #for cond in test_data_source_tmp.keys():\n",
    "        #    src = test_data_source_tmp[cond]\n",
    "        #    tgt = test_data_target_tmp[cond]\n",
    "        #    src_cond = test_data_conditions_tmp[cond]\n",
    "        #    if model.match_fn is not None:\n",
    "        #        tmat = model.match_fn(src, tgt)\n",
    "        #        src_ixs, tgt_ixs = solver_utils.sample_joint(rng_resample, tmat)\n",
    "        #        src, tgt = src[src_ixs], tgt[tgt_ixs]\n",
    "        #        src_cond = None if src_cond is None else src_cond[src_ixs]\n",
    "        #    _, valid_loss = model.step_fn(\n",
    "        #        rng,\n",
    "        #        model.vf_state,\n",
    "        #        src,\n",
    "        #        tgt,\n",
    "        #        src_cond,\n",
    "        #    )\n",
    "        #    valid_losses.append(valid_loss)\n",
    "\n",
    "        # predicted_target_train = jax.tree_util.tree_map(model.transport, train_data_source, train_data_conditions)\n",
    "        # train_metrics = jax.tree_util.tree_map(compute_metrics_fast, train_data_target, predicted_target_train)\n",
    "        # mean_train_metrics = compute_mean_metrics(train_metrics, prefix=\"train_\")\n",
    "\n",
    "        # predicted_target_train_decoded = jax.tree_util.tree_map(reconstruct_data_fn, predicted_target_train)\n",
    "        # train_metrics_decoded = jax.tree_util.tree_map(compute_metrics_fast, train_data_target_decoded, predicted_target_train_decoded)\n",
    "        # mean_train_metrics_decoded = compute_mean_metrics(train_metrics_decoded, prefix=\"decoded_train_\")\n",
    "\n",
    "        # train_deg_target_decoded_predicted = jax.tree_util.tree_map(get_mask, predicted_target_train_decoded, train_deg_dict)\n",
    "        # train_deg_target_decoded = jax.tree_util.tree_map(get_mask, train_data_target_decoded, test_deg_dict)\n",
    "\n",
    "        predicted_target_test = jax.tree_util.tree_map(model.transport, test_data_source_tmp, test_data_conditions_tmp)\n",
    "        #test_metrics = jax.tree_util.tree_map(compute_metrics_fast, test_data_target_tmp, predicted_target_test)\n",
    "        #mean_test_metrics = compute_mean_metrics(test_metrics, prefix=\"test_\")\n",
    "\n",
    "        predicted_target_test_decoded = jax.tree_util.tree_map(reconstruct_data_fn, predicted_target_test)\n",
    "        test_metrics_decoded = jax.tree_util.tree_map(\n",
    "            compute_metrics_fast, test_data_target_decoded_tmp, predicted_target_test_decoded\n",
    "        )\n",
    "        mean_test_metrics_decoded = compute_mean_metrics(test_metrics_decoded, prefix=\"decoded_test_\")\n",
    "\n",
    "\n",
    "        #test_deg_target_decoded_predicted = jax.tree_util.tree_map(\n",
    "        #    get_mask, predicted_target_test_decoded, test_deg_dict_tmp\n",
    "        #)\n",
    "        #test_deg_target_decoded = jax.tree_util.tree_map(get_mask, test_data_target_decoded_tmp, test_deg_dict_tmp)\n",
    "        #deg_test_metrics_encoded = jax.tree_util.tree_map(\n",
    "        #    compute_metrics_fast, test_deg_target_decoded, test_deg_target_decoded_predicted\n",
    "        #)\n",
    "        #deg_mean_test_metrics_encoded = compute_mean_metrics(deg_test_metrics_encoded, prefix=\"deg_test_\")\n",
    "\n",
    "        predicted_target_ood = jax.tree_util.tree_map(model.transport, ood_data_source, ood_data_conditions)\n",
    "        ood_metrics = jax.tree_util.tree_map(compute_metrics_fast, ood_data_target, predicted_target_ood)\n",
    "        mean_ood_metrics = compute_mean_metrics(ood_metrics, prefix=\"ood_\")\n",
    "\n",
    "        predicted_target_ood_decoded = jax.tree_util.tree_map(reconstruct_data_fn, predicted_target_ood)\n",
    "        ood_metrics_decoded = jax.tree_util.tree_map(\n",
    "            compute_metrics_fast, ood_data_target_decoded, predicted_target_ood_decoded\n",
    "        )\n",
    "        mean_ood_metrics_decoded = compute_mean_metrics(ood_metrics_decoded, prefix=\"decoded_ood_\")\n",
    "\n",
    "        #ood_deg_target_decoded_predicted = jax.tree_util.tree_map(\n",
    "        #    get_mask, predicted_target_ood_decoded, ood_deg_dict\n",
    "        #)\n",
    "        #ood_deg_target_decoded = jax.tree_util.tree_map(get_mask, ood_data_target_decoded, ood_deg_dict)\n",
    "        #deg_ood_metrics_encoded = jax.tree_util.tree_map(\n",
    "        #    compute_metrics_fast, ood_deg_target_decoded, ood_deg_target_decoded_predicted\n",
    "        #)\n",
    "        #deg_mean_ood_metrics_encoded = compute_mean_metrics(deg_ood_metrics_encoded, prefix=\"deg_ood_\")\n",
    "        print(mean_test_metrics_decoded, mean_ood_metrics_decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29c3437-af1a-46f7-8f94-dee977fdf04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_target_ood = jax.tree_util.tree_map(model.transport, ood_data_source, ood_data_conditions)\n",
    "ood_metrics = jax.tree_util.tree_map(compute_metrics_fast, ood_data_target, predicted_target_ood)\n",
    "mean_ood_metrics = compute_mean_metrics(ood_metrics, prefix=\"ood_\")\n",
    "\n",
    "predicted_target_ood_decoded = jax.tree_util.tree_map(reconstruct_data_fn, predicted_target_ood)\n",
    "ood_metrics_decoded = jax.tree_util.tree_map(\n",
    "    compute_metrics_fast, ood_data_target_decoded, predicted_target_ood_decoded\n",
    ")\n",
    "mean_ood_metrics_decoded = compute_mean_metrics(ood_metrics_decoded, prefix=\"decoded_ood_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa5aa1d-a803-4f14-9f21-57bbe91646f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ood_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7807c-8f93-411d-8312-af48fd5dd4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ood_metrics_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633784c9-8ca1-4ac9-aca1-00e6112699db",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = jax.tree_util.tree_map(lambda x: vf.get_embedding(model.vf_state, x[0]), ood_data_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae58bbd-5e19-4204-8065-5038f9965bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b79180-6428-4c99-a4cf-2ea57f936d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb36bf29-fb41-4990-a0cb-d42612786af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_target_ood = jax.tree_util.tree_map(model.transport, ood_data_source, ood_data_conditions)\n",
    "ood_metrics = jax.tree_util.tree_map(compute_metrics_fast, ood_data_target, predicted_target_ood)\n",
    "mean_ood_metrics = compute_mean_metrics(ood_metrics, prefix=\"ood_\")\n",
    "\n",
    "predicted_target_ood_decoded = jax.tree_util.tree_map(reconstruct_data_fn, predicted_target_ood)\n",
    "ood_metrics_decoded = jax.tree_util.tree_map(\n",
    "    compute_metrics_fast, ood_data_target_decoded, predicted_target_ood_decoded\n",
    ")\n",
    "mean_ood_metrics_decoded = compute_mean_metrics(ood_metrics_decoded, prefix=\"decoded_ood_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22507b33-b218-41db-9ac2-2e63a5b4d886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decoded_ood_r_squared': -0.7164179366485877,\n",
       " 'decoded_ood_e_distance': 52.26967538874433,\n",
       " 'decoded_ood_mmd_distance': 0.13167360613726622}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_ood_metrics_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f58d6b2-83f6-42b1-bfa9-ba184e28627e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75f9cd3-9fcb-4713-ab95-68f4ddd2ebc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ood_metrics_decoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ood_metrics_decoded\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ood_metrics_decoded' is not defined"
     ]
    }
   ],
   "source": [
    "ood_metrics_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b605b457-2c5d-4d3d-9f20-a8cf290661b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([el for el in test_data_source.keys() if el.startswith(\"K562\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a44719a-7d29-43e7-8721-e4a5d7d9d052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([el for el in test_data_source.keys() if el.startswith(\"MCF7\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "939ed433-5d4e-477a-81a4-984c5d87eb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([el for el in test_data_source.keys() if el.startswith(\"A549\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c09eaf-91ea-46f9-a527-5f92c1baa834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ot_pert_genot",
   "language": "python",
   "name": "ot_pert_genot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
