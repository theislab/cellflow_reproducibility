{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3eda365-8f24-401d-bfec-86ce88e043f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from typing import Literal, Optional\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import numpy as np\n",
    "import optax\n",
    "import scanpy as sc\n",
    "from ott.neural import datasets\n",
    "from ott.neural.methods.flows import dynamics, otfm\n",
    "from ott.neural.networks.layers import time_encoder\n",
    "from ott.solvers import utils as solver_utils\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ot_pert.metrics import compute_mean_metrics, compute_metrics_fast\n",
    "from ot_pert.nets.nets import VelocityFieldWithAttention\n",
    "from ot_pert.utils import ConditionalLoader\n",
    "\n",
    "\n",
    "def reconstruct_data(embedding, projection_matrix, mean_to_add):\n",
    "    \"\"\"Reconstructs data from projections.\"\"\"\n",
    "    return np.matmul(embedding, projection_matrix.T) + mean_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aaf2e25-2d39-4b1c-9d20-3348f09c2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsm_key_data = \"X_pca\"\n",
    "obsm_key_cond_1 = \"ecfp_drug_1\"\n",
    "obsm_key_cond_2 = \"ecfp_drug_2\"\n",
    "adata_train_path = \"/lustre/groups/ml01/workspace/ot_perturbation/data/combosciplex/adata_train_30.h5ad\"\n",
    "adata_test_path = \"/lustre/groups/ml01/workspace/ot_perturbation/data/combosciplex/adata_test_30.h5ad\"\n",
    "adata_ood_path = \"/lustre/groups/ml01/workspace/ot_perturbation/data/combosciplex/adata_ood_30.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f7643fc-6bbf-48a0-84a5-fd655683fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(adata, cfg, *, return_dl: bool):\n",
    "    \"\"\"Loads data and preprocesses it based on configuration.\"\"\"\n",
    "    dls = []\n",
    "    data_source = {}\n",
    "    data_target = {}\n",
    "    data_source_decoded = {}\n",
    "    data_target_decoded = {}\n",
    "    data_conditions = {}\n",
    "    source = adata[adata.obs[\"condition\"] == \"control\"].obsm[obsm_key_data]\n",
    "    source_decoded = adata[adata.obs[\"condition\"] == \"control\"].X\n",
    "\n",
    "    for cond in adata.obs[\"condition\"].cat.categories:\n",
    "        if cond != \"control\":\n",
    "            target = adata[adata.obs[\"condition\"] == cond].obsm[obsm_key_data]\n",
    "            target_decoded = adata[adata.obs[\"condition\"] == cond].X.A\n",
    "            condition_1 = adata[adata.obs[\"condition\"] == cond].obsm[obsm_key_cond_1]\n",
    "            condition_2 = adata[adata.obs[\"condition\"] == cond].obsm[obsm_key_cond_2]\n",
    "            assert np.all(np.all(condition_1 == condition_1[0], axis=1))\n",
    "            assert np.all(np.all(condition_2 == condition_2[0], axis=1))\n",
    "            expanded_arr = np.expand_dims(\n",
    "                np.concatenate((condition_1[0, :][None, :], condition_2[0, :][None, :]), axis=0), axis=0\n",
    "            )\n",
    "            conds = np.tile(expanded_arr, (len(source), 1, 1))\n",
    "\n",
    "            if return_dl:\n",
    "                dls.append(\n",
    "                    DataLoader(\n",
    "                        datasets.OTDataset(\n",
    "                            datasets.OTData(\n",
    "                                lin=source,\n",
    "                                condition=conds,\n",
    "                            ),\n",
    "                            datasets.OTData(lin=target),\n",
    "                        ),\n",
    "                        batch_size=32,\n",
    "                        shuffle=True,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                data_source[cond] = source\n",
    "                data_target[cond] = target\n",
    "                data_source_decoded[cond] = source_decoded\n",
    "                data_target_decoded[cond] = target_decoded\n",
    "                data_conditions[cond] = conds\n",
    "    if return_dl:\n",
    "        return ConditionalLoader(dls, seed=0)\n",
    "\n",
    "    deg_dict = {k: v for k, v in adata.uns[\"rank_genes_groups_cov_all\"].items() if k in data_conditions.keys()}\n",
    "\n",
    "    return {\n",
    "        \"source\": data_source,\n",
    "        \"target\": data_target,\n",
    "        \"source_decoded\": data_source_decoded,\n",
    "        \"target_decoded\": data_target_decoded,\n",
    "        \"conditions\": data_conditions,\n",
    "        \"deg_dict\": deg_dict,\n",
    "    }\n",
    "\n",
    "\n",
    "def data_match_fn(\n",
    "    src_lin: Optional[jnp.ndarray],\n",
    "    tgt_lin: Optional[jnp.ndarray],\n",
    "    src_quad: Optional[jnp.ndarray],\n",
    "    tgt_quad: Optional[jnp.ndarray],\n",
    "    *,\n",
    "    typ: Literal[\"lin\", \"quad\", \"fused\"],\n",
    "    epsilon: float = 1e-2,\n",
    "    tau_a: float = 1.0,\n",
    "    tau_b: float = 1.0,\n",
    ") -> jnp.ndarray:\n",
    "    if typ == \"lin\":\n",
    "        return solver_utils.match_linear(\n",
    "            x=src_lin, y=tgt_lin, scale_cost=\"mean\", epsilon=epsilon, tau_a=tau_a, tau_b=tau_b\n",
    "        )\n",
    "    if typ == \"quad\":\n",
    "        return solver_utils.match_quadratic(xx=src_quad, yy=tgt_quad)\n",
    "    if typ == \"fused\":\n",
    "        return solver_utils.match_quadratic(xx=src_quad, yy=tgt_quad, x=src_lin, y=tgt_lin)\n",
    "    raise NotImplementedError(f\"Unknown type: {typ}.\")\n",
    "\n",
    "\n",
    "def get_mask(x, y, var_names):\n",
    "    return x[:, [gene in y for gene in var_names]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df2d09b2-273c-4cc9-bae2-8dd9846a597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 10:22:39.257463: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.3 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "adata_train = sc.read_h5ad(adata_train_path)\n",
    "adata_test = sc.read_h5ad(adata_test_path)\n",
    "adata_ood = sc.read_h5ad(adata_ood_path)\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "ood_data = load_data(adata_ood, None, return_dl=False)\n",
    "dl = load_data(adata_train, None, return_dl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5ceeada-2f17-4246-869f-58d2babb061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks(dataset: List[jnp.ndarray]):\n",
    "    attention_mask = []\n",
    "    for data in dataset:\n",
    "        if data.ndim < 2:\n",
    "            data = data[None, :]\n",
    "        if data.ndim < 3:\n",
    "            data = data[None, :]\n",
    "        mask = jnp.all(data == 0.0, axis=-1)\n",
    "        mask = 1 - mask\n",
    "        mask = jnp.outer(mask, mask)\n",
    "        attention_mask.append(mask)\n",
    "    return jnp.expand_dims(jnp.equal(jnp.array(attention_mask), 1.0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e5eefe8-5331-4130-a3e9-0623ca00e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "\n",
    "class VelocityFieldWithAttention2(nn.Module):\n",
    "    num_heads: int\n",
    "    qkv_feature_dim: int\n",
    "    max_seq_length: int\n",
    "    hidden_dims: Sequence[int]\n",
    "    output_dims: Sequence[int]\n",
    "    condition_dims: Optional[Sequence[int]] = None\n",
    "    time_dims: Optional[Sequence[int]] = None\n",
    "    time_encoder: Callable[[jnp.ndarray], jnp.ndarray] = time_encoder.cyclical_time_encoder\n",
    "    act_fn: Callable[[jnp.ndarray], jnp.ndarray] = nn.silu\n",
    "    pad_max_dim: int = -1\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.get_masks = jax.jit(get_masks)\n",
    "        super().__post_init__()\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        t: jnp.ndarray,\n",
    "        x: jnp.ndarray,\n",
    "        condition: Optional[jnp.ndarray] = None,\n",
    "    ) -> jnp.ndarray:\n",
    "        \"\"\"Forward pass through the neural vector field.\n",
    "\n",
    "        Args:\n",
    "          t: Time of shape ``[batch, 1]``.\n",
    "          x: Data of shape ``[batch, ...]``.\n",
    "          condition: Conditioning vector of shape ``[batch, ...]``.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          Output of the neural vector field of shape ``[batch, output_dim]``.\n",
    "        \"\"\"\n",
    "        squeeze_output = False\n",
    "        if x.ndim < 2:\n",
    "            x = x[None, :]\n",
    "            t = jnp.full(shape=(1, 1), fill_value=t)\n",
    "            condition = condition[None, :]\n",
    "            squeeze_output = True\n",
    "\n",
    "        time_dims = self.hidden_dims if self.time_dims is None else self.time_dims\n",
    "        t = self.time_encoder(t)\n",
    "        for time_dim in time_dims:\n",
    "            t = self.act_fn(nn.Dense(time_dim)(t))\n",
    "\n",
    "        for hidden_dim in self.hidden_dims:\n",
    "            x = self.act_fn(nn.Dense(hidden_dim)(x))\n",
    "\n",
    "        assert condition is not None, \"No condition sequence was passed.\"\n",
    "\n",
    "        token_shape = (len(condition), 1) if condition.ndim > 2 else (1,)\n",
    "        print(token_shape)\n",
    "        class_token = nn.Embed(num_embeddings=1, features=condition.shape[-1])(jnp.int32(jnp.zeros(token_shape)))\n",
    "\n",
    "        condition = jnp.concatenate((class_token, condition), axis=-2)\n",
    "        mask = self.get_masks(condition)\n",
    "\n",
    "        attention = nn.MultiHeadDotProductAttention(num_heads=self.num_heads, qkv_features=self.qkv_feature_dim)\n",
    "        emb = attention(condition, mask=mask)\n",
    "        emb = emb[:, 0, :]  # only continue with token 0\n",
    "\n",
    "        for cond_dim in self.condition_dims:\n",
    "            condition = self.act_fn(nn.Dense(cond_dim)(emb))\n",
    "\n",
    "        feats = jnp.concatenate([t, x, condition], axis=1)\n",
    "\n",
    "        for output_dim in self.output_dims[:-1]:\n",
    "            feats = self.act_fn(nn.Dense(output_dim)(feats))\n",
    "\n",
    "        # no activation function for the final layer\n",
    "        out = nn.Dense(self.output_dims[-1])(feats)\n",
    "        return jnp.squeeze(out) if squeeze_output else out\n",
    "\n",
    "    def create_train_state(\n",
    "        self,\n",
    "        rng: jax.Array,\n",
    "        optimizer: optax.OptState,\n",
    "        input_dim: int,\n",
    "        condition_dim: Optional[int] = None,\n",
    "    ) -> train_state.TrainState:\n",
    "        \"\"\"Create the training state.\n",
    "\n",
    "        Args:\n",
    "          rng: Random number generator.\n",
    "          optimizer: Optimizer.\n",
    "          input_dim: Dimensionality of the velocity field.\n",
    "          condition_dim: Dimensionality of the condition of the velocity field.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          The training state.\n",
    "        \"\"\"\n",
    "        t, x = jnp.ones((1, 1)), jnp.ones((1, input_dim))\n",
    "        if self.condition_dims is None:\n",
    "            cond = None\n",
    "        else:\n",
    "            assert condition_dim > 0, \"Condition dimension must be positive.\"\n",
    "            print(condition_dim)\n",
    "            cond = jnp.ones((1, 1, condition_dim))\n",
    "\n",
    "        params = self.init(rng, t, x, cond)[\"params\"]\n",
    "        return train_state.TrainState.create(apply_fn=self.apply, params=params, tx=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbfdb31d-a572-4bef-ae28-7ece2739994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_metrics_fn = compute_metrics_fast\n",
    "\n",
    "reconstruct_data_fn = functools.partial(\n",
    "    reconstruct_data, projection_matrix=adata_train.varm[\"PCs\"], mean_to_add=adata_train.varm[\"X_train_mean\"].T\n",
    ")\n",
    "mask_fn = functools.partial(get_mask, var_names=adata_train.var_names)\n",
    "\n",
    "batch = next(dl)\n",
    "output_dim = batch[\"tgt_lin\"].shape[1]\n",
    "condition_dim = batch[\"src_condition\"].shape[-1]\n",
    "\n",
    "vf = VelocityFieldWithAttention(\n",
    "    num_heads=4,\n",
    "    qkv_feature_dim=32,\n",
    "    max_seq_length=2,\n",
    "    hidden_dims=[512, 512],\n",
    "    time_dims=[512, 512],\n",
    "    output_dims=[512, 512] + [output_dim],\n",
    "    condition_dims=[512, 512],\n",
    "    time_encoder=functools.partial(time_encoder.cyclical_time_encoder, n_freqs=1024),\n",
    ")\n",
    "\n",
    "model = otfm.OTFlowMatching(\n",
    "    vf,\n",
    "    flow=dynamics.ConstantNoiseFlow(0.0),\n",
    "    match_fn=jax.jit(\n",
    "        functools.partial(\n",
    "            data_match_fn,\n",
    "            typ=\"lin\",\n",
    "            src_quad=None,\n",
    "            tgt_quad=None,\n",
    "            epsilon=1.0,\n",
    "            tau_a=1.0,\n",
    "            tau_b=1.0,\n",
    "        )\n",
    "    ),\n",
    "    condition_dim=condition_dim,\n",
    "    rng=jax.random.PRNGKey(13),\n",
    "    optimizer=optax.MultiSteps(optax.adam(1e-4), 20),\n",
    ")\n",
    "\n",
    "training_logs = {\"loss\": []}\n",
    "rng = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f987cfc-9ef1-4812-b630-5180c6cafe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(cfg, model, data, log_metrics, reconstruct_data_fn, comp_metrics_fn, mask_fn):\n",
    "    for k, dat in data.items():\n",
    "        if k == \"test\":\n",
    "            n_samples = 0\n",
    "        if k == \"train\":\n",
    "            n_samples = 0\n",
    "        if k == \"ood\":\n",
    "            n_samples = -1\n",
    "\n",
    "        if n_samples != 0:\n",
    "            if n_samples > 0:\n",
    "                idcs = np.random.choice(list(list(dat.values())[0]), n_samples)\n",
    "                dat_source = {k: v for k, v in dat[\"source\"].items() if k in idcs}\n",
    "                dat_target = {k: v for k, v in dat[\"target\"].items() if k in idcs}\n",
    "                dat_conditions = {k: v for k, v in dat[\"conditions\"].items() if k in idcs}\n",
    "                dat_deg_dict = {k: v for k, v in dat[\"deg_dict\"].items() if k in idcs}\n",
    "                dat_target_decoded = {k: v for k, v in dat[\"target_decoded\"].items() if k in idcs}\n",
    "            else:\n",
    "                dat_source = dat[\"source\"]\n",
    "                dat_target = dat[\"target\"]\n",
    "                dat_conditions = dat[\"conditions\"]\n",
    "                dat_deg_dict = dat[\"deg_dict\"]\n",
    "                dat_target_decoded = dat[\"target_decoded\"]\n",
    "\n",
    "            prediction = jtu.tree_map(model.transport, dat_source, dat_conditions)\n",
    "            metrics = jtu.tree_map(comp_metrics_fn, dat_target, prediction)\n",
    "            mean_metrics = compute_mean_metrics(metrics, prefix=f\"{k}_\")\n",
    "            log_metrics.update(mean_metrics)\n",
    "\n",
    "            prediction_decoded = jtu.tree_map(reconstruct_data_fn, prediction)\n",
    "            metrics_decoded = jtu.tree_map(comp_metrics_fn, dat_target_decoded, prediction_decoded)\n",
    "            mean_metrics_decoded = compute_mean_metrics(metrics_decoded, prefix=f\"decoded_{k}_\")\n",
    "            log_metrics.update(mean_metrics_decoded)\n",
    "\n",
    "            prediction_decoded_deg = jtu.tree_map(mask_fn, prediction_decoded, dat_deg_dict)\n",
    "            target_decoded_deg = jax.tree_util.tree_map(mask_fn, dat_target_decoded, dat_deg_dict)\n",
    "            metrics_deg = jtu.tree_map(comp_metrics_fn, target_decoded_deg, prediction_decoded_deg)\n",
    "            mean_metrics_deg = compute_mean_metrics(metrics_deg, prefix=f\"deg_{k}_\")\n",
    "            log_metrics.update(mean_metrics_deg)\n",
    "\n",
    "    print(log_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f46144a-55de-43e0-aa0f-555eb07545ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:25<01:24,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 2.068877935409546, 'ood_r_squared': -0.267297544155283, 'ood_e_distance': 64.00366434401329, 'ood_mmd_distance': 0.10975084641701024, 'decoded_ood_r_squared': 0.6886720894982247, 'decoded_ood_e_distance': 65.1548799950073, 'decoded_ood_mmd_distance': 0.10469719692641617, 'deg_ood_r_squared': 0.39709923807133723, 'deg_ood_e_distance': 38.94894497198663, 'deg_ood_mmd_distance': 0.13494821025869946}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:48<01:45,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 2.196030855178833, 'ood_r_squared': -0.22045694068340493, 'ood_e_distance': 61.8951147119141, 'ood_mmd_distance': 0.10723329663260936, 'decoded_ood_r_squared': 0.6988271385301771, 'decoded_ood_e_distance': 63.046331175908264, 'decoded_ood_mmd_distance': 0.10334919571961845, 'deg_ood_r_squared': 0.41655784480552055, 'deg_ood_e_distance': 37.71764960054539, 'deg_ood_mmd_distance': 0.13275068108877447}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [01:12<01:39,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 1.6872590780258179, 'ood_r_squared': -0.22045694068340493, 'ood_e_distance': 61.8951147119141, 'ood_mmd_distance': 0.10723329663260936, 'decoded_ood_r_squared': 0.6988271385301771, 'decoded_ood_e_distance': 63.046331175908264, 'decoded_ood_mmd_distance': 0.10334919571961845, 'deg_ood_r_squared': 0.41655784480552055, 'deg_ood_e_distance': 37.71764960054539, 'deg_ood_mmd_distance': 0.13275068108877447}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [01:35<01:20,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 2.304449427127838, 'ood_r_squared': -0.17833956693922975, 'ood_e_distance': 59.94131206019108, 'ood_mmd_distance': 0.10491756734789348, 'decoded_ood_r_squared': 0.7081792279178719, 'decoded_ood_e_distance': 61.092529293228985, 'decoded_ood_mmd_distance': 0.10209074221028178, 'deg_ood_r_squared': 0.43524721889936496, 'deg_ood_e_distance': 36.532852764870995, 'deg_ood_mmd_distance': 0.13062581721605296}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [01:59<01:11,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 1.8693579137325287, 'ood_r_squared': -0.17833956693922975, 'ood_e_distance': 59.94131206019108, 'ood_mmd_distance': 0.10491756734789348, 'decoded_ood_r_squared': 0.7081792279178719, 'decoded_ood_e_distance': 61.092529293228985, 'decoded_ood_mmd_distance': 0.10209074221028178, 'deg_ood_r_squared': 0.43524721889936496, 'deg_ood_e_distance': 36.532852764870995, 'deg_ood_mmd_distance': 0.13062581721605296}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [02:23<00:54,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 2.015455973148346, 'ood_r_squared': -0.13918528124393015, 'ood_e_distance': 58.02488843024548, 'ood_mmd_distance': 0.10270528933883787, 'decoded_ood_r_squared': 0.7172547184235537, 'decoded_ood_e_distance': 59.17610639682092, 'decoded_ood_mmd_distance': 0.10086628547253966, 'deg_ood_r_squared': 0.4540298142172194, 'deg_ood_e_distance': 35.3378112140591, 'deg_ood_mmd_distance': 0.12850564704147158}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [02:46<00:36,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 2.144143211841583, 'ood_r_squared': -0.13918528124393015, 'ood_e_distance': 58.02488843024548, 'ood_mmd_distance': 0.10270528933883787, 'decoded_ood_r_squared': 0.7172547184235537, 'decoded_ood_e_distance': 59.17610639682092, 'decoded_ood_mmd_distance': 0.10086628547253966, 'deg_ood_r_squared': 0.4540298142172194, 'deg_ood_e_distance': 35.3378112140591, 'deg_ood_mmd_distance': 0.12850564704147158}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [03:11<00:17,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 1.7133100152015686, 'ood_r_squared': -0.10348161196377445, 'ood_e_distance': 56.17502905572415, 'ood_mmd_distance': 0.10062560824916915, 'decoded_ood_r_squared': 0.7259233296118598, 'decoded_ood_e_distance': 57.3262477166294, 'decoded_ood_mmd_distance': 0.09969110626106982, 'deg_ood_r_squared': 0.4728019100609421, 'deg_ood_e_distance': 34.13936983487522, 'deg_ood_mmd_distance': 0.12638921307176632}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:35<00:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': 2.1012008786201477, 'ood_r_squared': -0.10348161196377445, 'ood_e_distance': 56.17502905572415, 'ood_mmd_distance': 0.10062560824916915, 'decoded_ood_r_squared': 0.7259233296118598, 'decoded_ood_e_distance': 57.3262477166294, 'decoded_ood_mmd_distance': 0.09969110626106982, 'deg_ood_r_squared': 0.4728019100609421, 'deg_ood_e_distance': 34.13936983487522, 'deg_ood_mmd_distance': 0.12638921307176632}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for it in tqdm(range(100)):\n",
    "    rng, rng_resample, rng_step_fn = jax.random.split(rng, 3)\n",
    "    batch = next(dl)\n",
    "    batch = jtu.tree_map(jnp.asarray, batch)\n",
    "\n",
    "    src, tgt = batch[\"src_lin\"], batch[\"tgt_lin\"]\n",
    "    src_cond = batch.get(\"src_condition\")\n",
    "\n",
    "    if model.match_fn is not None:\n",
    "        tmat = model.match_fn(src, tgt)\n",
    "        src_ixs, tgt_ixs = solver_utils.sample_joint(rng_resample, tmat)\n",
    "        src, tgt = src[src_ixs], tgt[tgt_ixs]\n",
    "        src_cond = None if src_cond is None else src_cond[src_ixs]\n",
    "\n",
    "    model.vf_state, loss = model.step_fn(\n",
    "        rng_step_fn,\n",
    "        model.vf_state,\n",
    "        src,\n",
    "        tgt,\n",
    "        src_cond,\n",
    "    )\n",
    "\n",
    "    training_logs[\"loss\"].append(float(loss))\n",
    "    if (it % 10 == 0) and (it > 0):\n",
    "        train_loss = np.mean(training_logs[\"loss\"][-10:])\n",
    "        log_metrics = {\"train_loss\": train_loss}\n",
    "        eval_step(\n",
    "            None,\n",
    "            model,\n",
    "            {\"train\": train_data, \"test\": test_data, \"ood\": ood_data},\n",
    "            log_metrics,\n",
    "            reconstruct_data_fn,\n",
    "            comp_metrics_fn,\n",
    "            mask_fn,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9e56cce-9634-4c3b-8e87-5e9a3cdf00c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['src_condition', 'src_lin', 'tgt_lin'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ccb8a7d-4873-4d49-b722-15f1d3d30c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2, 1024)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"src_condition\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c786255-f9ae-4d2a-8521-98ff04bcd121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"src_lin\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19ca1aa5-dd4a-4acd-aed4-aeae2dd067bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"tgt_lin\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a301a615-95a5-40ca-bbb7-802bfdb7ee46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ot_pert_genot",
   "language": "python",
   "name": "ot_pert_genot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
