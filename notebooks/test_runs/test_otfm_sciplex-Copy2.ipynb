{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e761b2ce-9f52-4aff-ba9e-93048c063928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from typing import Literal, Optional\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import numpy as np\n",
    "import optax\n",
    "import scanpy as sc\n",
    "from flax import linen as nn\n",
    "from ott.neural import datasets\n",
    "from ott.neural.methods.flows import dynamics, otfm\n",
    "from ott.neural.networks.layers import time_encoder\n",
    "from ott.solvers import utils as solver_utils\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ot_pert.metrics import compute_mean_metrics, compute_metrics_fast\n",
    "from ot_pert.utils import ConditionalLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74575f53-0f9e-4c99-b2a8-967ec3143352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_data(embedding: np.ndarray, projection_matrix: np.ndarray, mean_to_add: np.ndarray) -> np.ndarray:\n",
    "    return np.matmul(embedding, projection_matrix.T) + mean_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e7d7477-ca40-49dd-b84c-6f6b67f71706",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsm_key_cond = \"ecfp_dose_cell_line\"\n",
    "obsm_key_data = \"X_pca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80093da-403e-4a3e-8a39-afc0b8d66467",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train_path = \"/lustre/groups/ml01/workspace/ot_perturbation/data/sciplex/adata_train_30.h5ad\"\n",
    "adata_test_path = \"/lustre/groups/ml01/workspace/ot_perturbation/data/sciplex/adata_test_30.h5ad\"\n",
    "adata_ood_path = \"/lustre/groups/ml01/workspace/ot_perturbation/data/sciplex/adata_ood_30.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57d49e-5b66-4a35-a22e-cd9b29f06204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc00f9f-8f22-4c3e-938f-e0e9543e8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "import hydra\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import numpy as np\n",
    "import optax\n",
    "import scanpy as sc\n",
    "import wandb\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from ott.neural import datasets\n",
    "from ott.neural.methods.flows import dynamics, otfm\n",
    "from ott.neural.networks.layers import time_encoder\n",
    "from ott.neural.networks.velocity_field import VelocityField\n",
    "from ott.solvers import utils as solver_utils\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ot_pert.metrics import compute_mean_metrics, compute_metrics, compute_metrics_fast\n",
    "from ot_pert.utils import ConditionalLoader\n",
    "\n",
    "\n",
    "def reconstruct_data(embedding, projection_matrix, mean_to_add):\n",
    "    \"\"\"Reconstructs data from projections.\"\"\"\n",
    "    return np.matmul(embedding, projection_matrix.T) + mean_to_add\n",
    "\n",
    "\n",
    "\n",
    "def load_data(adata, cfg, *, return_dl: bool):\n",
    "    \"\"\"Loads data and preprocesses it based on configuration.\"\"\"\n",
    "    dls = []\n",
    "    data_source = {}\n",
    "    data_target = {}\n",
    "    data_source_decoded = {}\n",
    "    data_target_decoded = {}\n",
    "    data_conditions = {}\n",
    "    for cond in adata.obs[\"condition\"].cat.categories:\n",
    "        if \"Vehicle\" not in cond:\n",
    "            src_str_unique = list(adata[adata.obs[\"condition\"] == cond].obs[\"cell_type\"].unique())\n",
    "            assert len(src_str_unique) == 1\n",
    "            src_str = src_str_unique[0] + \"_Vehicle_0.0\"\n",
    "            source = adata[adata.obs[\"condition\"] == src_str[0] + \"_Vehicle_0.0\"].obsm[obsm_key_data]\n",
    "            source_decoded = adata[adata.obs[\"condition\"] == src_str[0] + \"_Vehicle_0.0\"].X.A\n",
    "            target = adata[adata.obs[\"condition\"] == cond].obsm[obsm_key_data]\n",
    "            target_decoded = adata[adata.obs[\"condition\"] == cond].X.A\n",
    "            conds = adata[adata.obs[\"condition\"] == cond].obsm[obsm_key_cond]\n",
    "            assert np.all(np.all(conds == conds[0], axis=1))\n",
    "            conds = np.tile(conds[0], (len(source), 1))\n",
    "            if return_dl:\n",
    "                dls.append(\n",
    "                    DataLoader(\n",
    "                        datasets.OTDataset(\n",
    "                            datasets.OTData(\n",
    "                                lin=source,\n",
    "                                condition=conds,\n",
    "                            ),\n",
    "                            datasets.OTData(lin=target),\n",
    "                        ),\n",
    "                        batch_size=512,\n",
    "                        shuffle=True,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                data_source[cond] = source\n",
    "                data_target[cond] = target\n",
    "                data_source_decoded[cond] = source_decoded\n",
    "                data_target_decoded[cond] = target_decoded\n",
    "                data_conditions[cond] = conds\n",
    "    if return_dl:\n",
    "        return ConditionalLoader(dls, seed=0)\n",
    "\n",
    "    deg_dict = {k: v for k, v in adata.uns[\"rank_genes_groups_cov_all\"].items() if k in data_conditions.keys()}\n",
    "\n",
    "    return {\n",
    "        \"source\": data_source,\n",
    "        \"target\": data_target,\n",
    "        \"source_decoded\": data_source_decoded,\n",
    "        \"target_decoded\": data_target_decoded,\n",
    "        \"conditions\": data_conditions,\n",
    "        \"deg_dict\": deg_dict,\n",
    "    }\n",
    "\n",
    "\n",
    "def data_matching_function(src_lin, tgt_lin, src_quad, tgt_quad, typ, epsilon=1e-2, tau_a=1.0, tau_b=1.0):\n",
    "    \"\"\"Defines how data should be matched based on the type.\"\"\"\n",
    "    match_fn = {\n",
    "        \"lin\": lambda: solver_utils.match_linear(\n",
    "            x=src_lin, y=tgt_lin, scale_cost=\"mean\", epsilon=epsilon, tau_a=tau_a, tau_b=tau_b\n",
    "        ),\n",
    "        \"quad\": lambda: solver_utils.match_quadratic(xx=src_quad, yy=tgt_quad),\n",
    "        \"fused\": lambda: solver_utils.match_quadratic(xx=src_quad, yy=tgt_quad, x=src_lin, y=tgt_lin),\n",
    "    }\n",
    "    return match_fn.get(typ, lambda: None)()\n",
    "\n",
    "\n",
    "def get_mask(x, y, var_names):\n",
    "    return x[:, [gene in y for gene in var_names]]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def eval_step(model, data, log_metrics, reconstruct_data_fn, comp_metrics_fn, mask_fn):\n",
    "    for k, dat in data.items():\n",
    "        if len(dat) > 1:\n",
    "            prediction = jtu.tree_map(model.transport, dat[\"source\"], dat[\"conditions\"])\n",
    "            metrics = jtu.tree_map(comp_metrics_fn, dat[\"target\"], prediction)\n",
    "            mean_metrics = compute_mean_metrics(metrics, prefix=f\"{k}_\")\n",
    "            log_metrics.update(mean_metrics)\n",
    "\n",
    "            prediction_decoded = jtu.tree_map(reconstruct_data_fn, prediction)\n",
    "            metrics_decoded = jtu.tree_map(comp_metrics_fn, dat[\"target_decoded\"], prediction_decoded)\n",
    "            mean_metrics_decoded = compute_mean_metrics(metrics_decoded, prefix=f\"decoded_{k}_\")\n",
    "            log_metrics.update(mean_metrics_decoded)\n",
    "\n",
    "            prediction_decoded_deg = jtu.tree_map(mask_fn, prediction_decoded, dat[\"deg\"])\n",
    "            metrics_deg = jtu.tree_map(comp_metrics_fn, dat[\"target_decoded_deg\"], prediction_decoded_deg)\n",
    "            mean_metrics_deg = compute_mean_metrics(metrics_deg, prefix=f\"deg_{k}_\")\n",
    "            log_metrics.update(mean_metrics_deg)\n",
    "    wandb.log(log_metrics)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb732e3a-7dc0-413a-b3cd-fb407a81fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train = sc.read_h5ad(adata_train_path)\n",
    "sc.pp.subsample(adata_train, fraction=0.1)\n",
    "adata_test = sc.read_h5ad(adata_test_path) \n",
    "adata_ood = sc.read_h5ad(adata_ood_path)\n",
    "dl = load_data(adata_train, cfg, return_dl=True)\n",
    "train_data = {}\n",
    "test_data = load_data(adata_test, cfg, return_dl=False)\n",
    "ood_data = load_data(adata_ood, cfg, return_dl=False)\n",
    "comp_metrics_fn = compute_metrics_fast if True else compute_metrics\n",
    "\n",
    "reconstruct_data_fn = functools.partial(\n",
    "    reconstruct_data, projection_matrix=adata_train.varm[\"PCs\"], mean_to_add=adata_train.varm[\"X_train_mean\"].T\n",
    ")\n",
    "mask_fn = functools.partial(get_mask, var_names=adata_train.var_names)\n",
    "\n",
    "batch = next(dl)\n",
    "output_dim = batch[\"tgt_lin\"].shape[1]\n",
    "\n",
    "vf = VelocityField(\n",
    "    hidden_dims=[512, 512],\n",
    "    time_dims=[512, 512],\n",
    "    output_dims=[512, 512] + output_dim,\n",
    "    condition_dims=[512, 512],\n",
    "    time_encoder=functools.partial(time_encoder.cyclical_time_encoder, n_freqs=1024),\n",
    ")\n",
    "\n",
    "model = otfm.OTFlowMatching(\n",
    "    vf,\n",
    "    flow=dynamics.ConstantNoiseFlow(1.0),\n",
    "    match_fn=jax.jit(\n",
    "        functools.partial(\n",
    "            data_matching_function,\n",
    "            typ=\"lin\",\n",
    "            epsilon=1.0,\n",
    "            tau_a=1.0,\n",
    "            tau_b=1.0,\n",
    "        )\n",
    "    ),\n",
    "    condition_dim=[512, 512],\n",
    "    rng=jax.random.PRNGKey(13),\n",
    "    optimizer=optax.MultiSteps(optax.adam(1e-4), 10),\n",
    ")\n",
    "\n",
    "training_logs = {\"loss\": []}\n",
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "for it in tqdm(range(100)):\n",
    "    rng, rng_resample, rng_step_fn = jax.random.split(rng, 3)\n",
    "    batch = next(dl)\n",
    "    batch = jtu.tree_map(jnp.asarray, batch)\n",
    "\n",
    "    src, tgt = batch[\"src_lin\"], batch[\"tgt_lin\"]\n",
    "    src_cond = batch.get(\"src_condition\")\n",
    "\n",
    "    if model.match_fn is not None:\n",
    "        tmat = model.match_fn(src, tgt)\n",
    "        src_ixs, tgt_ixs = solver_utils.sample_joint(rng_resample, tmat)\n",
    "        src, tgt = src[src_ixs], tgt[tgt_ixs]\n",
    "        src_cond = None if src_cond is None else src_cond[src_ixs]\n",
    "\n",
    "    model.vf_state, loss = model.step_fn(\n",
    "        rng_step_fn,\n",
    "        model.vf_state,\n",
    "        src,\n",
    "        tgt,\n",
    "        src_cond,\n",
    "    )\n",
    "\n",
    "    training_logs[\"loss\"].append(float(loss))\n",
    "    if (it % 10 == 0) and (it > 0):\n",
    "        train_loss = np.mean(training_logs[\"loss\"][-10 :])\n",
    "        log_metrics = {\"train_loss\": train_loss}\n",
    "        eval_step(\n",
    "            model,\n",
    "            {\"train\": train_data, \"test\": test_data, \"ood\": ood_data},\n",
    "            log_metrics,\n",
    "            reconstruct_data_fn,\n",
    "            comp_metrics_fn,\n",
    "            mask_fn,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c09eaf-91ea-46f9-a527-5f92c1baa834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ot_pert_genot",
   "language": "python",
   "name": "ot_pert_genot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
