{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import jax\n",
    "import os\n",
    "from cfp.metrics import compute_metrics, compute_mean_metrics, compute_metrics_fast\n",
    "import cfp.preprocessing as cfpp\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from gears import PertData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(x, y):\n",
    "    return x[:, [gene in y for gene in adata_train.var_names]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0\n",
    "seed = split + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29254, 5045) (11254, 5045)\n",
      "(28754, 5045) (10754, 5045)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/home/haicu/soeren.becker/repos/ot_pert_reproducibility/norman2019/norman_preprocessed_adata\"\n",
    "\n",
    "adata_train_path = os.path.join(DATA_DIR, f\"adata_train_pca_50_split_{split}.h5ad\")\n",
    "adata_test_path = os.path.join(DATA_DIR, f\"adata_val_pca_50_split_{split}.h5ad\")\n",
    "adata_ood_path = os.path.join(DATA_DIR, f\"adata_test_pca_50_split_{split}.h5ad\")\n",
    "\n",
    "# load data splits\n",
    "adata_train = sc.read(adata_train_path)\n",
    "adata_test = sc.read(adata_test_path)\n",
    "adata_ood = sc.read(adata_ood_path)\n",
    "\n",
    "# remove ctrl from ood and val\n",
    "print(adata_ood.shape, adata_test.shape)\n",
    "adata_ood = adata_ood[adata_ood.obs.condition != \"ctrl\"]\n",
    "adata_test = adata_test[adata_test.obs.condition != \"ctrl\"]\n",
    "print(adata_ood.shape, adata_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "These perturbations are not in the GO graph and their perturbation can thus not be predicted\n",
      "['RHOXF2BB+ctrl' 'LYL1+IER5L' 'ctrl+IER5L' 'KIAA1804+ctrl' 'IER5L+ctrl'\n",
      " 'RHOXF2BB+ZBTB25' 'RHOXF2BB+SET']\n",
      "Local copy of pyg dataset is detected. Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/haicu/soeren.becker/repos/ot_pert_reproducibility/norman2019\"\n",
    "pert_data = PertData(\n",
    "    data_dir,  \n",
    "    gene_set_path=os.path.join(data_dir, \"essential_norman.pkl\")\n",
    ")\n",
    "pert_data.load(data_path = data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local copy of split is detected. Loading...\n",
      "Simulation split test composition:\n",
      "combo_seen0:9\n",
      "combo_seen1:43\n",
      "combo_seen2:19\n",
      "unseen_single:36\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here1\n"
     ]
    }
   ],
   "source": [
    "pert_data.prepare_split(split = \"simulation\", seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AHR+FEV',\n",
       " 'AHR+ctrl',\n",
       " 'ATL1+ctrl',\n",
       " 'BAK1+ctrl',\n",
       " 'BPGM+SAMD1',\n",
       " 'BPGM+ctrl',\n",
       " 'CBFA2T3+ctrl',\n",
       " 'CEBPA+ctrl',\n",
       " 'CEBPE+CEBPA',\n",
       " 'CEBPE+PTPN12',\n",
       " 'CEBPE+RUNX1T1',\n",
       " 'CEBPE+ctrl',\n",
       " 'CLDN6+ctrl',\n",
       " 'CNN1+UBASH3A',\n",
       " 'CNN1+ctrl',\n",
       " 'COL1A1+ctrl',\n",
       " 'CSRNP1+ctrl',\n",
       " 'DLX2+ctrl',\n",
       " 'ETS2+IGDCC3',\n",
       " 'ETS2+IKZF3',\n",
       " 'ETS2+ctrl',\n",
       " 'FEV+MAP7D1',\n",
       " 'FEV+ctrl',\n",
       " 'FOSB+UBASH3B',\n",
       " 'FOSB+ctrl',\n",
       " 'FOXA1+FOXF1',\n",
       " 'FOXA1+ctrl',\n",
       " 'FOXA3+FOXA1',\n",
       " 'FOXA3+FOXF1',\n",
       " 'FOXA3+ctrl',\n",
       " 'FOXF1+HOXB9',\n",
       " 'FOXF1+ctrl',\n",
       " 'FOXO4+ctrl',\n",
       " 'GLB1L2+ctrl',\n",
       " 'HES7+ctrl',\n",
       " 'HK2+ctrl',\n",
       " 'HNF4A+ctrl',\n",
       " 'HOXA13+ctrl',\n",
       " 'HOXB9+ctrl',\n",
       " 'HOXC13+ctrl',\n",
       " 'IGDCC3+MAPK1',\n",
       " 'IGDCC3+ZBTB25',\n",
       " 'IGDCC3+ctrl',\n",
       " 'IKZF3+ctrl',\n",
       " 'IRF1+SET',\n",
       " 'IRF1+ctrl',\n",
       " 'ISL2+ctrl',\n",
       " 'KIF18B+KIF2C',\n",
       " 'KIF18B+ctrl',\n",
       " 'KIF2C+ctrl',\n",
       " 'KMT2A+ctrl',\n",
       " 'LHX1+ctrl',\n",
       " 'LYL1+ctrl',\n",
       " 'MAML2+ctrl',\n",
       " 'MAP2K3+MAP2K6',\n",
       " 'MAP2K3+SLC38A2',\n",
       " 'MAP2K3+ctrl',\n",
       " 'MAP2K6+IKZF3',\n",
       " 'MAP2K6+ctrl',\n",
       " 'MAP4K3+ctrl',\n",
       " 'MAP4K5+ctrl',\n",
       " 'MAP7D1+ctrl',\n",
       " 'MAPK1+IKZF3',\n",
       " 'MAPK1+TGFBR2',\n",
       " 'MAPK1+ctrl',\n",
       " 'MIDN+ctrl',\n",
       " 'NCL+ctrl',\n",
       " 'NIT1+ctrl',\n",
       " 'PLK4+STIL',\n",
       " 'PLK4+ctrl',\n",
       " 'POU3F2+ctrl',\n",
       " 'PTPN1+ctrl',\n",
       " 'PTPN12+SNAI1',\n",
       " 'PTPN12+UBASH3A',\n",
       " 'PTPN12+ZBTB25',\n",
       " 'PTPN12+ctrl',\n",
       " 'RREB1+ctrl',\n",
       " 'RUNX1T1+ctrl',\n",
       " 'SAMD1+PTPN12',\n",
       " 'SAMD1+TGFBR2',\n",
       " 'SAMD1+UBASH3B',\n",
       " 'SAMD1+ctrl',\n",
       " 'SET+CEBPE',\n",
       " 'SET+ctrl',\n",
       " 'SGK1+TBX3',\n",
       " 'SGK1+ctrl',\n",
       " 'SLC6A9+ctrl',\n",
       " 'SNAI1+UBASH3B',\n",
       " 'SNAI1+ctrl',\n",
       " 'STIL+ctrl',\n",
       " 'TBX3+ctrl',\n",
       " 'TGFBR2+IGDCC3',\n",
       " 'TGFBR2+ctrl',\n",
       " 'TMSB4X+BAK1',\n",
       " 'TMSB4X+ctrl',\n",
       " 'TP73+ctrl',\n",
       " 'TSC22D1+ctrl',\n",
       " 'UBASH3A+ctrl',\n",
       " 'UBASH3B+CNN1',\n",
       " 'UBASH3B+UBASH3A',\n",
       " 'UBASH3B+ctrl',\n",
       " 'ZBTB25+ctrl',\n",
       " 'ZC3HAV1+CEBPA',\n",
       " 'ZC3HAV1+CEBPE',\n",
       " 'ZC3HAV1+ctrl',\n",
       " 'ZNF318+ctrl',\n",
       " 'ctrl',\n",
       " 'ctrl+BAK1',\n",
       " 'ctrl+CBFA2T3',\n",
       " 'ctrl+CEBPA',\n",
       " 'ctrl+CEBPE',\n",
       " 'ctrl+CLDN6',\n",
       " 'ctrl+CNN1',\n",
       " 'ctrl+DLX2',\n",
       " 'ctrl+ETS2',\n",
       " 'ctrl+FEV',\n",
       " 'ctrl+FOXA1',\n",
       " 'ctrl+FOXF1',\n",
       " 'ctrl+HOXB9',\n",
       " 'ctrl+HOXC13',\n",
       " 'ctrl+IGDCC3',\n",
       " 'ctrl+IKZF3',\n",
       " 'ctrl+ISL2',\n",
       " 'ctrl+KIF2C',\n",
       " 'ctrl+MAP2K6',\n",
       " 'ctrl+MAP7D1',\n",
       " 'ctrl+MAPK1',\n",
       " 'ctrl+PTPN12',\n",
       " 'ctrl+RUNX1T1',\n",
       " 'ctrl+SAMD1',\n",
       " 'ctrl+SET',\n",
       " 'ctrl+SLC38A2',\n",
       " 'ctrl+SNAI1',\n",
       " 'ctrl+STIL',\n",
       " 'ctrl+TBX3',\n",
       " 'ctrl+TGFBR2',\n",
       " 'ctrl+UBASH3A',\n",
       " 'ctrl+UBASH3B',\n",
       " 'ctrl+ZBTB25']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pert_data.set2conditions[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARRDC3+ctrl',\n",
       " 'BPGM+ZBTB1',\n",
       " 'C19orf26+ctrl',\n",
       " 'CITED1+ctrl',\n",
       " 'CNNM4+ctrl',\n",
       " 'ELMSAN1+ctrl',\n",
       " 'ETS2+MAP7D1',\n",
       " 'FEV+CBFA2T3',\n",
       " 'FOSB+IKZF3',\n",
       " 'FOSB+PTPN12',\n",
       " 'KLF1+BAK1',\n",
       " 'KLF1+CEBPA',\n",
       " 'KLF1+CLDN6',\n",
       " 'KLF1+MAP2K6',\n",
       " 'KLF1+TGFBR2',\n",
       " 'KLF1+ctrl',\n",
       " 'LHX1+ELMSAN1',\n",
       " 'MAP2K3+ELMSAN1',\n",
       " 'MAP2K6+ELMSAN1',\n",
       " 'SAMD1+ZBTB1',\n",
       " 'SET+KLF1',\n",
       " 'SGK1+TBX2',\n",
       " 'TBX2+ctrl',\n",
       " 'TGFBR2+C19orf26',\n",
       " 'TGFBR2+ETS2',\n",
       " 'ZBTB1+ctrl',\n",
       " 'ctrl+C19orf26',\n",
       " 'ctrl+ELMSAN1',\n",
       " 'ctrl+KLF1',\n",
       " 'ctrl+TBX2',\n",
       " 'ctrl+ZBTB1']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pert_data.set2conditions[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KLF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'adata',\n",
       " 'create_cell_graph',\n",
       " 'create_cell_graph_dataset',\n",
       " 'create_dataset_file',\n",
       " 'ctrl_adata',\n",
       " 'data_path',\n",
       " 'dataset_name',\n",
       " 'dataset_path',\n",
       " 'dataset_processed',\n",
       " 'default_pert_graph',\n",
       " 'gene2go',\n",
       " 'gene_names',\n",
       " 'gene_set_path',\n",
       " 'get_dataloader',\n",
       " 'get_pert_idx',\n",
       " 'load',\n",
       " 'new_data_process',\n",
       " 'node_map',\n",
       " 'node_map_pert',\n",
       " 'pert_names',\n",
       " 'prepare_split',\n",
       " 'seed',\n",
       " 'set2conditions',\n",
       " 'set_pert_genes',\n",
       " 'split',\n",
       " 'subgroup',\n",
       " 'train_gene_set_size']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pert_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Doublecheck that we are using the same splits as GEARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assertions passed -> We are using the same splits as GEARS.\n"
     ]
    }
   ],
   "source": [
    "path_to_splits_gears = f'/lustre/groups/ml01/workspace/leander.dony/projects/cellflow/241106_gears/reproduce_biolord_repro/data/perturbations/norman/norman2019/splits/norman2019_simulation_{seed}_0.75_subgroup.pkl'\n",
    "subgroups_gears = pd.read_pickle(path_to_splits_gears)\n",
    "test_conditions_gears, ood_conditions_gears = [], []\n",
    "for subgroup in subgroups_gears[\"test_subgroup\"].keys():\n",
    "    ood_conditions_gears.extend(subgroups_gears[\"test_subgroup\"][subgroup])\n",
    "ood_conditions_gears = np.array(ood_conditions_gears)\n",
    "\n",
    "for subgroup in subgroups_gears[\"val_subgroup\"].keys():\n",
    "    test_conditions_gears.extend(subgroups_gears[\"val_subgroup\"][subgroup])\n",
    "test_conditions_gears = np.array(test_conditions_gears)\n",
    "\n",
    "test_conditions = np.asarray(adata_test.obs.condition.values.unique())\n",
    "\n",
    "assert len(test_conditions[~np.isin(test_conditions, test_conditions_gears)]) == 0\n",
    "assert len(test_conditions_gears[~np.isin(test_conditions_gears, test_conditions)]) == 0\n",
    "\n",
    "ood_conditions = np.asarray(adata_ood.obs.condition.values.unique())\n",
    "assert len(ood_conditions[~np.isin(ood_conditions, ood_conditions_gears)]) == 0\n",
    "assert len(ood_conditions_gears[~np.isin(ood_conditions_gears, ood_conditions)]) == 0\n",
    "\n",
    "assert np.isin(subgroups_gears[\"test_subgroup\"]['combo_seen2'], adata_ood.obs.condition).all()\n",
    "\n",
    "print(\"Assertions passed -> We are using the same splits as GEARS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute pca on full dataset\n",
    "adata_all = ad.concat((adata_train, adata_test, adata_ood))\n",
    "cfpp.centered_pca(adata_all, n_comps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train_ctrl = adata_train[adata_train.obs.condition == \"ctrl\"].copy()\n",
    "adata_train_single = adata_train[adata_train.obs.kategory == \"single\"].copy()\n",
    "adata_ood_double_seen_2 = adata_ood[adata_ood.obs.condition.isin(subgroups_gears[\"test_subgroup\"]['combo_seen2'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TSC22D1' 'MAML2' 'ctrl' ... 'ctrl' 'FOXA3' 'MAP4K3']\n"
     ]
    }
   ],
   "source": [
    "genes = adata_train_single.obs.condition.str.split(\"+\", expand=True).values\n",
    "genes_1 = genes[:, 0]\n",
    "print(genes_1)\n",
    "genes_2 = genes[:, 1]\n",
    "mask = genes_1 == \"ctrl\"\n",
    "\n",
    "genes_1[mask], genes_2[mask] = genes_2[mask], genes_1[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the perturbed gene is always gene 1\n",
    "adata_train_single.obs.loc[:, \"condition_ordered\"] = genes_1 + \"+\" + genes_2\n",
    "adata_train_single.obs.loc[:, \"gene_1_ordered\"] = genes_1\n",
    "adata_train_single.obs.loc[:, \"gene_2_ordered\"] = genes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 5045), (761, 5045))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells_1.shape, cells_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KLF1'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ctrl+ELMSAN1',\n",
       " 'KLF1+ctrl',\n",
       " 'ctrl+KLF1',\n",
       " 'ctrl+TBX2',\n",
       " 'C19orf26+ctrl',\n",
       " 'ZBTB1+ctrl',\n",
       " 'ARRDC3+ctrl',\n",
       " 'ctrl+ZBTB1',\n",
       " 'ctrl+C19orf26',\n",
       " 'CNNM4+ctrl',\n",
       " 'TBX2+ctrl',\n",
       " 'ELMSAN1+ctrl',\n",
       " 'CITED1+ctrl']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_test[adata_test.obs.kategory == \"single\"].obs.condition.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['ARRDC3', 'BPGM', 'C19orf26', 'CITED1', 'CNNM4', 'ELMSAN1', 'ETS2',\n",
       "        'FEV', 'FOSB', 'KLF1', 'LHX1', 'MAP2K3', 'MAP2K6', 'SAMD1', 'SET',\n",
       "        'SGK1', 'TBX2', 'TGFBR2', 'ZBTB1', 'ctrl'], dtype='<U8'),\n",
       " array([ 6, 19,  3, 17, 11, 13, 15, 16, 18,  0,  4, 10,  8,  9,  7, 14, 12,\n",
       "         1,  5,  2]))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(\n",
    "    adata_test.obs.gene_1.unique().tolist(),\n",
    "    adata_test.obs.gene_2.unique().tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UBASH3B+PTPN12', 'KLF1+FOXA1', 'TBX3+TBX2', 'CEBPE+KLF1', 'UBASH3B+ZBTB25', ..., 'ETS2+MAPK1', 'FEV+ISL2', 'POU3F2+CBFA2T3', 'FOXA1+HOXB9', 'SNAI1+DLX2']\n",
       "Length: 19\n",
       "Categories (19, object): ['AHR+KLF1', 'CEBPE+CNN1', 'CEBPE+KLF1', 'CNN1+MAPK1', ..., 'TBX3+TBX2', 'UBASH3B+PTPN12', 'UBASH3B+ZBTB25', 'ZC3HAV1+HOXC13']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_ood_double_seen_2.obs.condition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLED_CELLS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315c12a3621a4804bb82b508d86113d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[177], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m cells_2 \u001b[38;5;241m=\u001b[39m adata_train_single[adata_train_single\u001b[38;5;241m.\u001b[39mobs\u001b[38;5;241m.\u001b[39mgene_1_ordered \u001b[38;5;241m==\u001b[39m gene_2]\u001b[38;5;241m.\u001b[39mX\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# choose NUM_SAMPLED_CELLS cells\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m random_idcs_1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcells_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_SAMPLED_CELLS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m random_idcs_2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(cells_2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], size\u001b[38;5;241m=\u001b[39mNUM_SAMPLED_CELLS, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m cells_1 \u001b[38;5;241m=\u001b[39m cells_1[random_idcs_1]\u001b[38;5;241m.\u001b[39mtodense()\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:968\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "all_predictions, all_conditions = [], []\n",
    "\n",
    "for condition in tqdm(adata_ood_double_seen_2.obs.condition.unique()):\n",
    "\n",
    "    # get perturbed genes\n",
    "    gene_1, gene_2 = condition.split(\"+\")\n",
    "\n",
    "    # get perturbed gene expression profiles\n",
    "    cells_1 = adata_train_single[adata_train_single.obs.gene_1_ordered == gene_1].X\n",
    "    cells_2 = adata_train_single[adata_train_single.obs.gene_1_ordered == gene_2].X\n",
    "\n",
    "    # choose NUM_SAMPLED_CELLS cells\n",
    "    random_idcs_1 = np.random.choice(cells_1.shape[0], size=NUM_SAMPLED_CELLS, replace=True)\n",
    "    random_idcs_2 = np.random.choice(cells_2.shape[0], size=NUM_SAMPLED_CELLS, replace=True)\n",
    "    \n",
    "    cells_1 = cells_1[random_idcs_1].todense()\n",
    "    cells_2 = cells_2[random_idcs_2].todense()\n",
    "\n",
    "    # get control cells\n",
    "    random_idcs_ctrl = np.random.choice(adata_train_ctrl.shape[0], size=NUM_SAMPLED_CELLS, replace=True)\n",
    "    ctrl_cells = adata_train_ctrl.X[random_idcs_ctrl]\n",
    "\n",
    "    # compute displacements\n",
    "    displacement_1 = cells_1 - ctrl_cells\n",
    "    displacement_2 = cells_2 - ctrl_cells\n",
    "\n",
    "    # get predictions\n",
    "    predictions = np.asarray(ctrl_cells + displacement_1 + displacement_2)\n",
    "    all_predictions.append(predictions)\n",
    "    all_conditions.extend([condition] * NUM_SAMPLED_CELLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haicu/soeren.becker/miniconda3/envs/env_cfp2/lib/python3.12/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "adata_pred_ood  = ad.AnnData(X=np.vstack(all_predictions), obs=pd.DataFrame(all_conditions, columns=[\"condition\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 7500 × 5045\n",
       "    obs: 'condition'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_pred_ood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfpp.project_pca(query_adata=adata_pred_ood, ref_adata=adata_all)\n",
    "cfpp.project_pca(query_adata=adata_ood, ref_adata=adata_all)\n",
    "\n",
    "ood_data_target_encoded, ood_data_target_decoded = {}, {}\n",
    "ood_data_target_encoded_predicted, ood_data_target_decoded_predicted = {}, {}\n",
    "\n",
    "subgroups = [\"double_seen_2\"]\n",
    "\n",
    "for subgroup in subgroups:\n",
    "\n",
    "    ood_data_target_encoded[subgroup] = {}\n",
    "    ood_data_target_decoded[subgroup] = {}\n",
    "    ood_data_target_encoded_predicted[subgroup] = {}\n",
    "    ood_data_target_decoded_predicted[subgroup] = {}\n",
    "    \n",
    "    for cond in adata_ood.obs[\"condition\"].cat.categories:\n",
    "        if cond == \"ctrl\":\n",
    "            continue\n",
    "        \n",
    "        select = adata_ood.obs[\"condition\"] == cond\n",
    "        select2 = adata_pred_ood.obs[\"condition\"] == cond\n",
    "        if subgroup != \"all\":\n",
    "            select = select & (adata_ood.obs.subgroup == subgroup)\n",
    "\n",
    "        if not any(select):\n",
    "            # the condition is not part of this subgroup\n",
    "            continue\n",
    "        \n",
    "        # pca space\n",
    "        ood_data_target_encoded[subgroup][cond] = adata_ood[select].obsm[\"X_pca\"]\n",
    "        ood_data_target_encoded_predicted[subgroup][cond] = adata_pred_ood[select2].obsm[\"X_pca\"]\n",
    "        # print(ood_data_target_encoded[subgroup][cond].shape, ood_data_target_encoded_predicted[subgroup][cond].shape)\n",
    "    \n",
    "        # gene space\n",
    "        ood_data_target_decoded[subgroup][cond] = np.asarray(adata_ood[select].X.todense())\n",
    "        ood_data_target_decoded_predicted[subgroup][cond] = adata_pred_ood[select2].X\n",
    "        # print(ood_data_target_decoded[subgroup][cond].shape, ood_data_target_decoded_predicted[subgroup][cond].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47f0e5003d24dbdaa0139e85d798f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subgroup: double_seen_2\n",
      "Computing ood_metrics_encoded\n",
      "Computing ood_metrics_decoded\n",
      "Apply DEG mask\n",
      "Compute metrics on DEG subsetted decoded\n"
     ]
    }
   ],
   "source": [
    "ood_metrics_encoded, mean_ood_metrics_encoded = {}, {}\n",
    "ood_metrics_decoded, mean_ood_metrics_decoded = {}, {}\n",
    "deg_ood_metrics, deg_mean_ood_metrics = {}, {}\n",
    "ood_deg_dict = {}\n",
    "ood_deg_target_decoded_predicted, ood_deg_target_decoded = {}, {}\n",
    "\n",
    "for subgroup in tqdm(subgroups[::-1]):\n",
    "\n",
    "    print(f\"subgroup: {subgroup}\")\n",
    "\n",
    "    print(\"Computing ood_metrics_encoded\")\n",
    "    # ood set: evaluation in encoded (=pca) space\n",
    "    ood_metrics_encoded[subgroup] = jax.tree_util.tree_map(\n",
    "        compute_metrics, \n",
    "        # compute_metrics_fast, \n",
    "        ood_data_target_encoded[subgroup], \n",
    "        ood_data_target_encoded_predicted[subgroup]\n",
    "    )\n",
    "    mean_ood_metrics_encoded[subgroup] = compute_mean_metrics(\n",
    "        ood_metrics_encoded[subgroup], \n",
    "        prefix=\"encoded_ood_\",\n",
    "    )\n",
    "\n",
    "    print(\"Computing ood_metrics_decoded\")\n",
    "    # ood set: evaluation in decoded (=gene) space\n",
    "    ood_metrics_decoded[subgroup] = jax.tree_util.tree_map(\n",
    "        # compute_metrics, \n",
    "        compute_metrics_fast, \n",
    "        ood_data_target_decoded[subgroup], \n",
    "        ood_data_target_decoded_predicted[subgroup]\n",
    "    )\n",
    "    mean_ood_metrics_decoded[subgroup] = compute_mean_metrics(\n",
    "        ood_metrics_decoded[subgroup], \n",
    "        prefix=\"decoded_ood_\",\n",
    "    )\n",
    "\n",
    "    # ood set\n",
    "    ood_deg_dict[subgroup] = {\n",
    "        k: v\n",
    "        for k, v in adata_train.uns['rank_genes_groups_cov_all'].items() \n",
    "        if k in ood_data_target_decoded_predicted[subgroup].keys()\n",
    "    }\n",
    "\n",
    "    print(\"Apply DEG mask\")\n",
    "    # ood set\n",
    "    ood_deg_target_decoded_predicted[subgroup] = jax.tree_util.tree_map(\n",
    "        get_mask, \n",
    "        ood_data_target_decoded_predicted[subgroup], \n",
    "        ood_deg_dict[subgroup]\n",
    "    )\n",
    "    \n",
    "    ood_deg_target_decoded[subgroup] = jax.tree_util.tree_map(\n",
    "        get_mask, \n",
    "        ood_data_target_decoded[subgroup], \n",
    "        ood_deg_dict[subgroup]\n",
    "    )\n",
    "\n",
    "    print(\"Compute metrics on DEG subsetted decoded\")\n",
    "    deg_ood_metrics[subgroup] = jax.tree_util.tree_map(\n",
    "        compute_metrics, \n",
    "        # compute_metrics_fast, \n",
    "        ood_deg_target_decoded[subgroup], \n",
    "        ood_deg_target_decoded_predicted[subgroup]\n",
    "    )\n",
    "    deg_mean_ood_metrics[subgroup] = compute_mean_metrics(\n",
    "        deg_ood_metrics[subgroup], \n",
    "        prefix=\"deg_ood_\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'double_seen_2': {'deg_ood_r_squared': 0.9708234429359436,\n",
       "  'deg_ood_sinkhorn_div_1': 32.74098542531331,\n",
       "  'deg_ood_sinkhorn_div_10': 11.421825281778972,\n",
       "  'deg_ood_sinkhorn_div_100': 2.0428421020507814,\n",
       "  'deg_ood_e_distance': np.float64(3.3670727565598644),\n",
       "  'deg_ood_mmd': np.float32(0.02222708)}}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deg_mean_ood_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_results = {\n",
    "    \"ood_metrics_encoded\": ood_metrics_encoded,\n",
    "    \"mean_ood_metrics_encoded\": mean_ood_metrics_encoded,\n",
    "    \"ood_metrics_decoded\": ood_metrics_decoded,\n",
    "    \"mean_ood_metrics_decoded\": mean_ood_metrics_decoded,\n",
    "    \"deg_ood_metrics\": deg_ood_metrics,\n",
    "    \"deg_mean_ood_metrics\": deg_mean_ood_metrics,\n",
    "    \"ood_deg_dict\": ood_deg_dict,\n",
    "    \"ood_deg_target_decoded_predicted\": ood_deg_target_decoded_predicted,\n",
    "    \"ood_deg_target_decoded\": ood_deg_target_decoded,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = \"/lustre/groups/ml01/workspace/ot_perturbation/data/norman_soren/additive\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "pd.to_pickle(collected_results, os.path.join(OUT_DIR, f\"norman_additive_split_{split}_collected_results.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_cfp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
